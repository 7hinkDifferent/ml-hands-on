{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22ef0bc",
   "metadata": {},
   "source": [
    "# NumPy - æ•°å€¼è®¡ç®—åŸºç¡€\n",
    "\n",
    "NumPy (Numerical Python) æ˜¯Pythonç§‘å­¦è®¡ç®—çš„åŸºç¡€åº“ï¼Œæä¾›äº†é«˜æ€§èƒ½çš„å¤šç»´æ•°ç»„å¯¹è±¡å’Œç›¸å…³å·¥å…·ã€‚\n",
    "\n",
    "## ä¸ºä»€ä¹ˆå­¦ä¹ NumPyï¼Ÿ\n",
    "\n",
    "- ğŸš€ **é«˜æ€§èƒ½**: Cè¯­è¨€å®ç°ï¼Œæ¯”åŸç”ŸPythonå¿«10-100å€\n",
    "- ğŸ“Š **æ•°ç»„è®¡ç®—**: æä¾›å¼ºå¤§çš„Nç»´æ•°ç»„å¯¹è±¡ndarray\n",
    "- ğŸ”§ **å¹¿æ³›åº”ç”¨**: å‡ ä¹æ‰€æœ‰Pythonç§‘å­¦è®¡ç®—åº“çš„åŸºç¡€\n",
    "- ğŸ§® **æ•°å­¦å‡½æ•°**: ä¸°å¯Œçš„æ•°å­¦å‡½æ•°åº“\n",
    "- ğŸ¯ **å‘é‡åŒ–æ“ä½œ**: é¿å…æ˜¾å¼å¾ªç¯ï¼Œä»£ç ç®€æ´é«˜æ•ˆ\n",
    "\n",
    "## å­¦ä¹ å†…å®¹\n",
    "\n",
    "1. NumPyåŸºç¡€ - æ•°ç»„åˆ›å»ºå’Œå±æ€§\n",
    "2. æ•°ç»„ç´¢å¼•å’Œåˆ‡ç‰‡\n",
    "3. æ•°ç»„è¿ç®—å’Œå¹¿æ’­\n",
    "4. æ•°å­¦å’Œç»Ÿè®¡å‡½æ•°\n",
    "5. æ•°ç»„å˜å½¢å’Œåˆå¹¶\n",
    "6. å®é™…åº”ç”¨ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e509c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥NumPyåº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# æ£€æŸ¥NumPyç‰ˆæœ¬\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "\n",
    "# 1. æ•°ç»„åˆ›å»º\n",
    "print(\"=== æ•°ç»„åˆ›å»º ===\")\n",
    "\n",
    "# ä»åˆ—è¡¨åˆ›å»º\n",
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"ä¸€ç»´æ•°ç»„: {arr1}\")\n",
    "print(f\"äºŒç»´æ•°ç»„:\\n{arr2}\")\n",
    "\n",
    "# ç‰¹æ®Šæ•°ç»„åˆ›å»º\n",
    "zeros = np.zeros((3, 4))  # å…¨0æ•°ç»„\n",
    "ones = np.ones((2, 3))    # å…¨1æ•°ç»„\n",
    "eye = np.eye(3)           # å•ä½çŸ©é˜µ\n",
    "arange = np.arange(0, 10, 2)  # ç­‰å·®æ•°åˆ—\n",
    "linspace = np.linspace(0, 1, 5)  # ç­‰é—´è·æ•°åˆ—\n",
    "\n",
    "print(f\"å…¨0æ•°ç»„:\\n{zeros}\")\n",
    "print(f\"å…¨1æ•°ç»„:\\n{ones}\")\n",
    "print(f\"å•ä½çŸ©é˜µ:\\n{eye}\")\n",
    "print(f\"ç­‰å·®æ•°åˆ—: {arange}\")\n",
    "print(f\"ç­‰é—´è·: {linspace}\")\n",
    "\n",
    "# éšæœºæ•°ç»„\n",
    "np.random.seed(42)  # è®¾ç½®éšæœºç§å­\n",
    "random_arr = np.random.random((2, 3))  # 0-1éšæœºæ•°\n",
    "normal_arr = np.random.normal(0, 1, (2, 3))  # æ­£æ€åˆ†å¸ƒ\n",
    "\n",
    "print(f\"éšæœºæ•°ç»„:\\n{random_arr}\")\n",
    "print(f\"æ­£æ€åˆ†å¸ƒ:\\n{normal_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab07ed",
   "metadata": {},
   "source": [
    "### æ•°ç»„å±æ€§å’Œä¿¡æ¯\n",
    "\n",
    "NumPyæ•°ç»„æœ‰å¾ˆå¤šæœ‰ç”¨çš„å±æ€§ï¼Œå¸®åŠ©æˆ‘ä»¬äº†è§£æ•°ç»„çš„ç»“æ„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. æ•°ç»„å±æ€§è¯¦è§£\n",
    "print(\"=== æ•°ç»„å±æ€§è¯¦è§£ ===\")\n",
    "\n",
    "# åˆ›å»ºå¤šç»´æ•°ç»„ç”¨äºæ¼”ç¤º\n",
    "arr_2d = np.array([[1, 2, 3, 4], \n",
    "                   [5, 6, 7, 8], \n",
    "                   [9, 10, 11, 12]])\n",
    "\n",
    "print(f\"2Dæ•°ç»„:\\n{arr_2d}\")\n",
    "print(f\"å½¢çŠ¶ (shape): {arr_2d.shape}\")          # (è¡Œæ•°, åˆ—æ•°)\n",
    "print(f\"ç»´åº¦æ•° (ndim): {arr_2d.ndim}\")          # ç»´åº¦æ•°\n",
    "print(f\"å…ƒç´ æ€»æ•° (size): {arr_2d.size}\")        # æ€»å…ƒç´ æ•°\n",
    "print(f\"æ•°æ®ç±»å‹ (dtype): {arr_2d.dtype}\")      # æ•°æ®ç±»å‹\n",
    "print(f\"æ¯ä¸ªå…ƒç´ å­—èŠ‚æ•° (itemsize): {arr_2d.itemsize}\")  # æ¯ä¸ªå…ƒç´ å ç”¨å­—èŠ‚\n",
    "print(f\"æ•°ç»„æ€»å­—èŠ‚æ•° (nbytes): {arr_2d.nbytes}\")  # æ€»å†…å­˜ä½¿ç”¨\n",
    "\n",
    "# ä¸åŒæ•°æ®ç±»å‹çš„æ¯”è¾ƒ\n",
    "print(\"\\n=== æ•°æ®ç±»å‹å¯¹æ¯” ===\")\n",
    "int_arr = np.array([1, 2, 3], dtype=np.int32)\n",
    "float_arr = np.array([1.0, 2.0, 3.0], dtype=np.float64)\n",
    "bool_arr = np.array([True, False, True])\n",
    "\n",
    "print(f\"int32æ•°ç»„: {int_arr}, å­—èŠ‚/å…ƒç´ : {int_arr.itemsize}\")\n",
    "print(f\"float64æ•°ç»„: {float_arr}, å­—èŠ‚/å…ƒç´ : {float_arr.itemsize}\")\n",
    "print(f\"boolæ•°ç»„: {bool_arr}, å­—èŠ‚/å…ƒç´ : {bool_arr.itemsize}\")\n",
    "\n",
    "# æ•°ç»„ç»´åº¦æ“ä½œ\n",
    "print(\"\\n=== æ•°ç»„ç»´åº¦æ“ä½œ ===\")\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)  # åˆ›å»º3Dæ•°ç»„\n",
    "print(f\"3Dæ•°ç»„å½¢çŠ¶: {arr_3d.shape}\")\n",
    "print(f\"ç¬¬ä¸€å±‚:\\n{arr_3d[0]}\")\n",
    "print(f\"ç¬¬äºŒå±‚:\\n{arr_3d[1]}\")\n",
    "\n",
    "# æ•°ç»„å†…å­˜å¸ƒå±€\n",
    "print(f\"\\næ•°ç»„æ˜¯å¦è¿ç»­å­˜å‚¨: {arr_2d.flags.c_contiguous}\")\n",
    "print(f\"æ•°ç»„æ˜¯å¦å¯å†™: {arr_2d.flags.writeable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae0de2",
   "metadata": {},
   "source": [
    "## 2. æ•°ç»„ç´¢å¼•å’Œåˆ‡ç‰‡\n",
    "\n",
    "æ•°ç»„ç´¢å¼•å’Œåˆ‡ç‰‡æ˜¯NumPyçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œç”¨äºè®¿é—®å’Œä¿®æ”¹æ•°ç»„å…ƒç´ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ç´¢å¼•å’Œåˆ‡ç‰‡\n",
    "print(\"=== ä¸€ç»´æ•°ç»„ç´¢å¼• ===\")\n",
    "arr_1d = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "print(f\"åŸæ•°ç»„: {arr_1d}\")\n",
    "print(f\"ç¬¬ä¸€ä¸ªå…ƒç´ : {arr_1d[0]}\")\n",
    "print(f\"æœ€åä¸€ä¸ªå…ƒç´ : {arr_1d[-1]}\")\n",
    "print(f\"å‰ä¸‰ä¸ªå…ƒç´ : {arr_1d[:3]}\")\n",
    "print(f\"åä¸‰ä¸ªå…ƒç´ : {arr_1d[-3:]}\")\n",
    "print(f\"æ¯éš”2ä¸ªå…ƒç´ : {arr_1d[::2]}\")\n",
    "print(f\"åå‘æ•°ç»„: {arr_1d[::-1]}\")\n",
    "\n",
    "print(\"\\n=== äºŒç»´æ•°ç»„ç´¢å¼• ===\")\n",
    "# åˆ›å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ ä¸­å¸¸è§çš„æ•°æ®çŸ©é˜µç¤ºä¾‹\n",
    "# å‡è®¾è¿™æ˜¯5ä¸ªæ ·æœ¬ï¼Œ4ä¸ªç‰¹å¾çš„æ•°æ®\n",
    "data_matrix = np.array([\n",
    "    [1.2, 2.1, 3.0, 4.5],  # æ ·æœ¬1\n",
    "    [2.3, 1.9, 2.8, 3.9],  # æ ·æœ¬2\n",
    "    [3.1, 3.5, 4.2, 5.1],  # æ ·æœ¬3\n",
    "    [1.8, 2.7, 3.3, 4.0],  # æ ·æœ¬4\n",
    "    [2.9, 3.2, 3.8, 4.8]   # æ ·æœ¬5\n",
    "])\n",
    "\n",
    "print(f\"æ•°æ®çŸ©é˜µ (5æ ·æœ¬ Ã— 4ç‰¹å¾):\\n{data_matrix}\")\n",
    "print(f\"ç¬¬ä¸€ä¸ªæ ·æœ¬: {data_matrix[0]}\")\n",
    "print(f\"ç¬¬ä¸€ä¸ªç‰¹å¾åˆ—: {data_matrix[:, 0]}\")\n",
    "print(f\"å‰3ä¸ªæ ·æœ¬: \\n{data_matrix[:3]}\")\n",
    "print(f\"å‰3ä¸ªæ ·æœ¬çš„å‰2ä¸ªç‰¹å¾: \\n{data_matrix[:3, :2]}\")\n",
    "print(f\"ç‰¹å®šå…ƒç´  (ç¬¬2è¡Œç¬¬3åˆ—): {data_matrix[1, 2]}\")\n",
    "\n",
    "print(\"\\n=== é«˜çº§ç´¢å¼• ===\")\n",
    "# å¸ƒå°”ç´¢å¼•\n",
    "scores = np.array([85, 92, 78, 96, 88, 73, 91, 87])\n",
    "print(f\"æˆç»©: {scores}\")\n",
    "print(f\"ä¼˜ç§€æˆç»© (>90): {scores[scores > 90]}\")\n",
    "print(f\"éœ€è¦è¡¥è€ƒ (<80): {scores[scores < 80]}\")\n",
    "print(f\"åŠæ ¼ç‡: {np.sum(scores >= 80) / len(scores):.2%}\")\n",
    "\n",
    "# èŠ±å¼ç´¢å¼•\n",
    "print(\"\\n=== èŠ±å¼ç´¢å¼• ===\")\n",
    "student_names = np.array(['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry'])\n",
    "selected_indices = [0, 2, 4, 6]  # é€‰æ‹©å¶æ•°ä½ç½®çš„å­¦ç”Ÿ\n",
    "print(f\"æ‰€æœ‰å­¦ç”Ÿ: {student_names}\")\n",
    "print(f\"é€‰ä¸­çš„å­¦ç”Ÿ: {student_names[selected_indices]}\")\n",
    "print(f\"å¯¹åº”æˆç»©: {scores[selected_indices]}\")\n",
    "\n",
    "# æ¡ä»¶ç´¢å¼•çš„å®é™…åº”ç”¨\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæ•°æ®ç­›é€‰ ===\")\n",
    "# æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®\n",
    "stock_prices = np.array([100, 105, 98, 102, 110, 95, 108, 112, 99, 106])\n",
    "trading_volume = np.array([1000, 1200, 800, 900, 1500, 700, 1100, 1300, 850, 950])\n",
    "\n",
    "# æ‰¾å‡ºä»·æ ¼ä¸Šæ¶¨ä¸”äº¤æ˜“é‡å¤§çš„æ—¥å­\n",
    "price_up = stock_prices > 100\n",
    "high_volume = trading_volume > 1000\n",
    "good_days = price_up & high_volume\n",
    "\n",
    "print(f\"è‚¡ä»·: {stock_prices}\")\n",
    "print(f\"äº¤æ˜“é‡: {trading_volume}\")\n",
    "print(f\"å¥½çš„äº¤æ˜“æ—¥: ç¬¬{np.where(good_days)[0] + 1}å¤©\")\n",
    "print(f\"å¯¹åº”è‚¡ä»·: {stock_prices[good_days]}\")\n",
    "print(f\"å¯¹åº”äº¤æ˜“é‡: {trading_volume[good_days]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74103a8b",
   "metadata": {},
   "source": [
    "## 3. æ•°ç»„è¿ç®—å’Œå¹¿æ’­\n",
    "\n",
    "NumPyçš„å‘é‡åŒ–è¿ç®—æ˜¯å…¶æ ¸å¿ƒä¼˜åŠ¿ï¼Œé¿å…äº†Pythonå¾ªç¯çš„ä½æ•ˆé—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬æ•°å­¦è¿ç®—\n",
    "print(\"=== åŸºæœ¬æ•°å­¦è¿ç®— ===\")\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "print(f\"æ•°ç»„a: {a}\")\n",
    "print(f\"æ•°ç»„b: {b}\")\n",
    "print(f\"åŠ æ³•: a + b = {a + b}\")\n",
    "print(f\"å‡æ³•: b - a = {b - a}\")\n",
    "print(f\"ä¹˜æ³•: a * b = {a * b}\")\n",
    "print(f\"é™¤æ³•: b / a = {b / a}\")\n",
    "print(f\"å¹‚è¿ç®—: a ** 2 = {a ** 2}\")\n",
    "print(f\"å–æ¨¡: b % 7 = {b % 7}\")\n",
    "\n",
    "# æ¯”è¾ƒè¿ç®—\n",
    "print(f\"\\næ¯”è¾ƒè¿ç®—: a > 3 = {a > 3}\")\n",
    "print(f\"é€»è¾‘è¿ç®—: (a > 2) & (a < 5) = {(a > 2) & (a < 5)}\")\n",
    "\n",
    "print(\"\\n=== æ€§èƒ½å¯¹æ¯”ï¼šNumPy vs Python ===\")\n",
    "import time\n",
    "\n",
    "# å¤§æ•°ç»„è¿ç®—æ€§èƒ½å¯¹æ¯”\n",
    "size = 1000000\n",
    "np_array = np.random.random(size)\n",
    "python_list = list(np_array)\n",
    "\n",
    "# NumPyè¿ç®—\n",
    "start_time = time.time()\n",
    "np_result = np_array ** 2 + 2 * np_array + 1\n",
    "numpy_time = time.time() - start_time\n",
    "\n",
    "# Pythonåˆ—è¡¨è¿ç®—\n",
    "start_time = time.time()\n",
    "python_result = [x**2 + 2*x + 1 for x in python_list]\n",
    "python_time = time.time() - start_time\n",
    "\n",
    "print(f\"æ•°ç»„å¤§å°: {size:,}\")\n",
    "print(f\"NumPyè¿ç®—æ—¶é—´: {numpy_time:.4f}ç§’\")\n",
    "print(f\"Pythonåˆ—è¡¨æ—¶é—´: {python_time:.4f}ç§’\")\n",
    "print(f\"NumPyå¿«äº†: {python_time/numpy_time:.1f}å€\")\n",
    "\n",
    "print(\"\\n=== å¹¿æ’­æœºåˆ¶ ===\")\n",
    "# å¹¿æ’­ï¼šä¸åŒå½¢çŠ¶æ•°ç»„é—´çš„è¿ç®—\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "vector = np.array([10, 20, 30])\n",
    "scalar = 100\n",
    "\n",
    "print(f\"åŸçŸ©é˜µ:\\n{matrix}\")\n",
    "print(f\"å‘é‡: {vector}\")\n",
    "print(f\"çŸ©é˜µ + å‘é‡ (å¹¿æ’­):\\n{matrix + vector}\")\n",
    "print(f\"çŸ©é˜µ + æ ‡é‡:\\n{matrix + scalar}\")\n",
    "\n",
    "# æœºå™¨å­¦ä¹ ä¸­çš„å®é™…åº”ç”¨ï¼šç‰¹å¾æ ‡å‡†åŒ–\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šç‰¹å¾æ ‡å‡†åŒ– ===\")\n",
    "# æ¨¡æ‹Ÿæœºå™¨å­¦ä¹ æ•°æ®ï¼š100ä¸ªæ ·æœ¬ï¼Œ3ä¸ªç‰¹å¾\n",
    "np.random.seed(42)\n",
    "features = np.random.normal(loc=[10, 50, 100], scale=[2, 10, 20], size=(100, 3))\n",
    "\n",
    "print(f\"åŸå§‹ç‰¹å¾ç»Ÿè®¡:\")\n",
    "print(f\"å‡å€¼: {np.mean(features, axis=0)}\")\n",
    "print(f\"æ ‡å‡†å·®: {np.std(features, axis=0)}\")\n",
    "\n",
    "# Z-scoreæ ‡å‡†åŒ–\n",
    "mean = np.mean(features, axis=0)\n",
    "std = np.std(features, axis=0)\n",
    "standardized_features = (features - mean) / std\n",
    "\n",
    "print(f\"\\næ ‡å‡†åŒ–åç»Ÿè®¡:\")\n",
    "print(f\"å‡å€¼: {np.mean(standardized_features, axis=0)}\")\n",
    "print(f\"æ ‡å‡†å·®: {np.std(standardized_features, axis=0)}\")\n",
    "\n",
    "# Min-Maxæ ‡å‡†åŒ–\n",
    "min_val = np.min(features, axis=0)\n",
    "max_val = np.max(features, axis=0)\n",
    "normalized_features = (features - min_val) / (max_val - min_val)\n",
    "\n",
    "print(f\"\\nå½’ä¸€åŒ–åèŒƒå›´:\")\n",
    "print(f\"æœ€å°å€¼: {np.min(normalized_features, axis=0)}\")\n",
    "print(f\"æœ€å¤§å€¼: {np.max(normalized_features, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c4a7f",
   "metadata": {},
   "source": [
    "## 4. æ•°å­¦å’Œç»Ÿè®¡å‡½æ•°\n",
    "\n",
    "NumPyæä¾›äº†å¤§é‡çš„æ•°å­¦å’Œç»Ÿè®¡å‡½æ•°ï¼Œæ˜¯æ•°æ®åˆ†æçš„åŸºç¡€å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226113b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ç»Ÿè®¡å‡½æ•°\n",
    "print(\"=== åŸºæœ¬ç»Ÿè®¡å‡½æ•° ===\")\n",
    "# æ¨¡æ‹Ÿå­¦ç”Ÿæˆç»©æ•°æ®\n",
    "np.random.seed(42)\n",
    "scores = np.random.normal(75, 15, 100).astype(int)  # å¹³å‡75åˆ†ï¼Œæ ‡å‡†å·®15\n",
    "scores = np.clip(scores, 0, 100)  # é™åˆ¶åœ¨0-100èŒƒå›´å†…\n",
    "\n",
    "print(f\"å­¦ç”Ÿæˆç»©æ ·æœ¬ (å‰10ä¸ª): {scores[:10]}\")\n",
    "print(f\"æ€»äººæ•°: {len(scores)}\")\n",
    "print(f\"å¹³å‡åˆ†: {np.mean(scores):.2f}\")\n",
    "print(f\"ä¸­ä½æ•°: {np.median(scores):.2f}\")\n",
    "print(f\"æ ‡å‡†å·®: {np.std(scores):.2f}\")\n",
    "print(f\"æ–¹å·®: {np.var(scores):.2f}\")\n",
    "print(f\"æœ€é«˜åˆ†: {np.max(scores)}\")\n",
    "print(f\"æœ€ä½åˆ†: {np.min(scores)}\")\n",
    "print(f\"åˆ†æ•°èŒƒå›´: {np.ptp(scores)}\")  # peak to peak\n",
    "print(f\"25%åˆ†ä½æ•°: {np.percentile(scores, 25):.2f}\")\n",
    "print(f\"75%åˆ†ä½æ•°: {np.percentile(scores, 75):.2f}\")\n",
    "\n",
    "# å¤šç»´æ•°ç»„çš„ç»Ÿè®¡\n",
    "print(\"\\n=== å¤šç»´æ•°ç»„ç»Ÿè®¡ ===\")\n",
    "# æ¨¡æ‹Ÿ3ä¸ªç­çº§çš„æˆç»©\n",
    "class_scores = np.random.normal([70, 75, 80], [10, 12, 8], (3, 30)).astype(int)\n",
    "class_scores = np.clip(class_scores, 0, 100)\n",
    "\n",
    "print(f\"ä¸‰ä¸ªç­çº§æˆç»©å½¢çŠ¶: {class_scores.shape}\")\n",
    "print(f\"å„ç­å¹³å‡åˆ†: {np.mean(class_scores, axis=1)}\")\n",
    "print(f\"å…¨ä½“å¹³å‡åˆ†: {np.mean(class_scores):.2f}\")\n",
    "print(f\"æ¯ç§‘ç›®å¹³å‡åˆ† (å‰5ç§‘): {np.mean(class_scores, axis=0)[:5]}\")\n",
    "\n",
    "# æ•°å­¦å‡½æ•°\n",
    "print(\"\\n=== æ•°å­¦å‡½æ•° ===\")\n",
    "angles = np.array([0, 30, 45, 60, 90])\n",
    "radians = np.deg2rad(angles)  # è§’åº¦è½¬å¼§åº¦\n",
    "\n",
    "print(f\"è§’åº¦: {angles}Â°\")\n",
    "print(f\"å¼§åº¦: {radians}\")\n",
    "print(f\"æ­£å¼¦å€¼: {np.sin(radians)}\")\n",
    "print(f\"ä½™å¼¦å€¼: {np.cos(radians)}\")\n",
    "print(f\"æ­£åˆ‡å€¼: {np.tan(radians)}\")\n",
    "\n",
    "# æŒ‡æ•°å’Œå¯¹æ•°å‡½æ•°\n",
    "print(\"\\n=== æŒ‡æ•°å’Œå¯¹æ•°å‡½æ•° ===\")\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "print(f\"x: {x}\")\n",
    "print(f\"e^x: {np.exp(x)}\")\n",
    "print(f\"2^x: {np.power(2, x)}\")\n",
    "print(f\"ln(x): {np.log(x)}\")\n",
    "print(f\"log10(x): {np.log10(x)}\")\n",
    "print(f\"log2(x): {np.log2(x)}\")\n",
    "\n",
    "# é‡‘èè®¡ç®—ç¤ºä¾‹\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šå¤åˆ©è®¡ç®— ===\")\n",
    "# è®¡ç®—ä¸åŒå¹´åˆ©ç‡ä¸‹çš„æŠ•èµ„å¢é•¿\n",
    "principal = 10000  # æœ¬é‡‘\n",
    "rates = np.array([0.03, 0.05, 0.08, 0.10])  # å¹´åˆ©ç‡\n",
    "years = np.array([1, 5, 10, 20, 30])  # æŠ•èµ„å¹´é™\n",
    "\n",
    "# ä½¿ç”¨å¹¿æ’­è®¡ç®—æ‰€æœ‰ç»„åˆ\n",
    "final_amounts = principal * np.power(1 + rates[:, np.newaxis], years)\n",
    "\n",
    "print(f\"æœ¬é‡‘: Â¥{principal:,}\")\n",
    "print(f\"æŠ•èµ„å¹´é™: {years}\")\n",
    "print(\"ä¸åŒåˆ©ç‡ä¸‹çš„æœ€ç»ˆé‡‘é¢:\")\n",
    "for i, rate in enumerate(rates):\n",
    "    print(f\"{rate:.0%}å¹´åˆ©ç‡: {final_amounts[i]}\")\n",
    "\n",
    "# ç»Ÿè®¡åˆ†æå®ä¾‹\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæ•°æ®åˆ†æ ===\")\n",
    "# æ¨¡æ‹Ÿç½‘ç«™è®¿é—®æ•°æ®\n",
    "np.random.seed(42)\n",
    "daily_visitors = np.random.poisson(1000, 365)  # æ³Šæ¾åˆ†å¸ƒæ¨¡æ‹Ÿæ—¥è®¿é—®é‡\n",
    "weekly_visitors = daily_visitors.reshape(52, 7)  # æŒ‰å‘¨é‡æ’\n",
    "\n",
    "print(f\"å¹´åº¦è®¿é—®æ•°æ®åˆ†æ:\")\n",
    "print(f\"æ€»è®¿é—®é‡: {np.sum(daily_visitors):,}\")\n",
    "print(f\"æ—¥å‡è®¿é—®é‡: {np.mean(daily_visitors):.0f}\")\n",
    "print(f\"è®¿é—®é‡ä¸­ä½æ•°: {np.median(daily_visitors):.0f}\")\n",
    "print(f\"æœ€é«˜æ—¥è®¿é—®é‡: {np.max(daily_visitors):,}\")\n",
    "print(f\"æœ€ä½æ—¥è®¿é—®é‡: {np.min(daily_visitors):,}\")\n",
    "\n",
    "# å‘¨ç»Ÿè®¡\n",
    "weekly_totals = np.sum(weekly_visitors, axis=1)\n",
    "print(f\"\\nå‘¨è®¿é—®é‡ç»Ÿè®¡:\")\n",
    "print(f\"å‘¨å‡è®¿é—®é‡: {np.mean(weekly_totals):.0f}\")\n",
    "print(f\"æœ€å¥½çš„ä¸€å‘¨: {np.max(weekly_totals):,}\")\n",
    "print(f\"æœ€å·®çš„ä¸€å‘¨: {np.min(weekly_totals):,}\")\n",
    "\n",
    "# å·¥ä½œæ—¥vså‘¨æœ«\n",
    "weekday_avg = np.mean(weekly_visitors[:, :5])  # å‘¨ä¸€åˆ°å‘¨äº”\n",
    "weekend_avg = np.mean(weekly_visitors[:, 5:])  # å‘¨å…­å‘¨æ—¥\n",
    "print(f\"å·¥ä½œæ—¥å¹³å‡: {weekday_avg:.0f}\")\n",
    "print(f\"å‘¨æœ«å¹³å‡: {weekend_avg:.0f}\")\n",
    "print(f\"å‘¨æœ«æ¯”å·¥ä½œæ—¥{'é«˜' if weekend_avg > weekday_avg else 'ä½'}{abs(weekend_avg/weekday_avg - 1):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a89ee",
   "metadata": {},
   "source": [
    "## 5. æ•°ç»„å˜å½¢å’Œæ“ä½œ\n",
    "\n",
    "æ•°ç»„çš„å½¢çŠ¶å˜æ¢æ˜¯æ•°æ®å¤„ç†ä¸­çš„å¸¸ç”¨æ“ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°ç»„å½¢çŠ¶å˜æ¢\n",
    "print(\"=== æ•°ç»„å½¢çŠ¶å˜æ¢ ===\")\n",
    "original_array = np.arange(12)\n",
    "print(f\"åŸå§‹æ•°ç»„: {original_array}\")\n",
    "print(f\"åŸå§‹å½¢çŠ¶: {original_array.shape}\")\n",
    "\n",
    "# ä¸åŒçš„reshapeæ–¹å¼\n",
    "reshaped_2d = original_array.reshape(3, 4)\n",
    "reshaped_3d = original_array.reshape(2, 2, 3)\n",
    "\n",
    "print(f\"\\né‡å¡‘ä¸º3Ã—4çŸ©é˜µ:\\n{reshaped_2d}\")\n",
    "print(f\"å½¢çŠ¶: {reshaped_2d.shape}\")\n",
    "\n",
    "print(f\"\\né‡å¡‘ä¸º2Ã—2Ã—3ç«‹æ–¹ä½“:\\n{reshaped_3d}\")\n",
    "print(f\"å½¢çŠ¶: {reshaped_3d.shape}\")\n",
    "\n",
    "# è‡ªåŠ¨æ¨æ–­å½¢çŠ¶\n",
    "auto_reshaped = original_array.reshape(4, -1)  # -1è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—\n",
    "print(f\"\\nè‡ªåŠ¨æ¨æ–­å½¢çŠ¶ (4, -1):\\n{auto_reshaped}\")\n",
    "print(f\"å®é™…å½¢çŠ¶: {auto_reshaped.shape}\")\n",
    "\n",
    "# å±•å¹³æ•°ç»„\n",
    "print(\"\\n=== æ•°ç»„å±•å¹³ ===\")\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"åŸçŸ©é˜µ:\\n{matrix}\")\n",
    "print(f\"flatten(): {matrix.flatten()}\")    # è¿”å›æ‹·è´\n",
    "print(f\"ravel(): {matrix.ravel()}\")        # è¿”å›è§†å›¾ï¼ˆå¦‚æœå¯èƒ½ï¼‰\n",
    "\n",
    "# è½¬ç½®æ“ä½œ\n",
    "print(\"\\n=== è½¬ç½®æ“ä½œ ===\")\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"åŸçŸ©é˜µ (2Ã—3):\\n{matrix}\")\n",
    "print(f\"è½¬ç½®å (3Ã—2):\\n{matrix.T}\")\n",
    "print(f\"ä½¿ç”¨transpose():\\n{np.transpose(matrix)}\")\n",
    "\n",
    "# ç»´åº¦äº¤æ¢\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "print(f\"\\n3Dæ•°ç»„å½¢çŠ¶: {arr_3d.shape}\")\n",
    "swapped = np.transpose(arr_3d, (2, 0, 1))  # äº¤æ¢è½´\n",
    "print(f\"äº¤æ¢è½´åå½¢çŠ¶: {swapped.shape}\")\n",
    "\n",
    "print(\"\\n=== æ•°ç»„åˆå¹¶ ===\")\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"æ•°ç»„a:\\n{a}\")\n",
    "print(f\"æ•°ç»„b:\\n{b}\")\n",
    "\n",
    "# å‚ç›´åˆå¹¶\n",
    "v_concat = np.vstack((a, b))  # æˆ– np.concatenate((a, b), axis=0)\n",
    "print(f\"å‚ç›´åˆå¹¶:\\n{v_concat}\")\n",
    "\n",
    "# æ°´å¹³åˆå¹¶\n",
    "h_concat = np.hstack((a, b))  # æˆ– np.concatenate((a, b), axis=1)\n",
    "print(f\"æ°´å¹³åˆå¹¶:\\n{h_concat}\")\n",
    "\n",
    "# æ·±åº¦åˆå¹¶ï¼ˆæ²¿æ–°è½´ï¼‰\n",
    "d_concat = np.dstack((a, b))\n",
    "print(f\"æ·±åº¦åˆå¹¶å½¢çŠ¶: {d_concat.shape}\")\n",
    "\n",
    "print(\"\\n=== æ•°ç»„åˆ†å‰² ===\")\n",
    "large_array = np.arange(12).reshape(4, 3)\n",
    "print(f\"å¤§æ•°ç»„:\\n{large_array}\")\n",
    "\n",
    "# æ°´å¹³åˆ†å‰²\n",
    "h_splits = np.hsplit(large_array, 3)\n",
    "print(f\"æ°´å¹³åˆ†å‰²æˆ3éƒ¨åˆ†:\")\n",
    "for i, part in enumerate(h_splits):\n",
    "    print(f\"  éƒ¨åˆ†{i+1}:\\n{part}\")\n",
    "\n",
    "# å‚ç›´åˆ†å‰²\n",
    "v_splits = np.vsplit(large_array, 2)\n",
    "print(f\"å‚ç›´åˆ†å‰²æˆ2éƒ¨åˆ†:\")\n",
    "for i, part in enumerate(v_splits):\n",
    "    print(f\"  éƒ¨åˆ†{i+1}:\\n{part}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šå›¾åƒæ•°æ®å¤„ç† ===\")\n",
    "# æ¨¡æ‹ŸRGBå›¾åƒæ•°æ® (é«˜åº¦Ã—å®½åº¦Ã—é€šé“)\n",
    "np.random.seed(42)\n",
    "image = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)\n",
    "\n",
    "print(f\"åŸå§‹å›¾åƒå½¢çŠ¶: {image.shape}\")\n",
    "print(f\"å›¾åƒæ•°æ®ç±»å‹: {image.dtype}\")\n",
    "print(f\"åƒç´ å€¼èŒƒå›´: {image.min()} - {image.max()}\")\n",
    "\n",
    "# æå–å„é¢œè‰²é€šé“\n",
    "red_channel = image[:, :, 0]\n",
    "green_channel = image[:, :, 1]\n",
    "blue_channel = image[:, :, 2]\n",
    "\n",
    "print(f\"çº¢è‰²é€šé“å½¢çŠ¶: {red_channel.shape}\")\n",
    "print(f\"çº¢è‰²é€šé“å¹³å‡å€¼: {red_channel.mean():.1f}\")\n",
    "\n",
    "# è½¬æ¢ä¸ºç°åº¦å›¾åƒ\n",
    "grayscale = 0.299 * red_channel + 0.587 * green_channel + 0.114 * blue_channel\n",
    "print(f\"ç°åº¦å›¾åƒå½¢çŠ¶: {grayscale.shape}\")\n",
    "print(f\"ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {grayscale.dtype}\")\n",
    "\n",
    "# å›¾åƒæ‰¹å¤„ç†\n",
    "batch_size = 32\n",
    "reshaped_for_batch = image.reshape(-1, 3)  # å±•å¹³ä¸º (åƒç´ æ•°, 3)\n",
    "print(f\"æ‰¹å¤„ç†é‡å¡‘å½¢çŠ¶: {reshaped_for_batch.shape}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæœºå™¨å­¦ä¹ æ•°æ®å‡†å¤‡ ===\")\n",
    "# æ¨¡æ‹Ÿæ—¶é—´åºåˆ—æ•°æ®\n",
    "time_series = np.random.randn(1000)  # 1000ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®\n",
    "\n",
    "# åˆ›å»ºæ»‘åŠ¨çª—å£ç”¨äºLSTMè¾“å…¥\n",
    "window_size = 10\n",
    "n_windows = len(time_series) - window_size + 1\n",
    "\n",
    "# ä½¿ç”¨å¹¿æ’­åˆ›å»ºçª—å£\n",
    "windows = np.array([time_series[i:i+window_size] for i in range(n_windows)])\n",
    "print(f\"æ—¶é—´åºåˆ—é•¿åº¦: {len(time_series)}\")\n",
    "print(f\"æ»‘åŠ¨çª—å£å½¢çŠ¶: {windows.shape}\")\n",
    "print(f\"çª—å£ç¤ºä¾‹:\\n{windows[:3]}\")\n",
    "\n",
    "# å‡†å¤‡è®­ç»ƒæ•°æ®\n",
    "X = windows[:-1]  # ç‰¹å¾\n",
    "y = windows[1:, -1]  # æ ‡ç­¾ï¼ˆä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹çš„å€¼ï¼‰\n",
    "print(f\"ç‰¹å¾Xå½¢çŠ¶: {X.shape}\")\n",
    "print(f\"æ ‡ç­¾yå½¢çŠ¶: {y.shape}\")\n",
    "\n",
    "# æ•°æ®æ ‡å‡†åŒ–\n",
    "X_mean = np.mean(X)\n",
    "X_std = np.std(X)\n",
    "X_normalized = (X - X_mean) / X_std\n",
    "print(f\"æ ‡å‡†åŒ–åå‡å€¼: {np.mean(X_normalized):.6f}\")\n",
    "print(f\"æ ‡å‡†åŒ–åæ ‡å‡†å·®: {np.std(X_normalized):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a15b88",
   "metadata": {},
   "source": [
    "## 6. çº¿æ€§ä»£æ•°æ“ä½œ\n",
    "\n",
    "çº¿æ€§ä»£æ•°æ˜¯æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€ï¼ŒNumPyæä¾›äº†å®Œæ•´çš„çº¿æ€§ä»£æ•°åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1539ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çŸ©é˜µè¿ç®—åŸºç¡€\n",
    "print(\"=== çŸ©é˜µè¿ç®—åŸºç¡€ ===\")\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "B = np.array([[7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "\n",
    "print(f\"çŸ©é˜µA (2Ã—3):\\n{A}\")\n",
    "print(f\"çŸ©é˜µB (3Ã—2):\\n{B}\")\n",
    "\n",
    "# çŸ©é˜µä¹˜æ³•\n",
    "C = np.dot(A, B)  # æˆ– A @ B\n",
    "print(f\"çŸ©é˜µä¹˜æ³• A @ B (2Ã—2):\\n{C}\")\n",
    "\n",
    "# å…ƒç´ ä¹˜æ³• vs çŸ©é˜µä¹˜æ³•\n",
    "square_A = np.array([[1, 2], [3, 4]])\n",
    "square_B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"\\næ­£æ–¹çŸ©é˜µA:\\n{square_A}\")\n",
    "print(f\"æ­£æ–¹çŸ©é˜µB:\\n{square_B}\")\n",
    "print(f\"å…ƒç´ çº§ä¹˜æ³• A * B:\\n{square_A * square_B}\")\n",
    "print(f\"çŸ©é˜µä¹˜æ³• A @ B:\\n{square_A @ square_B}\")\n",
    "\n",
    "print(\"\\n=== ç‰¹æ®ŠçŸ©é˜µæ“ä½œ ===\")\n",
    "# çŸ©é˜µçš„é€†\n",
    "matrix = np.array([[4, 2], [3, 1]], dtype=float)\n",
    "print(f\"åŸçŸ©é˜µ:\\n{matrix}\")\n",
    "\n",
    "try:\n",
    "    inverse = np.linalg.inv(matrix)\n",
    "    print(f\"é€†çŸ©é˜µ:\\n{inverse}\")\n",
    "    \n",
    "    # éªŒè¯ A * A^(-1) = I\n",
    "    identity_check = matrix @ inverse\n",
    "    print(f\"éªŒè¯ A @ A^(-1):\\n{identity_check}\")\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"çŸ©é˜µä¸å¯é€†\")\n",
    "\n",
    "# è¡Œåˆ—å¼\n",
    "det = np.linalg.det(matrix)\n",
    "print(f\"è¡Œåˆ—å¼: {det:.4f}\")\n",
    "\n",
    "# ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡\n",
    "print(\"\\n=== ç‰¹å¾å€¼åˆ†è§£ ===\")\n",
    "symmetric_matrix = np.array([[3, 1], [1, 3]], dtype=float)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(symmetric_matrix)\n",
    "\n",
    "print(f\"å¯¹ç§°çŸ©é˜µ:\\n{symmetric_matrix}\")\n",
    "print(f\"ç‰¹å¾å€¼: {eigenvalues}\")\n",
    "print(f\"ç‰¹å¾å‘é‡:\\n{eigenvectors}\")\n",
    "\n",
    "# éªŒè¯ç‰¹å¾å€¼åˆ†è§£\n",
    "for i in range(len(eigenvalues)):\n",
    "    lambda_i = eigenvalues[i]\n",
    "    v_i = eigenvectors[:, i]\n",
    "    Av = symmetric_matrix @ v_i\n",
    "    lambda_v = lambda_i * v_i\n",
    "    print(f\"éªŒè¯ç‰¹å¾å€¼{i+1}: A*v â‰ˆ Î»*v ? {np.allclose(Av, lambda_v)}\")\n",
    "\n",
    "print(\"\\n=== å¥‡å¼‚å€¼åˆ†è§£ (SVD) ===\")\n",
    "# SVDåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨\n",
    "data_matrix = np.random.randn(5, 4)\n",
    "U, s, Vt = np.linalg.svd(data_matrix, full_matrices=False)\n",
    "\n",
    "print(f\"åŸçŸ©é˜µå½¢çŠ¶: {data_matrix.shape}\")\n",
    "print(f\"UçŸ©é˜µå½¢çŠ¶: {U.shape}\")\n",
    "print(f\"å¥‡å¼‚å€¼: {s}\")\n",
    "print(f\"V^TçŸ©é˜µå½¢çŠ¶: {Vt.shape}\")\n",
    "\n",
    "# é‡æ„çŸ©é˜µ\n",
    "reconstructed = U @ np.diag(s) @ Vt\n",
    "print(f\"é‡æ„è¯¯å·®: {np.allclose(data_matrix, reconstructed)}\")\n",
    "\n",
    "# é™ç»´åº”ç”¨\n",
    "k = 2  # ä¿ç•™å‰2ä¸ªä¸»æˆåˆ†\n",
    "U_k = U[:, :k]\n",
    "s_k = s[:k]\n",
    "Vt_k = Vt[:k, :]\n",
    "compressed = U_k @ np.diag(s_k) @ Vt_k\n",
    "\n",
    "print(f\"å‹ç¼©åå½¢çŠ¶: {compressed.shape}\")\n",
    "compression_error = np.linalg.norm(data_matrix - compressed)\n",
    "print(f\"å‹ç¼©è¯¯å·®: {compression_error:.4f}\")\n",
    "\n",
    "print(\"\\n=== çº¿æ€§æ–¹ç¨‹ç»„æ±‚è§£ ===\")\n",
    "# æ±‚è§£ Ax = b\n",
    "A_eq = np.array([[2, 1, -1],\n",
    "                 [-3, -1, 2],\n",
    "                 [-2, 1, 2]], dtype=float)\n",
    "b_eq = np.array([8, -11, -3], dtype=float)\n",
    "\n",
    "print(f\"ç³»æ•°çŸ©é˜µA:\\n{A_eq}\")\n",
    "print(f\"å¸¸æ•°å‘é‡b: {b_eq}\")\n",
    "\n",
    "# æ±‚è§£\n",
    "x_solution = np.linalg.solve(A_eq, b_eq)\n",
    "print(f\"è§£å‘é‡x: {x_solution}\")\n",
    "\n",
    "# éªŒè¯è§£\n",
    "verification = A_eq @ x_solution\n",
    "print(f\"éªŒè¯ Ax: {verification}\")\n",
    "print(f\"è¯¯å·®: {np.allclose(verification, b_eq)}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šçº¿æ€§å›å½’ ===\")\n",
    "# ä½¿ç”¨æ­£è§„æ–¹ç¨‹æ±‚è§£çº¿æ€§å›å½’\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®\n",
    "n_samples = 100\n",
    "X_features = np.random.randn(n_samples, 2)\n",
    "true_coefficients = np.array([3, -2])\n",
    "true_intercept = 1\n",
    "noise = np.random.randn(n_samples) * 0.1\n",
    "\n",
    "y_target = X_features @ true_coefficients + true_intercept + noise\n",
    "\n",
    "# æ·»åŠ åç½®é¡¹ï¼ˆæˆªè·ï¼‰\n",
    "X_with_bias = np.column_stack([np.ones(n_samples), X_features])\n",
    "\n",
    "print(f\"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X_with_bias.shape}\")\n",
    "print(f\"ç›®æ ‡å‘é‡å½¢çŠ¶: {y_target.shape}\")\n",
    "print(f\"çœŸå®å‚æ•°: æˆªè·={true_intercept}, ç³»æ•°={true_coefficients}\")\n",
    "\n",
    "# ä½¿ç”¨æ­£è§„æ–¹ç¨‹: Î¸ = (X^T X)^(-1) X^T y\n",
    "theta = np.linalg.inv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y_target\n",
    "\n",
    "print(f\"ä¼°è®¡å‚æ•°: æˆªè·={theta[0]:.3f}, ç³»æ•°=[{theta[1]:.3f}, {theta[2]:.3f}]\")\n",
    "\n",
    "# è®¡ç®—é¢„æµ‹å’Œè¯¯å·®\n",
    "y_pred = X_with_bias @ theta\n",
    "mse = np.mean((y_target - y_pred) ** 2)\n",
    "r_squared = 1 - np.sum((y_target - y_pred) ** 2) / np.sum((y_target - np.mean(y_target)) ** 2)\n",
    "\n",
    "print(f\"å‡æ–¹è¯¯å·®: {mse:.6f}\")\n",
    "print(f\"RÂ²åˆ†æ•°: {r_squared:.6f}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šä¸»æˆåˆ†åˆ†æ (PCA) ===\")\n",
    "# ç®€å•çš„PCAå®ç°\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç”Ÿæˆ2Dæ•°æ®\n",
    "mean = [0, 0]\n",
    "cov = [[2, 1.5], [1.5, 2]]\n",
    "data_2d = np.random.multivariate_normal(mean, cov, 200)\n",
    "\n",
    "print(f\"åŸå§‹æ•°æ®å½¢çŠ¶: {data_2d.shape}\")\n",
    "print(f\"åŸå§‹æ•°æ®å‡å€¼: {np.mean(data_2d, axis=0)}\")\n",
    "print(f\"åŸå§‹æ•°æ®åæ–¹å·®:\\n{np.cov(data_2d.T)}\")\n",
    "\n",
    "# ä¸­å¿ƒåŒ–æ•°æ®\n",
    "data_centered = data_2d - np.mean(data_2d, axis=0)\n",
    "\n",
    "# è®¡ç®—åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡\n",
    "cov_matrix = np.cov(data_centered.T)\n",
    "eigenvalues_pca, eigenvectors_pca = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# æŒ‰ç‰¹å¾å€¼å¤§å°æ’åº\n",
    "sorted_indices = np.argsort(eigenvalues_pca)[::-1]\n",
    "eigenvalues_pca = eigenvalues_pca[sorted_indices]\n",
    "eigenvectors_pca = eigenvectors_pca[:, sorted_indices]\n",
    "\n",
    "print(f\"ä¸»æˆåˆ†æ–¹å·®: {eigenvalues_pca}\")\n",
    "print(f\"æ–¹å·®è§£é‡Šæ¯”ä¾‹: {eigenvalues_pca / np.sum(eigenvalues_pca)}\")\n",
    "print(f\"ä¸»æˆåˆ†æ–¹å‘:\\n{eigenvectors_pca}\")\n",
    "\n",
    "# æŠ•å½±åˆ°ä¸»æˆåˆ†\n",
    "data_pca = data_centered @ eigenvectors_pca\n",
    "print(f\"PCAå˜æ¢åå½¢çŠ¶: {data_pca.shape}\")\n",
    "print(f\"ç¬¬ä¸€ä¸»æˆåˆ†æ–¹å·®: {np.var(data_pca[:, 0]):.4f}\")\n",
    "print(f\"ç¬¬äºŒä¸»æˆåˆ†æ–¹å·®: {np.var(data_pca[:, 1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5109c",
   "metadata": {},
   "source": [
    "## 7. é«˜çº§NumPyç‰¹æ€§\n",
    "\n",
    "è¿™ä¸€éƒ¨åˆ†ä»‹ç»NumPyçš„ä¸€äº›é«˜çº§ç‰¹æ€§ï¼Œåœ¨å¤æ‚çš„æ•°æ®å¤„ç†å’Œæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­éå¸¸æœ‰ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šä¹‰å‡½æ•°å‘é‡åŒ–\n",
    "print(\"=== å‡½æ•°å‘é‡åŒ– ===\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoidæ¿€æ´»å‡½æ•°\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # é˜²æ­¢æº¢å‡º\n",
    "\n",
    "# å‘é‡åŒ–å‡½æ•°\n",
    "vectorized_sigmoid = np.vectorize(sigmoid)\n",
    "\n",
    "# æµ‹è¯•å•ä¸ªå€¼å’Œæ•°ç»„\n",
    "x_single = 2.0\n",
    "x_array = np.array([-2, -1, 0, 1, 2])\n",
    "\n",
    "print(f\"å•ä¸ªå€¼: sigmoid({x_single}) = {sigmoid(x_single):.4f}\")\n",
    "print(f\"æ•°ç»„: sigmoid({x_array}) = {vectorized_sigmoid(x_array)}\")\n",
    "\n",
    "# æ€§èƒ½æ¯”è¾ƒï¼šå‘é‡åŒ– vs å¾ªç¯\n",
    "large_array = np.random.randn(10000)\n",
    "\n",
    "# ä½¿ç”¨å‘é‡åŒ–å‡½æ•°\n",
    "start_time = time.time()\n",
    "result_vectorized = vectorized_sigmoid(large_array)\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "# ä½¿ç”¨Pythonå¾ªç¯\n",
    "start_time = time.time()\n",
    "result_loop = [sigmoid(x) for x in large_array]\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\næ€§èƒ½å¯¹æ¯” (10000ä¸ªå…ƒç´ ):\")\n",
    "print(f\"å‘é‡åŒ–æ—¶é—´: {vectorized_time:.6f}ç§’\")\n",
    "print(f\"å¾ªç¯æ—¶é—´: {loop_time:.6f}ç§’\")\n",
    "print(f\"å‘é‡åŒ–å¿«äº†: {loop_time/vectorized_time:.1f}å€\")\n",
    "\n",
    "print(\"\\n=== é€šç”¨å‡½æ•° (ufunc) ===\")\n",
    "# åˆ›å»ºè‡ªå®šä¹‰ufunc\n",
    "@np.vectorize\n",
    "def relu(x):\n",
    "    \"\"\"ReLUæ¿€æ´»å‡½æ•°\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "@np.vectorize\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Leaky ReLUæ¿€æ´»å‡½æ•°\"\"\"\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "test_array = np.array([-2, -1, 0, 1, 2])\n",
    "print(f\"è¾“å…¥: {test_array}\")\n",
    "print(f\"ReLU: {relu(test_array)}\")\n",
    "print(f\"Leaky ReLU: {leaky_relu(test_array)}\")\n",
    "\n",
    "print(\"\\n=== å†…å­˜è§†å›¾å’Œæ‹·è´ ===\")\n",
    "original = np.arange(12).reshape(3, 4)\n",
    "print(f\"åŸå§‹æ•°ç»„:\\n{original}\")\n",
    "\n",
    "# è§†å›¾ (view) - å…±äº«å†…å­˜\n",
    "view = original[1:, 1:]\n",
    "print(f\"è§†å›¾:\\n{view}\")\n",
    "\n",
    "# ä¿®æ”¹è§†å›¾\n",
    "view[0, 0] = 999\n",
    "print(f\"ä¿®æ”¹è§†å›¾åçš„åŸæ•°ç»„:\\n{original}\")\n",
    "\n",
    "# æ‹·è´ (copy) - ç‹¬ç«‹å†…å­˜\n",
    "original[1, 1] = 5  # æ¢å¤\n",
    "copy = original[1:, 1:].copy()\n",
    "copy[0, 0] = 888\n",
    "print(f\"ä¿®æ”¹æ‹·è´åçš„åŸæ•°ç»„:\\n{original}\")\n",
    "print(f\"æ‹·è´:\\n{copy}\")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦å…±äº«å†…å­˜\n",
    "print(f\"viewä¸åŸæ•°ç»„å…±äº«å†…å­˜: {np.shares_memory(original, view)}\")\n",
    "print(f\"copyä¸åŸæ•°ç»„å…±äº«å†…å­˜: {np.shares_memory(original, copy)}\")\n",
    "\n",
    "print(\"\\n=== ç»“æ„åŒ–æ•°ç»„ ===\")\n",
    "# å®šä¹‰å¤åˆæ•°æ®ç±»å‹\n",
    "student_dtype = np.dtype([\n",
    "    ('name', 'U20'),      # 20å­—ç¬¦çš„Unicodeå­—ç¬¦ä¸²\n",
    "    ('age', 'i4'),        # 32ä½æ•´æ•°\n",
    "    ('grade', 'f4'),      # 32ä½æµ®ç‚¹æ•°\n",
    "    ('passed', '?')       # å¸ƒå°”å€¼\n",
    "])\n",
    "\n",
    "# åˆ›å»ºç»“æ„åŒ–æ•°ç»„\n",
    "students = np.array([\n",
    "    ('Alice', 20, 85.5, True),\n",
    "    ('Bob', 19, 72.3, True),\n",
    "    ('Charlie', 21, 58.7, False),\n",
    "    ('Diana', 20, 91.2, True)\n",
    "], dtype=student_dtype)\n",
    "\n",
    "print(f\"å­¦ç”Ÿæ•°æ®:\\n{students}\")\n",
    "print(f\"æ‰€æœ‰å§“å: {students['name']}\")\n",
    "print(f\"æ‰€æœ‰æˆç»©: {students['grade']}\")\n",
    "print(f\"åŠæ ¼å­¦ç”Ÿ: {students[students['passed']]['name']}\")\n",
    "print(f\"å¹³å‡æˆç»©: {np.mean(students['grade']):.2f}\")\n",
    "\n",
    "print(\"\\n=== æ©ç æ•°ç»„ ===\")\n",
    "# å¤„ç†ç¼ºå¤±æ•°æ®\n",
    "data_with_missing = np.array([1.0, 2.0, np.nan, 4.0, 5.0, np.nan, 7.0])\n",
    "print(f\"å«ç¼ºå¤±å€¼çš„æ•°æ®: {data_with_missing}\")\n",
    "\n",
    "# åˆ›å»ºæ©ç \n",
    "mask = np.isnan(data_with_missing)\n",
    "masked_array = np.ma.masked_array(data_with_missing, mask=mask)\n",
    "\n",
    "print(f\"æ©ç : {mask}\")\n",
    "print(f\"æ©ç æ•°ç»„: {masked_array}\")\n",
    "print(f\"æœ‰æ•ˆæ•°æ®å‡å€¼: {np.ma.mean(masked_array):.2f}\")\n",
    "print(f\"æœ‰æ•ˆæ•°æ®æ•°é‡: {np.ma.count(masked_array)}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šå›¾åƒå¤„ç† ===\")\n",
    "# åˆ›å»ºç®€å•çš„å›¾åƒæ»¤æ³¢å™¨\n",
    "def apply_filter(image, kernel):\n",
    "    \"\"\"åº”ç”¨å·ç§¯æ»¤æ³¢å™¨\"\"\"\n",
    "    from scipy import ndimage  # å®é™…é¡¹ç›®ä¸­ä¼šä½¿ç”¨scipy\n",
    "    # è¿™é‡Œç”¨ç®€å•çš„å®ç°ç¤ºæ„\n",
    "    h, w = image.shape\n",
    "    kh, kw = kernel.shape\n",
    "    \n",
    "    # ç®€åŒ–ç‰ˆå·ç§¯ï¼ˆä¸åŒ…å«è¾¹ç•Œå¤„ç†ï¼‰\n",
    "    result = np.zeros_like(image)\n",
    "    for i in range(kh//2, h - kh//2):\n",
    "        for j in range(kw//2, w - kw//2):\n",
    "            result[i, j] = np.sum(image[i-kh//2:i+kh//2+1, j-kw//2:j+kw//2+1] * kernel)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•å›¾åƒ\n",
    "test_image = np.random.randint(0, 256, (10, 10), dtype=np.uint8)\n",
    "\n",
    "# è¾¹ç¼˜æ£€æµ‹æ»¤æ³¢å™¨\n",
    "edge_kernel = np.array([[-1, -1, -1],\n",
    "                        [-1,  8, -1],\n",
    "                        [-1, -1, -1]])\n",
    "\n",
    "# æ¨¡ç³Šæ»¤æ³¢å™¨\n",
    "blur_kernel = np.ones((3, 3)) / 9\n",
    "\n",
    "print(f\"åŸå§‹å›¾åƒ (10x10):\\n{test_image}\")\n",
    "print(f\"è¾¹ç¼˜æ£€æµ‹æ ¸:\\n{edge_kernel}\")\n",
    "print(f\"åº”ç”¨æ»¤æ³¢å™¨åçš„ç»“æœå½¢çŠ¶: {apply_filter(test_image.astype(float), edge_kernel).shape}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæ•°æ®åˆ†ç®± ===\")\n",
    "# å°†è¿ç»­æ•°æ®åˆ†ç®±\n",
    "np.random.seed(42)\n",
    "ages = np.random.normal(35, 10, 1000)\n",
    "ages = np.clip(ages, 18, 65)  # é™åˆ¶åœ¨åˆç†èŒƒå›´\n",
    "\n",
    "# å®šä¹‰åˆ†ç®±è¾¹ç•Œ\n",
    "bins = np.array([18, 25, 35, 45, 55, 65])\n",
    "bin_labels = ['18-25', '25-35', '35-45', '45-55', '55-65']\n",
    "\n",
    "# ä½¿ç”¨digitizeè¿›è¡Œåˆ†ç®±\n",
    "bin_indices = np.digitize(ages, bins) - 1\n",
    "bin_indices = np.clip(bin_indices, 0, len(bin_labels) - 1)\n",
    "\n",
    "print(f\"å¹´é¾„èŒƒå›´: {ages.min():.1f} - {ages.max():.1f}\")\n",
    "print(f\"åˆ†ç®±ç»Ÿè®¡:\")\n",
    "for i, label in enumerate(bin_labels):\n",
    "    count = np.sum(bin_indices == i)\n",
    "    percentage = count / len(ages) * 100\n",
    "    print(f\"  {label}: {count}äºº ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæ—¶é—´åºåˆ—æ»‘åŠ¨çª—å£ ===\")\n",
    "# é«˜æ•ˆåˆ›å»ºæ»‘åŠ¨çª—å£\n",
    "def sliding_window_view(arr, window_shape):\n",
    "    \"\"\"åˆ›å»ºæ»‘åŠ¨çª—å£è§†å›¾\"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    window_shape = np.asarray(window_shape)\n",
    "    \n",
    "    if arr.ndim != 1:\n",
    "        raise ValueError(\"ä»…æ”¯æŒä¸€ç»´æ•°ç»„\")\n",
    "    \n",
    "    n = arr.shape[0]\n",
    "    w = window_shape[0]\n",
    "    \n",
    "    if w > n:\n",
    "        raise ValueError(\"çª—å£å¤§å°ä¸èƒ½å¤§äºæ•°ç»„é•¿åº¦\")\n",
    "    \n",
    "    # ä½¿ç”¨strideæŠ€å·§åˆ›å»ºè§†å›¾\n",
    "    shape = (n - w + 1, w)\n",
    "    strides = (arr.strides[0], arr.strides[0])\n",
    "    \n",
    "    return np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "# æµ‹è¯•æ»‘åŠ¨çª—å£\n",
    "time_series = np.arange(10)\n",
    "window_size = 3\n",
    "\n",
    "windowed = sliding_window_view(time_series, (window_size,))\n",
    "print(f\"æ—¶é—´åºåˆ—: {time_series}\")\n",
    "print(f\"æ»‘åŠ¨çª—å£ (çª—å£å¤§å°={window_size}):\\n{windowed}\")\n",
    "\n",
    "# è®¡ç®—æ»‘åŠ¨ç»Ÿè®¡\n",
    "rolling_mean = np.mean(windowed, axis=1)\n",
    "rolling_std = np.std(windowed, axis=1)\n",
    "\n",
    "print(f\"æ»‘åŠ¨å¹³å‡: {rolling_mean}\")\n",
    "print(f\"æ»‘åŠ¨æ ‡å‡†å·®: {rolling_std}\")\n",
    "\n",
    "# æ£€æŸ¥å†…å­˜æ•ˆç‡\n",
    "print(f\"åŸæ•°ç»„å†…å­˜: {time_series.nbytes} bytes\")\n",
    "print(f\"çª—å£è§†å›¾å†…å­˜: {windowed.nbytes} bytes\")\n",
    "print(f\"å…±äº«å†…å­˜: {np.shares_memory(time_series, windowed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16958e3e",
   "metadata": {},
   "source": [
    "## 8. éšæœºæ•°ç”Ÿæˆå’Œè’™ç‰¹å¡æ´›æ–¹æ³•\n",
    "\n",
    "éšæœºæ•°ç”Ÿæˆåœ¨æœºå™¨å­¦ä¹ ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œç”¨äºæ•°æ®é‡‡æ ·ã€å‚æ•°åˆå§‹åŒ–ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fcf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæœºæ•°ç”ŸæˆåŸºç¡€\n",
    "print(\"=== åŸºæœ¬éšæœºæ•°ç”Ÿæˆ ===\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§\n",
    "np.random.seed(42)\n",
    "\n",
    "# å„ç§åˆ†å¸ƒçš„éšæœºæ•°\n",
    "uniform_random = np.random.uniform(0, 1, 10)  # å‡åŒ€åˆ†å¸ƒ\n",
    "normal_random = np.random.normal(0, 1, 10)    # æ ‡å‡†æ­£æ€åˆ†å¸ƒ\n",
    "integers = np.random.randint(1, 7, 10)        # æ•´æ•°ï¼ˆæ¨¡æ‹Ÿéª°å­ï¼‰\n",
    "\n",
    "print(f\"å‡åŒ€åˆ†å¸ƒ [0,1): {uniform_random}\")\n",
    "print(f\"æ ‡å‡†æ­£æ€åˆ†å¸ƒ: {normal_random}\")\n",
    "print(f\"éª°å­ç»“æœ: {integers}\")\n",
    "\n",
    "# å¸¸ç”¨åˆ†å¸ƒ\n",
    "print(\"\\n=== å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ ===\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# äºŒé¡¹åˆ†å¸ƒ - æŠ•ç¡¬å¸\n",
    "coin_flips = np.random.binomial(n=10, p=0.5, size=1000)  # 10æ¬¡æŠ•ç¡¬å¸ï¼Œé‡å¤1000æ¬¡\n",
    "print(f\"10æ¬¡æŠ•ç¡¬å¸æ­£é¢æœä¸Šæ¬¡æ•° (1000æ¬¡å®éªŒ):\")\n",
    "print(f\"å¹³å‡å€¼: {np.mean(coin_flips):.2f} (ç†è®ºå€¼: 5.0)\")\n",
    "print(f\"æ ‡å‡†å·®: {np.std(coin_flips):.2f} (ç†è®ºå€¼: {np.sqrt(10*0.5*0.5):.2f})\")\n",
    "\n",
    "# æ³Šæ¾åˆ†å¸ƒ - äº‹ä»¶å‘ç”Ÿæ¬¡æ•°\n",
    "website_visits = np.random.poisson(lam=50, size=365)  # ç½‘ç«™æ—¥è®¿é—®é‡\n",
    "print(f\"\\nç½‘ç«™å¹´åº¦è®¿é—®é‡ç»Ÿè®¡:\")\n",
    "print(f\"å¹³å‡æ—¥è®¿é—®é‡: {np.mean(website_visits):.1f}\")\n",
    "print(f\"æœ€é«˜æ—¥è®¿é—®é‡: {np.max(website_visits)}\")\n",
    "print(f\"è®¿é—®é‡>60çš„å¤©æ•°: {np.sum(website_visits > 60)}\")\n",
    "\n",
    "# æŒ‡æ•°åˆ†å¸ƒ - ç­‰å¾…æ—¶é—´\n",
    "wait_times = np.random.exponential(scale=5, size=1000)  # å¹³å‡ç­‰å¾…5åˆ†é’Ÿ\n",
    "print(f\"\\nå®¢æœç­‰å¾…æ—¶é—´åˆ†æ:\")\n",
    "print(f\"å¹³å‡ç­‰å¾…æ—¶é—´: {np.mean(wait_times):.2f}åˆ†é’Ÿ\")\n",
    "print(f\"ç­‰å¾…è¶…è¿‡10åˆ†é’Ÿçš„æ¦‚ç‡: {np.mean(wait_times > 10):.2%}\")\n",
    "\n",
    "print(\"\\n=== æ•°æ®é‡‡æ · ===\")\n",
    "# ä»æ•°ç»„ä¸­éšæœºé‡‡æ ·\n",
    "population = np.arange(1, 101)  # 1åˆ°100çš„æ•°å­—\n",
    "sample = np.random.choice(population, size=20, replace=False)  # æ— æ”¾å›é‡‡æ ·\n",
    "print(f\"ä»1-100ä¸­éšæœºé€‰æ‹©20ä¸ªæ•°: {np.sort(sample)}\")\n",
    "\n",
    "# åŠ æƒé‡‡æ ·\n",
    "products = ['A', 'B', 'C', 'D']\n",
    "weights = [0.1, 0.3, 0.4, 0.2]  # äº§å“é”€é‡æƒé‡\n",
    "sales_sample = np.random.choice(products, size=1000, p=weights)\n",
    "print(f\"\\näº§å“é”€é‡æ¨¡æ‹Ÿ (1000æ¬¡):\")\n",
    "for product in products:\n",
    "    count = np.sum(sales_sample == product)\n",
    "    print(f\"äº§å“{product}: {count}æ¬¡ ({count/1000:.1%})\")\n",
    "\n",
    "# éšæœºæ’åˆ—\n",
    "deck = np.arange(52)  # æ‰‘å…‹ç‰Œ\n",
    "shuffled_deck = np.random.permutation(deck)\n",
    "print(f\"\\næ´—ç‰Œå‰5å¼ : {deck[:5]}\")\n",
    "print(f\"æ´—ç‰Œå5å¼ : {shuffled_deck[:5]}\")\n",
    "\n",
    "print(\"\\n=== è’™ç‰¹å¡æ´›æ–¹æ³•ï¼šä¼°ç®—Ï€ ===\")\n",
    "def estimate_pi(n_points):\n",
    "    \"\"\"ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¼°ç®—Ï€\"\"\"\n",
    "    # åœ¨å•ä½æ­£æ–¹å½¢å†…éšæœºç”Ÿæˆç‚¹\n",
    "    points = np.random.uniform(-1, 1, (n_points, 2))\n",
    "    \n",
    "    # è®¡ç®—ç‚¹åˆ°åŸç‚¹çš„è·ç¦»\n",
    "    distances = np.sqrt(np.sum(points**2, axis=1))\n",
    "    \n",
    "    # ç»Ÿè®¡è½åœ¨å•ä½åœ†å†…çš„ç‚¹\n",
    "    inside_circle = np.sum(distances <= 1)\n",
    "    \n",
    "    # Ï€ â‰ˆ 4 * (åœ†å†…ç‚¹æ•° / æ€»ç‚¹æ•°)\n",
    "    pi_estimate = 4 * inside_circle / n_points\n",
    "    \n",
    "    return pi_estimate, inside_circle\n",
    "\n",
    "# ä¸åŒæ ·æœ¬é‡ä¸‹çš„ä¼°ç®—\n",
    "sample_sizes = [1000, 10000, 100000, 1000000]\n",
    "print(\"è’™ç‰¹å¡æ´›ä¼°ç®—Ï€:\")\n",
    "for n in sample_sizes:\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡ç°\n",
    "    pi_est, inside = estimate_pi(n)\n",
    "    error = abs(pi_est - np.pi)\n",
    "    print(f\"æ ·æœ¬æ•°: {n:7,}, Ï€ä¼°ç®—: {pi_est:.6f}, è¯¯å·®: {error:.6f}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šA/Bæµ‹è¯•åˆ†æ ===\")\n",
    "# æ¨¡æ‹ŸA/Bæµ‹è¯•æ•°æ®\n",
    "np.random.seed(42)\n",
    "\n",
    "# å¯¹ç…§ç»„Aå’Œå®éªŒç»„Bçš„è½¬åŒ–ç‡\n",
    "true_rate_A = 0.12  # Aç»„çœŸå®è½¬åŒ–ç‡12%\n",
    "true_rate_B = 0.15  # Bç»„çœŸå®è½¬åŒ–ç‡15%\n",
    "\n",
    "n_users_A = 1000\n",
    "n_users_B = 1000\n",
    "\n",
    "# ç”Ÿæˆè½¬åŒ–æ•°æ® (1=è½¬åŒ–, 0=æœªè½¬åŒ–)\n",
    "conversions_A = np.random.binomial(1, true_rate_A, n_users_A)\n",
    "conversions_B = np.random.binomial(1, true_rate_B, n_users_B)\n",
    "\n",
    "# è®¡ç®—è§‚æµ‹è½¬åŒ–ç‡\n",
    "observed_rate_A = np.mean(conversions_A)\n",
    "observed_rate_B = np.mean(conversions_B)\n",
    "improvement = (observed_rate_B - observed_rate_A) / observed_rate_A\n",
    "\n",
    "print(f\"A/Bæµ‹è¯•ç»“æœ:\")\n",
    "print(f\"å¯¹ç…§ç»„A: {np.sum(conversions_A)}/{n_users_A} = {observed_rate_A:.3f}\")\n",
    "print(f\"å®éªŒç»„B: {np.sum(conversions_B)}/{n_users_B} = {observed_rate_B:.3f}\")\n",
    "print(f\"ç›¸å¯¹æå‡: {improvement:.1%}\")\n",
    "\n",
    "# ç®€å•çš„ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ (z-test)\n",
    "pooled_rate = (np.sum(conversions_A) + np.sum(conversions_B)) / (n_users_A + n_users_B)\n",
    "se = np.sqrt(pooled_rate * (1 - pooled_rate) * (1/n_users_A + 1/n_users_B))\n",
    "z_score = (observed_rate_B - observed_rate_A) / se\n",
    "\n",
    "print(f\"Zåˆ†æ•°: {z_score:.3f}\")\n",
    "print(f\"æ˜¾è‘—æ€§: {'æ˜¾è‘—' if abs(z_score) > 1.96 else 'ä¸æ˜¾è‘—'} (95%ç½®ä¿¡åº¦)\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šé‡‘èé£é™©æ¨¡æ‹Ÿ ===\")\n",
    "# æ¨¡æ‹Ÿè‚¡ç¥¨ä»·æ ¼éšæœºæ¸¸èµ°\n",
    "np.random.seed(42)\n",
    "\n",
    "# å‚æ•°è®¾ç½®\n",
    "initial_price = 100\n",
    "daily_volatility = 0.02  # æ—¥æ³¢åŠ¨ç‡2%\n",
    "n_days = 252  # ä¸€å¹´äº¤æ˜“æ—¥\n",
    "n_simulations = 1000\n",
    "\n",
    "# ç”Ÿæˆéšæœºæ”¶ç›Šç‡ (æ­£æ€åˆ†å¸ƒ)\n",
    "daily_returns = np.random.normal(0, daily_volatility, (n_simulations, n_days))\n",
    "\n",
    "# è®¡ç®—ç´¯ç§¯æ”¶ç›Šç‡\n",
    "cumulative_returns = np.cumprod(1 + daily_returns, axis=1)\n",
    "\n",
    "# è®¡ç®—æœ€ç»ˆä»·æ ¼\n",
    "final_prices = initial_price * cumulative_returns[:, -1]\n",
    "\n",
    "print(f\"è‚¡ç¥¨ä»·æ ¼æ¨¡æ‹Ÿ ({n_simulations}æ¬¡æ¨¡æ‹Ÿ, {n_days}å¤©):\")\n",
    "print(f\"åˆå§‹ä»·æ ¼: ${initial_price}\")\n",
    "print(f\"å¹³å‡æœ€ç»ˆä»·æ ¼: ${np.mean(final_prices):.2f}\")\n",
    "print(f\"ä»·æ ¼ä¸­ä½æ•°: ${np.median(final_prices):.2f}\")\n",
    "print(f\"æœ€é«˜ä»·æ ¼: ${np.max(final_prices):.2f}\")\n",
    "print(f\"æœ€ä½ä»·æ ¼: ${np.min(final_prices):.2f}\")\n",
    "\n",
    "# é£é™©æŒ‡æ ‡\n",
    "returns_1year = (final_prices - initial_price) / initial_price\n",
    "var_95 = np.percentile(returns_1year, 5)  # 5%åˆ†ä½æ•°\n",
    "var_99 = np.percentile(returns_1year, 1)  # 1%åˆ†ä½æ•°\n",
    "\n",
    "print(f\"\\né£é™©åˆ†æ:\")\n",
    "print(f\"å¹³å‡å¹´æ”¶ç›Šç‡: {np.mean(returns_1year):.1%}\")\n",
    "print(f\"æ”¶ç›Šç‡æ ‡å‡†å·®: {np.std(returns_1year):.1%}\")\n",
    "print(f\"VaR (95%): {var_95:.1%} (95%æ¦‚ç‡ä¸‹æœ€å¤§æŸå¤±)\")\n",
    "print(f\"VaR (99%): {var_99:.1%} (99%æ¦‚ç‡ä¸‹æœ€å¤§æŸå¤±)\")\n",
    "print(f\"ç›ˆåˆ©æ¦‚ç‡: {np.mean(returns_1year > 0):.1%}\")\n",
    "\n",
    "print(\"\\n=== å®é™…åº”ç”¨ï¼šæœºå™¨å­¦ä¹ æ•°æ®å¢å¼º ===\")\n",
    "# æ•°æ®å¢å¼ºæŠ€æœ¯æ¨¡æ‹Ÿ\n",
    "np.random.seed(42)\n",
    "\n",
    "# åŸå§‹\"å›¾åƒ\"æ•°æ® (ç®€åŒ–ä¸º1Dä¿¡å·)\n",
    "original_signal = np.sin(np.linspace(0, 4*np.pi, 100)) + 0.1*np.random.randn(100)\n",
    "\n",
    "def augment_data(signal, n_augmented=5):\n",
    "    \"\"\"æ•°æ®å¢å¼ºå‡½æ•°\"\"\"\n",
    "    augmented_signals = []\n",
    "    \n",
    "    for _ in range(n_augmented):\n",
    "        # æ·»åŠ éšæœºå™ªå£°\n",
    "        noise_level = np.random.uniform(0.05, 0.15)\n",
    "        noisy_signal = signal + noise_level * np.random.randn(len(signal))\n",
    "        \n",
    "        # éšæœºç¼©æ”¾\n",
    "        scale_factor = np.random.uniform(0.8, 1.2)\n",
    "        scaled_signal = signal * scale_factor\n",
    "        \n",
    "        # éšæœºåç§»\n",
    "        shift = np.random.randint(-5, 6)\n",
    "        shifted_signal = np.roll(signal, shift)\n",
    "        \n",
    "        augmented_signals.extend([noisy_signal, scaled_signal, shifted_signal])\n",
    "    \n",
    "    return np.array(augmented_signals)\n",
    "\n",
    "# ç”Ÿæˆå¢å¼ºæ•°æ®\n",
    "augmented_data = augment_data(original_signal, n_augmented=3)\n",
    "\n",
    "print(f\"åŸå§‹æ•°æ®å½¢çŠ¶: {original_signal.shape}\")\n",
    "print(f\"å¢å¼ºæ•°æ®å½¢çŠ¶: {augmented_data.shape}\")\n",
    "print(f\"æ•°æ®å¢å¼ºå€æ•°: {len(augmented_data) / 1:.0f}å€\")\n",
    "print(f\"åŸå§‹æ•°æ®ç»Ÿè®¡: å‡å€¼={np.mean(original_signal):.3f}, æ ‡å‡†å·®={np.std(original_signal):.3f}\")\n",
    "print(f\"å¢å¼ºæ•°æ®ç»Ÿè®¡: å‡å€¼={np.mean(augmented_data):.3f}, æ ‡å‡†å·®={np.std(augmented_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6b437",
   "metadata": {},
   "source": [
    "## 9. æ€§èƒ½ä¼˜åŒ–æŠ€å·§\n",
    "\n",
    "NumPyçš„æ€§èƒ½ä¼˜åŠ¿æ¥è‡ªäºæ­£ç¡®çš„ä½¿ç”¨æ–¹å¼ï¼Œè¿™é‡Œä»‹ç»ä¸€äº›å…³é”®çš„ä¼˜åŒ–æŠ€å·§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘é‡åŒ– vs å¾ªç¯æ€§èƒ½å¯¹æ¯”\n",
    "print(\"=== å‘é‡åŒ–ä¼˜åŒ– ===\")\n",
    "import time\n",
    "\n",
    "# å¤§è§„æ¨¡æ•°æ®\n",
    "n = 1000000\n",
    "a = np.random.randn(n)\n",
    "b = np.random.randn(n)\n",
    "\n",
    "# æ–¹æ³•1ï¼šPythonå¾ªç¯\n",
    "start_time = time.time()\n",
    "result_loop = []\n",
    "for i in range(n):\n",
    "    result_loop.append(a[i] * b[i] + a[i]**2)\n",
    "result_loop = np.array(result_loop)\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# æ–¹æ³•2ï¼šNumPyå‘é‡åŒ–\n",
    "start_time = time.time()\n",
    "result_vectorized = a * b + a**2\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "print(f\"æ•°æ®è§„æ¨¡: {n:,}\")\n",
    "print(f\"Pythonå¾ªç¯æ—¶é—´: {loop_time:.4f}ç§’\")\n",
    "print(f\"NumPyå‘é‡åŒ–æ—¶é—´: {vectorized_time:.4f}ç§’\")\n",
    "print(f\"åŠ é€Ÿæ¯”: {loop_time/vectorized_time:.1f}x\")\n",
    "print(f\"ç»“æœç›¸åŒ: {np.allclose(result_loop, result_vectorized)}\")\n",
    "\n",
    "print(\"\\n=== å†…å­˜å¸ƒå±€ä¼˜åŒ– ===\")\n",
    "# C-order vs Fortran-order\n",
    "size = (1000, 1000)\n",
    "\n",
    "# C-order (è¡Œä¼˜å…ˆ)\n",
    "arr_c = np.random.randn(*size)\n",
    "# Fortran-order (åˆ—ä¼˜å…ˆ)\n",
    "arr_f = np.asfortranarray(arr_c)\n",
    "\n",
    "print(f\"C-orderè¿ç»­: {arr_c.flags.c_contiguous}\")\n",
    "print(f\"Fortran-orderè¿ç»­: {arr_f.flags.f_contiguous}\")\n",
    "\n",
    "# æŒ‰è¡Œè®¿é—®æ€§èƒ½æµ‹è¯•\n",
    "start_time = time.time()\n",
    "row_sum_c = np.sum(arr_c, axis=1)  # æŒ‰è¡Œæ±‚å’Œ\n",
    "c_row_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "row_sum_f = np.sum(arr_f, axis=1)  # æŒ‰è¡Œæ±‚å’Œ\n",
    "f_row_time = time.time() - start_time\n",
    "\n",
    "print(f\"C-orderæŒ‰è¡Œæ±‚å’Œ: {c_row_time:.4f}ç§’\")\n",
    "print(f\"F-orderæŒ‰è¡Œæ±‚å’Œ: {f_row_time:.4f}ç§’\")\n",
    "print(f\"C-orderä¼˜åŠ¿: {f_row_time/c_row_time:.1f}x\")\n",
    "\n",
    "# æŒ‰åˆ—è®¿é—®æ€§èƒ½æµ‹è¯•\n",
    "start_time = time.time()\n",
    "col_sum_c = np.sum(arr_c, axis=0)  # æŒ‰åˆ—æ±‚å’Œ\n",
    "c_col_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "col_sum_f = np.sum(arr_f, axis=0)  # æŒ‰åˆ—æ±‚å’Œ\n",
    "f_col_time = time.time() - start_time\n",
    "\n",
    "print(f\"C-orderæŒ‰åˆ—æ±‚å’Œ: {c_col_time:.4f}ç§’\")\n",
    "print(f\"F-orderæŒ‰åˆ—æ±‚å’Œ: {f_col_time:.4f}ç§’\")\n",
    "print(f\"F-orderä¼˜åŠ¿: {c_col_time/f_col_time:.1f}x\")\n",
    "\n",
    "print(\"\\n=== æ•°æ®ç±»å‹ä¼˜åŒ– ===\")\n",
    "# ä¸åŒæ•°æ®ç±»å‹çš„å†…å­˜å’Œæ€§èƒ½å¯¹æ¯”\n",
    "data_size = 1000000\n",
    "\n",
    "# åˆ›å»ºä¸åŒç²¾åº¦çš„æ•°ç»„\n",
    "float64_arr = np.random.randn(data_size).astype(np.float64)\n",
    "float32_arr = float64_arr.astype(np.float32)\n",
    "int32_arr = (float64_arr * 1000).astype(np.int32)\n",
    "\n",
    "print(f\"æ•°æ®é‡: {data_size:,}\")\n",
    "print(f\"float64å†…å­˜: {float64_arr.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"float32å†…å­˜: {float32_arr.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"int32å†…å­˜: {int32_arr.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# è®¡ç®—æ€§èƒ½æµ‹è¯•\n",
    "operations = [\n",
    "    (\"åŠ æ³•\", lambda x: x + x),\n",
    "    (\"ä¹˜æ³•\", lambda x: x * x),\n",
    "    (\"å¹³æ–¹æ ¹\", lambda x: np.sqrt(np.abs(x)))\n",
    "]\n",
    "\n",
    "for op_name, op_func in operations:\n",
    "    # float64\n",
    "    start_time = time.time()\n",
    "    result64 = op_func(float64_arr)\n",
    "    time64 = time.time() - start_time\n",
    "    \n",
    "    # float32\n",
    "    start_time = time.time()\n",
    "    result32 = op_func(float32_arr)\n",
    "    time32 = time.time() - start_time\n",
    "    \n",
    "    print(f\"{op_name} - float64: {time64:.4f}s, float32: {time32:.4f}s, åŠ é€Ÿ: {time64/time32:.1f}x\")\n",
    "\n",
    "print(\"\\n=== é¿å…ä¸å¿…è¦çš„æ‹·è´ ===\")\n",
    "large_array = np.random.randn(1000, 1000)\n",
    "\n",
    "# æ–¹æ³•1ï¼šåˆ›å»ºæ‹·è´ï¼ˆæ…¢ï¼‰\n",
    "start_time = time.time()\n",
    "subset_copy = large_array[100:900, 100:900].copy()\n",
    "result1 = np.sum(subset_copy)\n",
    "copy_time = time.time() - start_time\n",
    "\n",
    "# æ–¹æ³•2ï¼šä½¿ç”¨è§†å›¾ï¼ˆå¿«ï¼‰\n",
    "start_time = time.time()\n",
    "subset_view = large_array[100:900, 100:900]\n",
    "result2 = np.sum(subset_view)\n",
    "view_time = time.time() - start_time\n",
    "\n",
    "print(f\"ä½¿ç”¨æ‹·è´: {copy_time:.4f}ç§’\")\n",
    "print(f\"ä½¿ç”¨è§†å›¾: {view_time:.4f}ç§’\")\n",
    "print(f\"è§†å›¾åŠ é€Ÿ: {copy_time/view_time:.1f}x\")\n",
    "print(f\"ç»“æœç›¸åŒ: {np.isclose(result1, result2)}\")\n",
    "\n",
    "print(\"\\n=== ä½¿ç”¨numexpråŠ é€Ÿå¤æ‚è¡¨è¾¾å¼ ===\")\n",
    "try:\n",
    "    import numexpr as ne\n",
    "    \n",
    "    # å¤æ‚æ•°å­¦è¡¨è¾¾å¼\n",
    "    x = np.random.randn(100000)\n",
    "    y = np.random.randn(100000)\n",
    "    z = np.random.randn(100000)\n",
    "    \n",
    "    # NumPyæ–¹å¼\n",
    "    start_time = time.time()\n",
    "    result_numpy = 2*x**2 + 3*y**3 + np.sqrt(z)\n",
    "    numpy_time = time.time() - start_time\n",
    "    \n",
    "    # numexpræ–¹å¼\n",
    "    start_time = time.time()\n",
    "    result_numexpr = ne.evaluate(\"2*x**2 + 3*y**3 + sqrt(z)\")\n",
    "    numexpr_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"NumPyè®¡ç®—: {numpy_time:.4f}ç§’\")\n",
    "    print(f\"numexprè®¡ç®—: {numexpr_time:.4f}ç§’\")\n",
    "    print(f\"numexpråŠ é€Ÿ: {numpy_time/numexpr_time:.1f}x\")\n",
    "    print(f\"ç»“æœç›¸åŒ: {np.allclose(result_numpy, result_numexpr)}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"numexpræœªå®‰è£…ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•\")\n",
    "    print(\"å®‰è£…å‘½ä»¤: pip install numexpr\")\n",
    "\n",
    "print(\"\\n=== å†…å­˜é¢„åˆ†é… ===\")\n",
    "# é”™è¯¯æ–¹å¼ï¼šåŠ¨æ€å¢é•¿æ•°ç»„\n",
    "def inefficient_array_building(n):\n",
    "    result = np.array([])\n",
    "    for i in range(n):\n",
    "        result = np.append(result, i**2)\n",
    "    return result\n",
    "\n",
    "# æ­£ç¡®æ–¹å¼ï¼šé¢„åˆ†é…æ•°ç»„\n",
    "def efficient_array_building(n):\n",
    "    result = np.empty(n)\n",
    "    for i in range(n):\n",
    "        result[i] = i**2\n",
    "    return result\n",
    "\n",
    "# æœ€ä½³æ–¹å¼ï¼šå‘é‡åŒ–\n",
    "def vectorized_array_building(n):\n",
    "    indices = np.arange(n)\n",
    "    return indices**2\n",
    "\n",
    "n = 5000\n",
    "\n",
    "# æ€§èƒ½æ¯”è¾ƒ\n",
    "start_time = time.time()\n",
    "result1 = inefficient_array_building(n)\n",
    "inefficient_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result2 = efficient_array_building(n)\n",
    "efficient_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result3 = vectorized_array_building(n)\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "print(f\"åŠ¨æ€å¢é•¿: {inefficient_time:.4f}ç§’\")\n",
    "print(f\"é¢„åˆ†é…: {efficient_time:.4f}ç§’\")\n",
    "print(f\"å‘é‡åŒ–: {vectorized_time:.4f}ç§’\")\n",
    "print(f\"é¢„åˆ†é…åŠ é€Ÿ: {inefficient_time/efficient_time:.1f}x\")\n",
    "print(f\"å‘é‡åŒ–åŠ é€Ÿ: {inefficient_time/vectorized_time:.1f}x\")\n",
    "\n",
    "print(\"\\n=== æ€§èƒ½ä¼˜åŒ–æ€»ç»“ ===\")\n",
    "print(\"1. ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£Pythonå¾ªç¯\")\n",
    "print(\"2. é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹ï¼ˆfloat32 vs float64ï¼‰\")\n",
    "print(\"3. æ³¨æ„æ•°ç»„çš„å†…å­˜å¸ƒå±€ï¼ˆC-order vs F-orderï¼‰\")\n",
    "print(\"4. é¿å…ä¸å¿…è¦çš„æ•°ç»„æ‹·è´ï¼Œä½¿ç”¨è§†å›¾\")\n",
    "print(\"5. é¢„åˆ†é…æ•°ç»„å¤§å°ï¼Œé¿å…åŠ¨æ€å¢é•¿\")\n",
    "print(\"6. å¯¹å¤æ‚è¡¨è¾¾å¼ä½¿ç”¨numexpr\")\n",
    "print(\"7. åˆ©ç”¨NumPyçš„å†…ç½®å‡½æ•°è€Œéè‡ªå®šä¹‰å®ç°\")\n",
    "print(\"8. åˆç†ä½¿ç”¨å¹¿æ’­æœºåˆ¶\")\n",
    "print(\"9. æ³¨æ„ç¼“å­˜å‹å¥½çš„æ•°æ®è®¿é—®æ¨¡å¼\")\n",
    "print(\"10. è€ƒè™‘ä½¿ç”¨å¤šçº¿ç¨‹åº“å¦‚numbaè¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6b3c1",
   "metadata": {},
   "source": [
    "## 10. æ€»ç»“å’Œä¸‹ä¸€æ­¥\n",
    "\n",
    "### æœ¬æ•™ç¨‹å­¦ä¹ å†…å®¹å›é¡¾\n",
    "\n",
    "âœ… **NumPyåŸºç¡€**: æ•°ç»„åˆ›å»ºã€å±æ€§ã€æ•°æ®ç±»å‹  \n",
    "âœ… **ç´¢å¼•å’Œåˆ‡ç‰‡**: ä¸€ç»´ã€å¤šç»´ã€å¸ƒå°”ã€èŠ±å¼ç´¢å¼•  \n",
    "âœ… **æ•°ç»„è¿ç®—**: å‘é‡åŒ–è¿ç®—ã€å¹¿æ’­æœºåˆ¶  \n",
    "âœ… **æ•°å­¦ç»Ÿè®¡**: åŸºæœ¬ç»Ÿè®¡å‡½æ•°ã€æ•°å­¦å‡½æ•°åº“  \n",
    "âœ… **æ•°ç»„æ“ä½œ**: å½¢çŠ¶å˜æ¢ã€åˆå¹¶åˆ†å‰²ã€è½¬ç½®  \n",
    "âœ… **çº¿æ€§ä»£æ•°**: çŸ©é˜µè¿ç®—ã€ç‰¹å¾å€¼ã€SVDã€çº¿æ€§æ–¹ç¨‹ç»„  \n",
    "âœ… **é«˜çº§ç‰¹æ€§**: è‡ªå®šä¹‰å‡½æ•°ã€ç»“æ„åŒ–æ•°ç»„ã€æ©ç æ•°ç»„  \n",
    "âœ… **éšæœºæ•°ç”Ÿæˆ**: å„ç§åˆ†å¸ƒã€è’™ç‰¹å¡æ´›æ–¹æ³•  \n",
    "âœ… **æ€§èƒ½ä¼˜åŒ–**: å‘é‡åŒ–ã€å†…å­˜å¸ƒå±€ã€æ•°æ®ç±»å‹ä¼˜åŒ–  \n",
    "\n",
    "### å…³é”®æ¦‚å¿µæ€»ç»“\n",
    "\n",
    "1. **å‘é‡åŒ–æ˜¯æ ¸å¿ƒ**: NumPyçš„æ€§èƒ½ä¼˜åŠ¿æ¥è‡ªå‘é‡åŒ–è¿ç®—\n",
    "2. **å¹¿æ’­æœºåˆ¶**: ä½¿ä¸åŒå½¢çŠ¶çš„æ•°ç»„èƒ½å¤Ÿè¿›è¡Œè¿ç®—\n",
    "3. **è§†å›¾ vs æ‹·è´**: ç†è§£å†…å­˜ç®¡ç†ï¼Œé¿å…ä¸å¿…è¦çš„å†…å­˜å¼€é”€\n",
    "4. **æ•°æ®ç±»å‹é€‰æ‹©**: å¹³è¡¡ç²¾åº¦å’Œæ€§èƒ½éœ€æ±‚\n",
    "5. **è½´çš„æ¦‚å¿µ**: ç†è§£å¤šç»´æ•°ç»„çš„è½´å¯¹äºæ­£ç¡®ä½¿ç”¨å‡½æ•°è‡³å…³é‡è¦\n",
    "\n",
    "### å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "- **æ•°æ®é¢„å¤„ç†**: æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ã€ç‰¹å¾å·¥ç¨‹\n",
    "- **æœºå™¨å­¦ä¹ **: çŸ©é˜µè¿ç®—ã€æ¢¯åº¦è®¡ç®—ã€æŸå¤±å‡½æ•°\n",
    "- **ç§‘å­¦è®¡ç®—**: æ•°å€¼ç§¯åˆ†ã€å¾®åˆ†æ–¹ç¨‹æ±‚è§£\n",
    "- **å›¾åƒå¤„ç†**: æ»¤æ³¢ã€å˜æ¢ã€ç‰¹å¾æå–\n",
    "- **é‡‘èåˆ†æ**: é£é™©å»ºæ¨¡ã€ç»„åˆä¼˜åŒ–\n",
    "- **ä¿¡å·å¤„ç†**: æ—¶é¢‘åˆ†æã€æ»¤æ³¢å™¨è®¾è®¡\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **æ·±å…¥å®è·µ**: åœ¨å®é™…é¡¹ç›®ä¸­å¤šä½¿ç”¨NumPy\n",
    "2. **å­¦ä¹ ç›¸å…³åº“**: \n",
    "   - **Pandas**: æ•°æ®å¤„ç†å’Œåˆ†æ (`03_pandas.ipynb`)\n",
    "   - **Matplotlib**: æ•°æ®å¯è§†åŒ– (`04_matplotlib.ipynb`)\n",
    "   - **Scikit-learn**: æœºå™¨å­¦ä¹ ç®—æ³• (`05_sklearn.ipynb`)\n",
    "3. **æ€§èƒ½ä¼˜åŒ–**: å­¦ä¹ Numbaã€Cythonç­‰åŠ é€Ÿå·¥å…·\n",
    "4. **å¹¶è¡Œè®¡ç®—**: äº†è§£Daskã€Rayç­‰åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶\n",
    "\n",
    "### å¸¸ç”¨å‡½æ•°é€ŸæŸ¥\n",
    "\n",
    "```python\n",
    "# æ•°ç»„åˆ›å»º\n",
    "np.array(), np.zeros(), np.ones(), np.eye(), np.arange(), np.linspace()\n",
    "\n",
    "# æ•°ç»„å±æ€§\n",
    "arr.shape, arr.dtype, arr.size, arr.ndim\n",
    "\n",
    "# æ•°å­¦è¿ç®—  \n",
    "np.add(), np.multiply(), np.dot(), np.matmul(), np.sqrt(), np.exp()\n",
    "\n",
    "# ç»Ÿè®¡å‡½æ•°\n",
    "np.mean(), np.median(), np.std(), np.var(), np.min(), np.max()\n",
    "\n",
    "# æ•°ç»„æ“ä½œ\n",
    "np.reshape(), np.transpose(), np.concatenate(), np.split()\n",
    "\n",
    "# çº¿æ€§ä»£æ•°\n",
    "np.linalg.inv(), np.linalg.det(), np.linalg.eig(), np.linalg.svd()\n",
    "\n",
    "# éšæœºæ•°\n",
    "np.random.random(), np.random.normal(), np.random.choice()\n",
    "```\n",
    "\n",
    "### æ¨èèµ„æº\n",
    "\n",
    "- [NumPyå®˜æ–¹æ–‡æ¡£](https://numpy.org/doc/stable/)\n",
    "- [NumPyç”¨æˆ·æŒ‡å—](https://numpy.org/doc/stable/user/index.html)\n",
    "- [From Python to NumPy](https://www.labri.fr/perso/nrougier/from-python-to-numpy/)\n",
    "- [100 NumPy exercises](https://github.com/rougier/numpy-100)\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†NumPyçš„å­¦ä¹ ï¼NumPyæ˜¯Pythonç§‘å­¦è®¡ç®—ç”Ÿæ€ç³»ç»Ÿçš„åŸºçŸ³ï¼ŒæŒæ¡å®ƒå°†ä¸ºåç»­å­¦ä¹ æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦æ‰“ä¸‹åšå®åŸºç¡€ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
