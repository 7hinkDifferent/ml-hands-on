{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bd5187",
   "metadata": {},
   "source": [
    "# PyTorchæ·±åº¦å­¦ä¹ å®Œå…¨æ•™ç¨‹\n",
    "\n",
    "PyTorchæ˜¯å½“å‰æœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¹‹ä¸€ï¼Œä»¥å…¶åŠ¨æ€è®¡ç®—å›¾ã€ç›´è§‚çš„APIè®¾è®¡å’Œå¼ºå¤§çš„GPUåŠ é€Ÿèƒ½åŠ›è€Œè‘—ç§°ã€‚æœ¬æ•™ç¨‹å°†å¸¦ä½ ä»åŸºç¡€åˆ°é«˜çº§ï¼Œå…¨é¢æŒæ¡PyTorchåœ¨å®é™…é¡¹ç›®ä¸­çš„åº”ç”¨ã€‚\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å°†æŒæ¡ï¼š\n",
    "- **PyTorchåŸºç¡€**ï¼šå¼ é‡æ“ä½œã€è‡ªåŠ¨å¾®åˆ†ã€è®¡ç®—å›¾\n",
    "- **æ¨¡å‹æ„å»º**ï¼šè‡ªå®šä¹‰ç½‘ç»œæ¶æ„ã€å±‚çš„ç»„åˆã€å‚æ•°ç®¡ç†\n",
    "- **æ•°æ®å¤„ç†**ï¼šè‡ªå®šä¹‰æ•°æ®é›†ã€æ•°æ®åŠ è½½å™¨ã€æ•°æ®å¢å¼º\n",
    "- **è®­ç»ƒæµç¨‹**ï¼šå®Œæ•´çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•å¾ªç¯ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨\n",
    "- **æ¨¡å‹ç®¡ç†**ï¼šæ–­ç‚¹ä¿å­˜æ¢å¤ã€æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ã€æœ€ä½³æ¨¡å‹é€‰æ‹©\n",
    "- **å®éªŒè·Ÿè¸ª**ï¼šTensorBoardå¯è§†åŒ–ã€æ—¥å¿—è®°å½•ã€è¶…å‚æ•°è·Ÿè¸ª\n",
    "- **ç”Ÿäº§éƒ¨ç½²**ï¼šæ¨¡å‹å¯¼å‡ºã€æ¨ç†ä¼˜åŒ–ã€æ€§èƒ½ç›‘æ§\n",
    "\n",
    "## ğŸ“‹ å®Œæ•´å†…å®¹å¤§çº²\n",
    "\n",
    "### 1. ç¯å¢ƒé…ç½®ä¸PyTorchåŸºç¡€\n",
    "- CUDAç¯å¢ƒæ£€æŸ¥\n",
    "- å¼ é‡åˆ›å»ºä¸æ“ä½œ\n",
    "- è‡ªåŠ¨å¾®åˆ†æœºåˆ¶\n",
    "\n",
    "### 2. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "- åŸºç¡€æ¨¡å‹æ¶æ„\n",
    "- å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰\n",
    "- é«˜çº§ç½‘ç»œç»„ä»¶\n",
    "\n",
    "### 3. è‡ªå®šä¹‰æ•°æ®é›†ä¸æ•°æ®åŠ è½½\n",
    "- MNISTæ•°æ®é›†å¤„ç†\n",
    "- è‡ªå®šä¹‰Datasetç±»\n",
    "- æ•°æ®é¢„å¤„ç†ä¸å¢å¼º\n",
    "\n",
    "### 4. å®Œæ•´è®­ç»ƒæµç¨‹\n",
    "- è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•åˆ’åˆ†\n",
    "- æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨\n",
    "- å­¦ä¹ ç‡è°ƒåº¦\n",
    "\n",
    "### 5. æ–­ç‚¹ä¿å­˜ä¸æ¢å¤\n",
    "- æ¨¡å‹çŠ¶æ€ä¿å­˜\n",
    "- è®­ç»ƒä¸­æ–­æ¢å¤\n",
    "- æœ€ä½³æ¨¡å‹ç®¡ç†\n",
    "\n",
    "### 6. TensorBoardå¯è§†åŒ–\n",
    "- æŸå¤±ä¸æŒ‡æ ‡è·Ÿè¸ª\n",
    "- æ¨¡å‹ç»“æ„å¯è§†åŒ–\n",
    "- å‚æ•°åˆ†å¸ƒç›‘æ§\n",
    "\n",
    "### 7. é«˜çº§æ—¥å¿—ä¸å®éªŒç®¡ç†\n",
    "- ç»“æ„åŒ–æ—¥å¿—è®°å½•\n",
    "- è¶…å‚æ•°å®éªŒè·Ÿè¸ª\n",
    "- æ€§èƒ½åˆ†æå·¥å…·\n",
    "\n",
    "### 8. å®é™…é¡¹ç›®æ¡ˆä¾‹\n",
    "- MNISTæ‰‹å†™æ•°å­—è¯†åˆ«\n",
    "- ç«¯åˆ°ç«¯é¡¹ç›®æµç¨‹\n",
    "- æœ€ä½³å®è·µæ€»ç»“\n",
    "\n",
    "**é‡ç‚¹æ¡ˆä¾‹**ï¼šåŸºäºMNISTæ•°æ®é›†çš„æ‰‹å†™æ•°å­—åˆ†ç±»ï¼Œä»é›¶æ„å»ºå®Œæ•´çš„æ·±åº¦å­¦ä¹ é¡¹ç›®ï¼ŒåŒ…å«æ‰€æœ‰ç”Ÿäº§çº§ç‰¹æ€§ã€‚\n",
    "\n",
    "PyTorchä»¥å…¶Pythonicçš„è®¾è®¡å“²å­¦å’Œç ”ç©¶å‹å¥½çš„ç‰¹æ€§ï¼Œæˆä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„é¦–é€‰æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è®©æˆ‘ä»¬å¼€å§‹è¿™ä¸ªç²¾å½©çš„å­¦ä¹ ä¹‹æ—…ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PyTorchæ·±åº¦å­¦ä¹ ç¯å¢ƒé…ç½® ===\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# è®¾ç½®è­¦å‘Šè¿‡æ»¤\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒå¯é‡ç°æ€§\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ç¯å¢ƒä¿¡æ¯æ£€æŸ¥\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"Torchvisionç‰ˆæœ¬: {torchvision.__version__}\")\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "\n",
    "# CUDAç¯å¢ƒè¯¦ç»†æ£€æŸ¥\n",
    "print(f\"\\n=== GPUç¯å¢ƒä¿¡æ¯ ===\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "    print(f\"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"GPUè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ\")\n",
    "\n",
    "# è®¾å¤‡é…ç½®\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„\n",
    "project_dirs = {\n",
    "    'models': 'saved_models',\n",
    "    'logs': 'logs', \n",
    "    'tensorboard': 'runs',\n",
    "    'data': 'data',\n",
    "    'checkpoints': 'checkpoints',\n",
    "    'outputs': 'outputs'\n",
    "}\n",
    "\n",
    "print(f\"\\n=== åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„ ===\")\n",
    "for name, path in project_dirs.items():\n",
    "    Path(path).mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ {name}: {path}/\")\n",
    "\n",
    "# é…ç½®matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# PyTorchè®¾ç½®ä¼˜åŒ–\n",
    "if torch.cuda.is_available():\n",
    "    # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"âœ“ å¯ç”¨cuDNNåŸºå‡†æµ‹è¯•æ¨¡å¼ä»¥ä¼˜åŒ–æ€§èƒ½\")\n",
    "\n",
    "print(f\"\\n=== ç¯å¢ƒé…ç½®å®Œæˆ ===\")\n",
    "print(f\"é¡¹ç›®åˆå§‹åŒ–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# éªŒè¯PyTorchåŸºæœ¬åŠŸèƒ½\n",
    "print(f\"\\n=== PyTorchåŠŸèƒ½éªŒè¯ ===\")\n",
    "# åˆ›å»ºæµ‹è¯•å¼ é‡\n",
    "test_tensor = torch.randn(2, 3, device=device)\n",
    "print(f\"æµ‹è¯•å¼ é‡åˆ›å»ºæˆåŠŸ: {test_tensor.shape} on {test_tensor.device}\")\n",
    "\n",
    "# æµ‹è¯•è‡ªåŠ¨å¾®åˆ†\n",
    "x = torch.tensor([2.0], requires_grad=True, device=device)\n",
    "y = x ** 2 + 3 * x + 1\n",
    "y.backward()\n",
    "print(f\"è‡ªåŠ¨å¾®åˆ†æµ‹è¯•: f(2) = {y.item():.2f}, f'(2) = {x.grad.item():.2f}\")\n",
    "\n",
    "print(f\"âœ“ PyTorchç¯å¢ƒéªŒè¯å®Œæˆï¼Œå‡†å¤‡å¼€å§‹æ·±åº¦å­¦ä¹ ä¹‹æ—…ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63662bc",
   "metadata": {},
   "source": [
    "## 2. PyTorchå¼ é‡åŸºç¡€\n",
    "\n",
    "å¼ é‡ï¼ˆTensorï¼‰æ˜¯PyTorchçš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œç±»ä¼¼äºNumPyçš„æ•°ç»„ä½†æ”¯æŒGPUåŠ é€Ÿå’Œè‡ªåŠ¨å¾®åˆ†ã€‚æŒæ¡å¼ é‡æ“ä½œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 å¼ é‡åˆ›å»ºä¸åŸºæœ¬æ“ä½œ\n",
    "print(\"=== PyTorchå¼ é‡åŸºç¡€æ“ä½œ ===\")\n",
    "\n",
    "# 2.1.1 å¼ é‡åˆ›å»ºçš„å¤šç§æ–¹å¼\n",
    "print(\"1. å¼ é‡åˆ›å»ºæ–¹å¼:\")\n",
    "\n",
    "# ä»Pythonåˆ—è¡¨åˆ›å»º\n",
    "tensor_from_list = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=device)\n",
    "print(f\"ä»åˆ—è¡¨åˆ›å»º: \\n{tensor_from_list}\")\n",
    "\n",
    "# åˆ›å»ºç‰¹æ®Šå¼ é‡\n",
    "zeros_tensor = torch.zeros(3, 4, device=device)\n",
    "ones_tensor = torch.ones(2, 3, device=device)\n",
    "random_tensor = torch.randn(2, 3, device=device)\n",
    "arange_tensor = torch.arange(0, 10, 2, device=device)\n",
    "\n",
    "print(f\"\\né›¶å¼ é‡ (3x4): \\n{zeros_tensor}\")\n",
    "print(f\"\\nå•ä½å¼ é‡ (2x3): \\n{ones_tensor}\")\n",
    "print(f\"\\néšæœºå¼ é‡ (2x3): \\n{random_tensor}\")\n",
    "print(f\"\\nç­‰å·®æ•°åˆ—å¼ é‡: {arange_tensor}\")\n",
    "\n",
    "# æ ¹æ®ç°æœ‰å¼ é‡åˆ›å»º\n",
    "like_tensor = torch.zeros_like(tensor_from_list)\n",
    "rand_like_tensor = torch.randn_like(tensor_from_list)\n",
    "\n",
    "print(f\"\\nç±»ä¼¼å½¢çŠ¶çš„é›¶å¼ é‡: \\n{like_tensor}\")\n",
    "print(f\"\\nç±»ä¼¼å½¢çŠ¶çš„éšæœºå¼ é‡: \\n{rand_like_tensor}\")\n",
    "\n",
    "# 2.1.2 å¼ é‡å±æ€§\n",
    "print(f\"\\n2. å¼ é‡å±æ€§:\")\n",
    "sample_tensor = torch.randn(2, 3, 4, device=device)\n",
    "print(f\"å¼ é‡å½¢çŠ¶: {sample_tensor.shape}\")\n",
    "print(f\"å¼ é‡ç»´åº¦: {sample_tensor.dim()}\")\n",
    "print(f\"å¼ é‡æ•°æ®ç±»å‹: {sample_tensor.dtype}\")\n",
    "print(f\"å¼ é‡è®¾å¤‡: {sample_tensor.device}\")\n",
    "print(f\"å¼ é‡å¤§å°: {sample_tensor.size()}\")\n",
    "print(f\"å…ƒç´ æ€»æ•°: {sample_tensor.numel()}\")\n",
    "\n",
    "# 2.1.3 å¼ é‡è¿ç®—\n",
    "print(f\"\\n3. å¼ é‡è¿ç®—:\")\n",
    "\n",
    "# åŸºæœ¬æ•°å­¦è¿ç®—\n",
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, device=device)\n",
    "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32, device=device)\n",
    "\n",
    "print(f\"å¼ é‡ a: \\n{a}\")\n",
    "print(f\"å¼ é‡ b: \\n{b}\")\n",
    "\n",
    "# å…ƒç´ çº§è¿ç®—\n",
    "print(f\"\\nåŠ æ³•: \\n{a + b}\")\n",
    "print(f\"å‡æ³•: \\n{a - b}\")\n",
    "print(f\"ä¹˜æ³•: \\n{a * b}\")\n",
    "print(f\"é™¤æ³•: \\n{a / b}\")\n",
    "print(f\"å¹‚è¿ç®—: \\n{a ** 2}\")\n",
    "\n",
    "# çŸ©é˜µè¿ç®—\n",
    "print(f\"\\nçŸ©é˜µä¹˜æ³•: \\n{torch.mm(a, b)}\")\n",
    "print(f\"çŸ©é˜µä¹˜æ³• (æ“ä½œç¬¦): \\n{a @ b}\")\n",
    "\n",
    "# ç»Ÿè®¡è¿ç®—\n",
    "sample_data = torch.randn(100, device=device)\n",
    "print(f\"\\nç»Ÿè®¡è¿ç®— (100ä¸ªéšæœºæ•°):\")\n",
    "print(f\"å‡å€¼: {sample_data.mean().item():.4f}\")\n",
    "print(f\"æ ‡å‡†å·®: {sample_data.std().item():.4f}\")\n",
    "print(f\"æœ€å¤§å€¼: {sample_data.max().item():.4f}\")\n",
    "print(f\"æœ€å°å€¼: {sample_data.min().item():.4f}\")\n",
    "print(f\"æ±‚å’Œ: {sample_data.sum().item():.4f}\")\n",
    "\n",
    "# 2.1.4 å¼ é‡å˜å½¢\n",
    "print(f\"\\n4. å¼ é‡å˜å½¢æ“ä½œ:\")\n",
    "original = torch.arange(12, device=device)\n",
    "print(f\"åŸå§‹å¼ é‡: {original}\")\n",
    "\n",
    "# é‡å¡‘\n",
    "reshaped = original.view(3, 4)\n",
    "print(f\"é‡å¡‘ä¸º 3x4: \\n{reshaped}\")\n",
    "\n",
    "# æ·»åŠ ç»´åº¦\n",
    "unsqueezed = original.unsqueeze(0)  # åœ¨ç¬¬0ç»´æ·»åŠ \n",
    "print(f\"æ·»åŠ ç»´åº¦å: {unsqueezed.shape}\")\n",
    "\n",
    "# ç§»é™¤ç»´åº¦\n",
    "squeezed = unsqueezed.squeeze(0)  # ç§»é™¤ç¬¬0ç»´\n",
    "print(f\"ç§»é™¤ç»´åº¦å: {squeezed.shape}\")\n",
    "\n",
    "# è½¬ç½®\n",
    "matrix = torch.randn(3, 4, device=device)\n",
    "transposed = matrix.t()\n",
    "print(f\"åŸçŸ©é˜µå½¢çŠ¶: {matrix.shape}\")\n",
    "print(f\"è½¬ç½®åå½¢çŠ¶: {transposed.shape}\")\n",
    "\n",
    "# 2.1.5 å¼ é‡ç´¢å¼•ä¸åˆ‡ç‰‡\n",
    "print(f\"\\n5. å¼ é‡ç´¢å¼•ä¸åˆ‡ç‰‡:\")\n",
    "data = torch.arange(24, device=device).view(4, 6)\n",
    "print(f\"åŸå§‹æ•°æ® (4x6): \\n{data}\")\n",
    "\n",
    "# åŸºæœ¬ç´¢å¼•\n",
    "print(f\"ç¬¬ä¸€è¡Œ: {data[0]}\")\n",
    "print(f\"ç¬¬ä¸€åˆ—: {data[:, 0]}\")\n",
    "print(f\"å·¦ä¸Šè§’2x2: \\n{data[:2, :2]}\")\n",
    "\n",
    "# å¸ƒå°”ç´¢å¼•\n",
    "mask = data > 10\n",
    "print(f\"å¤§äº10çš„å…ƒç´ : {data[mask]}\")\n",
    "\n",
    "# é«˜çº§ç´¢å¼•\n",
    "indices = torch.tensor([0, 2], device=device)\n",
    "print(f\"é€‰æ‹©ç¬¬0å’Œç¬¬2è¡Œ: \\n{data[indices]}\")\n",
    "\n",
    "# 2.1.6 å°±åœ°æ“ä½œä¸å†…å­˜ç®¡ç†\n",
    "print(f\"\\n6. å°±åœ°æ“ä½œä¸å†…å­˜ç®¡ç†:\")\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32, device=device)\n",
    "print(f\"åŸå§‹å¼ é‡: {x}\")\n",
    "print(f\"å†…å­˜åœ°å€: {x.data_ptr()}\")\n",
    "\n",
    "# éå°±åœ°æ“ä½œ\n",
    "y = x + 1\n",
    "print(f\"éå°±åœ°æ“ä½œç»“æœ: {y}\")\n",
    "print(f\"åŸå§‹å¼ é‡ä¸å˜: {x}\")\n",
    "\n",
    "# å°±åœ°æ“ä½œ\n",
    "x.add_(1)  # ç­‰ä»·äº x += 1\n",
    "print(f\"å°±åœ°æ“ä½œå: {x}\")\n",
    "\n",
    "# å†…å­˜è¿ç»­æ€§\n",
    "non_contiguous = torch.randn(3, 4, device=device).t()\n",
    "print(f\"æ˜¯å¦å†…å­˜è¿ç»­: {non_contiguous.is_contiguous()}\")\n",
    "contiguous = non_contiguous.contiguous()\n",
    "print(f\"è¿ç»­åŒ–å: {contiguous.is_contiguous()}\")\n",
    "\n",
    "# 2.1.7 ä¸NumPyçš„äº’æ“ä½œ\n",
    "print(f\"\\n7. ä¸NumPyçš„äº’æ“ä½œ:\")\n",
    "if device.type == 'cpu':\n",
    "    # åªæœ‰CPUå¼ é‡å¯ä»¥ä¸NumPyç›´æ¥äº’è½¬\n",
    "    torch_tensor = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "    numpy_array = torch_tensor.numpy()\n",
    "    print(f\"PyTorchå¼ é‡: {torch_tensor}\")\n",
    "    print(f\"è½¬æ¢ä¸ºNumPy: {numpy_array}\")\n",
    "    \n",
    "    # ä»NumPyåˆ›å»ºå¼ é‡\n",
    "    new_torch = torch.from_numpy(numpy_array)\n",
    "    print(f\"ä»NumPyåˆ›å»º: {new_torch}\")\n",
    "else:\n",
    "    # GPUå¼ é‡éœ€è¦å…ˆç§»åˆ°CPU\n",
    "    gpu_tensor = torch.tensor([1, 2, 3, 4], dtype=torch.float32, device=device)\n",
    "    cpu_tensor = gpu_tensor.cpu()\n",
    "    numpy_array = cpu_tensor.numpy()\n",
    "    print(f\"GPUå¼ é‡è½¬NumPy: {numpy_array}\")\n",
    "\n",
    "print(f\"\\nâœ“ PyTorchå¼ é‡åŸºç¡€æ“ä½œå­¦ä¹ å®Œæˆï¼\")\n",
    "\n",
    "# å¯è§†åŒ–ä¸€äº›å¼ é‡æ“ä½œ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. éšæœºå¼ é‡å¯è§†åŒ–\n",
    "random_2d = torch.randn(10, 10, device='cpu')\n",
    "axes[0, 0].imshow(random_2d.numpy(), cmap='viridis')\n",
    "axes[0, 0].set_title('éšæœºå¼ é‡å¯è§†åŒ–')\n",
    "axes[0, 0].colorbar = plt.colorbar(axes[0, 0].imshow(random_2d.numpy(), cmap='viridis'), ax=axes[0, 0])\n",
    "\n",
    "# 2. å¼ é‡è¿ç®—ç»“æœ\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y1 = torch.sin(x)\n",
    "y2 = torch.cos(x)\n",
    "y3 = torch.exp(-x**2)\n",
    "\n",
    "axes[0, 1].plot(x.numpy(), y1.numpy(), label='sin(x)')\n",
    "axes[0, 1].plot(x.numpy(), y2.numpy(), label='cos(x)')\n",
    "axes[0, 1].plot(x.numpy(), y3.numpy(), label='exp(-xÂ²)')\n",
    "axes[0, 1].set_title('å¼ é‡æ•°å­¦å‡½æ•°')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# 3. çŸ©é˜µä¹˜æ³•å¯è§†åŒ–\n",
    "A = torch.randn(5, 3)\n",
    "B = torch.randn(3, 4)\n",
    "C = torch.mm(A, B)\n",
    "\n",
    "axes[1, 0].imshow(A.numpy(), cmap='RdBu', aspect='auto')\n",
    "axes[1, 0].set_title('çŸ©é˜µ A (5x3)')\n",
    "\n",
    "axes[1, 1].imshow(B.numpy(), cmap='RdBu', aspect='auto')\n",
    "axes[1, 1].set_title('çŸ©é˜µ B (3x4)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "print(f\"\\n=== æ€§èƒ½åŸºå‡†æµ‹è¯• ===\")\n",
    "def benchmark_operation(operation_func, tensor_size=(1000, 1000), iterations=100):\n",
    "    \"\"\"åŸºå‡†æµ‹è¯•å‡½æ•°\"\"\"\n",
    "    tensor = torch.randn(tensor_size, device=device)\n",
    "    \n",
    "    # é¢„çƒ­\n",
    "    for _ in range(10):\n",
    "        _ = operation_func(tensor)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        result = operation_func(tensor)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    avg_time = (end_time - start_time) / iterations * 1000  # æ¯«ç§’\n",
    "    return avg_time\n",
    "\n",
    "# æµ‹è¯•ä¸åŒæ“ä½œçš„æ€§èƒ½\n",
    "operations = {\n",
    "    'çŸ©é˜µä¹˜æ³•': lambda x: torch.mm(x, x.t()),\n",
    "    'å…ƒç´ çº§åŠ æ³•': lambda x: x + x,\n",
    "    'ä¸‰è§’å‡½æ•°': lambda x: torch.sin(x),\n",
    "    'æŒ‡æ•°å‡½æ•°': lambda x: torch.exp(x),\n",
    "    'æ±‚å’Œ': lambda x: torch.sum(x)\n",
    "}\n",
    "\n",
    "print(f\"è®¾å¤‡: {device}\")\n",
    "print(f\"å¼ é‡å¤§å°: 1000x1000\")\n",
    "print(f\"è¿­ä»£æ¬¡æ•°: 100\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, op in operations.items():\n",
    "    avg_time = benchmark_operation(op)\n",
    "    print(f\"{name:12}: {avg_time:.2f} ms\")\n",
    "\n",
    "print(f\"\\nâœ“ å¼ é‡åŸºç¡€æ“ä½œå’Œæ€§èƒ½æµ‹è¯•å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabd08d",
   "metadata": {},
   "source": [
    "## 3. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰\n",
    "\n",
    "è‡ªåŠ¨å¾®åˆ†æ˜¯PyTorchçš„æ ¸å¿ƒç‰¹æ€§ä¹‹ä¸€ï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼Œæ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒçš„åŸºç¡€ã€‚ç†è§£autogradæœºåˆ¶å¯¹äºæŒæ¡PyTorchè‡³å…³é‡è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 è‡ªåŠ¨å¾®åˆ†åŸºç¡€\n",
    "print(\"=== è‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰è¯¦è§£ ===\")\n",
    "\n",
    "# 3.1.1 requires_gradå‚æ•°\n",
    "print(\"1. requires_gradå‚æ•°å’Œè®¡ç®—å›¾æ„å»º:\")\n",
    "\n",
    "# åˆ›å»ºéœ€è¦æ¢¯åº¦çš„å¼ é‡\n",
    "x = torch.tensor([2.0], requires_grad=True, device=device)\n",
    "y = torch.tensor([3.0], requires_grad=True, device=device)\n",
    "\n",
    "print(f\"x = {x}, requires_grad = {x.requires_grad}\")\n",
    "print(f\"y = {y}, requires_grad = {y.requires_grad}\")\n",
    "\n",
    "# å®šä¹‰è®¡ç®—å›¾\n",
    "z = x * y  # z = 2 * 3 = 6\n",
    "w = z + x  # w = 6 + 2 = 8\n",
    "loss = w ** 2  # loss = 8^2 = 64\n",
    "\n",
    "print(f\"z = x * y = {z}\")\n",
    "print(f\"w = z + x = {w}\")\n",
    "print(f\"loss = w^2 = {loss}\")\n",
    "\n",
    "# æŸ¥çœ‹è®¡ç®—å›¾ä¿¡æ¯\n",
    "print(f\"\\nloss.grad_fn: {loss.grad_fn}\")\n",
    "print(f\"w.grad_fn: {w.grad_fn}\")\n",
    "print(f\"z.grad_fn: {z.grad_fn}\")\n",
    "\n",
    "# 3.1.2 åå‘ä¼ æ’­\n",
    "print(f\"\\n2. åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦:\")\n",
    "loss.backward()\n",
    "\n",
    "print(f\"âˆ‚loss/âˆ‚x = {x.grad}\")\n",
    "print(f\"âˆ‚loss/âˆ‚y = {y.grad}\")\n",
    "\n",
    "# æ‰‹åŠ¨éªŒè¯æ¢¯åº¦è®¡ç®—\n",
    "# loss = (x*y + x)^2 = (2*3 + 2)^2 = 8^2 = 64\n",
    "# âˆ‚loss/âˆ‚x = 2*(x*y + x) * (y + 1) = 2*8*(3+1) = 64\n",
    "# âˆ‚loss/âˆ‚y = 2*(x*y + x) * x = 2*8*2 = 32\n",
    "print(f\"æ‰‹åŠ¨è®¡ç®— âˆ‚loss/âˆ‚x = 2*8*4 = {2*8*4}\")\n",
    "print(f\"æ‰‹åŠ¨è®¡ç®— âˆ‚loss/âˆ‚y = 2*8*2 = {2*8*2}\")\n",
    "\n",
    "# 3.1.3 æ¢¯åº¦æ¸…é›¶\n",
    "print(f\"\\n3. æ¢¯åº¦ç´¯ç§¯å’Œæ¸…é›¶:\")\n",
    "print(f\"ç¬¬ä¸€æ¬¡åå‘ä¼ æ’­å x.grad: {x.grad}\")\n",
    "\n",
    "# å†æ¬¡åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ä¼šç´¯ç§¯ï¼‰\n",
    "loss.backward()\n",
    "print(f\"ç¬¬äºŒæ¬¡åå‘ä¼ æ’­å x.grad: {x.grad}\")\n",
    "\n",
    "# æ¢¯åº¦æ¸…é›¶\n",
    "x.grad.zero_()\n",
    "y.grad.zero_()\n",
    "print(f\"æ¸…é›¶å x.grad: {x.grad}\")\n",
    "\n",
    "# 3.1.4 æ¢¯åº¦ä¸Šä¸‹æ–‡ç®¡ç†\n",
    "print(f\"\\n4. æ¢¯åº¦ä¸Šä¸‹æ–‡ç®¡ç†:\")\n",
    "\n",
    "# ç¦ç”¨æ¢¯åº¦è®¡ç®—\n",
    "x = torch.randn(3, 3, requires_grad=True, device=device)\n",
    "print(f\"x.requires_grad: {x.requires_grad}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print(f\"åœ¨ no_grad ä¸Šä¸‹æ–‡ä¸­ï¼Œy.requires_grad: {y.requires_grad}\")\n",
    "\n",
    "# ä¸´æ—¶å¯ç”¨æ¢¯åº¦è®¡ç®—\n",
    "x = torch.randn(3, 3, device=device)\n",
    "with torch.enable_grad():\n",
    "    x.requires_grad_(True)\n",
    "    y = x * 2\n",
    "    print(f\"åœ¨ enable_grad ä¸Šä¸‹æ–‡ä¸­ï¼Œy.requires_grad: {y.requires_grad}\")\n",
    "\n",
    "# 3.1.5 detach()æ–¹æ³•\n",
    "print(f\"\\n5. detach()æ–¹æ³•ä½¿ç”¨:\")\n",
    "x = torch.randn(3, requires_grad=True, device=device)\n",
    "y = x * 2\n",
    "\n",
    "# åˆ†ç¦»å¼ é‡ï¼Œåœæ­¢æ¢¯åº¦ä¼ æ’­\n",
    "y_detached = y.detach()\n",
    "print(f\"åŸå§‹ y.requires_grad: {y.requires_grad}\")\n",
    "print(f\"åˆ†ç¦»å y_detached.requires_grad: {y_detached.requires_grad}\")\n",
    "\n",
    "# 3.1.6 å‡½æ•°çš„è‡ªåŠ¨å¾®åˆ†\n",
    "print(f\"\\n6. å¤æ‚å‡½æ•°çš„è‡ªåŠ¨å¾®åˆ†:\")\n",
    "\n",
    "def complex_function(x):\n",
    "    \"\"\"å¤æ‚å‡½æ•°ç¤ºä¾‹\"\"\"\n",
    "    return torch.sin(x) * torch.exp(-x**2) + torch.cos(x**2)\n",
    "\n",
    "# åˆ›å»ºè¾“å…¥\n",
    "x = torch.linspace(-2, 2, 100, requires_grad=True, device=device)\n",
    "y = complex_function(x)\n",
    "\n",
    "# è®¡ç®—æŸç‚¹çš„æ¢¯åº¦\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"åœ¨åŒºé—´[-2, 2]ä¸Šçš„æ¢¯åº¦èŒƒå›´: [{x.grad.min().item():.4f}, {x.grad.max().item():.4f}]\")\n",
    "\n",
    "# å¯è§†åŒ–å‡½æ•°å’Œæ¢¯åº¦\n",
    "if device.type == 'cpu':\n",
    "    x_np = x.detach().numpy()\n",
    "    y_np = y.detach().numpy()\n",
    "    grad_np = x.grad.numpy()\n",
    "else:\n",
    "    x_np = x.detach().cpu().numpy()\n",
    "    y_np = y.detach().cpu().numpy()\n",
    "    grad_np = x.grad.cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "ax1.plot(x_np, y_np, 'b-', linewidth=2, label='f(x)')\n",
    "ax1.set_title('å¤æ‚å‡½æ•° f(x) = sin(x)Â·exp(-xÂ²) + cos(xÂ²)')\n",
    "ax1.set_ylabel('f(x)')\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(x_np, grad_np, 'r-', linewidth=2, label=\"f'(x)\")\n",
    "ax2.set_title('å‡½æ•°çš„å¯¼æ•°')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel(\"f'(x)\")\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.1.7 è‡ªå®šä¹‰autogradå‡½æ•°\n",
    "print(f\"\\n7. è‡ªå®šä¹‰autogradå‡½æ•°:\")\n",
    "\n",
    "class SquareFunction(torch.autograd.Function):\n",
    "    \"\"\"è‡ªå®šä¹‰å¹³æ–¹å‡½æ•°ï¼Œæ¼”ç¤ºå¦‚ä½•å®ç°è‡ªå®šä¹‰çš„å‰å‘å’Œåå‘ä¼ æ’­\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"å‰å‘ä¼ æ’­\"\"\"\n",
    "        # ä¿å­˜è¾“å…¥ä»¥ä¾›åå‘ä¼ æ’­ä½¿ç”¨\n",
    "        ctx.save_for_backward(input)\n",
    "        return input ** 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"åå‘ä¼ æ’­\"\"\"\n",
    "        # è·å–ä¿å­˜çš„è¾“å…¥\n",
    "        input, = ctx.saved_tensors\n",
    "        # è®¡ç®—æ¢¯åº¦ï¼šd(xÂ²)/dx = 2x\n",
    "        grad_input = 2 * input * grad_output\n",
    "        return grad_input\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°\n",
    "square = SquareFunction.apply\n",
    "\n",
    "x = torch.tensor([3.0], requires_grad=True, device=device)\n",
    "y = square(x)\n",
    "y.backward()\n",
    "\n",
    "print(f\"è‡ªå®šä¹‰å¹³æ–¹å‡½æ•°: f(3) = {y.item()}\")\n",
    "print(f\"è‡ªå®šä¹‰å‡½æ•°æ¢¯åº¦: f'(3) = {x.grad.item()}\")\n",
    "print(f\"ç†è®ºæ¢¯åº¦: 2*3 = 6\")\n",
    "\n",
    "# 3.1.8 é«˜é˜¶æ¢¯åº¦\n",
    "print(f\"\\n8. é«˜é˜¶æ¢¯åº¦è®¡ç®—:\")\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True, device=device)\n",
    "y = x ** 3  # y = xÂ³\n",
    "\n",
    "# ä¸€é˜¶å¯¼æ•°\n",
    "grad_1 = torch.autograd.grad(y, x, create_graph=True)[0]\n",
    "print(f\"ä¸€é˜¶å¯¼æ•° dy/dx = {grad_1.item()}\")  # 3xÂ² = 12\n",
    "\n",
    "# äºŒé˜¶å¯¼æ•°\n",
    "grad_2 = torch.autograd.grad(grad_1, x)[0]\n",
    "print(f\"äºŒé˜¶å¯¼æ•° dÂ²y/dxÂ² = {grad_2.item()}\")  # 6x = 12\n",
    "\n",
    "# 3.1.9 é›…å¯æ¯”çŸ©é˜µ\n",
    "print(f\"\\n9. é›…å¯æ¯”çŸ©é˜µè®¡ç®—:\")\n",
    "\n",
    "def vector_function(x):\n",
    "    \"\"\"å‘é‡å‡½æ•° f(x,y) = [xÂ²+y, xy, yÂ²]\"\"\"\n",
    "    return torch.stack([\n",
    "        x[0]**2 + x[1],\n",
    "        x[0] * x[1], \n",
    "        x[1]**2\n",
    "    ])\n",
    "\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True, device=device)\n",
    "y = vector_function(x)\n",
    "\n",
    "# è®¡ç®—é›…å¯æ¯”çŸ©é˜µ\n",
    "jacobian = torch.autograd.functional.jacobian(vector_function, x)\n",
    "print(f\"è¾“å…¥: {x}\")\n",
    "print(f\"è¾“å‡º: {y}\")\n",
    "print(f\"é›…å¯æ¯”çŸ©é˜µ:\\n{jacobian}\")\n",
    "\n",
    "# ç†è®ºé›…å¯æ¯”çŸ©é˜µ:\n",
    "# fâ‚ = xÂ² + y  â†’  âˆ‚fâ‚/âˆ‚x = 2x, âˆ‚fâ‚/âˆ‚y = 1\n",
    "# fâ‚‚ = xy      â†’  âˆ‚fâ‚‚/âˆ‚x = y,  âˆ‚fâ‚‚/âˆ‚y = x  \n",
    "# fâ‚ƒ = yÂ²      â†’  âˆ‚fâ‚ƒ/âˆ‚x = 0,  âˆ‚fâ‚ƒ/âˆ‚y = 2y\n",
    "theoretical_jacobian = torch.tensor([\n",
    "    [2*x[0], 1],      # [4, 1]\n",
    "    [x[1], x[0]],     # [3, 2]\n",
    "    [0, 2*x[1]]       # [0, 6]\n",
    "], device=device)\n",
    "print(f\"ç†è®ºé›…å¯æ¯”çŸ©é˜µ:\\n{theoretical_jacobian}\")\n",
    "\n",
    "print(f\"\\nâœ“ è‡ªåŠ¨å¾®åˆ†æœºåˆ¶å­¦ä¹ å®Œæˆï¼\")\n",
    "\n",
    "# 3.1.10 æ¢¯åº¦æ£€æŸ¥å·¥å…·\n",
    "print(f\"\\n10. æ¢¯åº¦æ£€æŸ¥ï¼ˆæ•°å€¼éªŒè¯ï¼‰:\")\n",
    "\n",
    "def numerical_gradient(f, x, h=1e-5):\n",
    "    \"\"\"æ•°å€¼æ–¹æ³•è®¡ç®—æ¢¯åº¦\"\"\"\n",
    "    grad = torch.zeros_like(x)\n",
    "    for i in range(x.numel()):\n",
    "        x_pos = x.clone()\n",
    "        x_neg = x.clone()\n",
    "        x_pos.view(-1)[i] += h\n",
    "        x_neg.view(-1)[i] -= h\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            grad.view(-1)[i] = (f(x_pos) - f(x_neg)) / (2 * h)\n",
    "    return grad\n",
    "\n",
    "# æµ‹è¯•å‡½æ•°\n",
    "def test_function(x):\n",
    "    return (x**2).sum()\n",
    "\n",
    "x = torch.randn(3, requires_grad=True, device=device)\n",
    "\n",
    "# è‡ªåŠ¨å¾®åˆ†æ¢¯åº¦\n",
    "loss = test_function(x)\n",
    "loss.backward()\n",
    "auto_grad = x.grad.clone()\n",
    "\n",
    "# æ•°å€¼æ¢¯åº¦\n",
    "x.grad.zero_()\n",
    "numerical_grad = numerical_gradient(test_function, x)\n",
    "\n",
    "# æ¯”è¾ƒä¸¤ç§æ¢¯åº¦\n",
    "difference = torch.abs(auto_grad - numerical_grad)\n",
    "print(f\"è‡ªåŠ¨å¾®åˆ†æ¢¯åº¦: {auto_grad}\")\n",
    "print(f\"æ•°å€¼è®¡ç®—æ¢¯åº¦: {numerical_grad}\")\n",
    "print(f\"å·®å¼‚: {difference}\")\n",
    "print(f\"æœ€å¤§å·®å¼‚: {difference.max().item():.2e}\")\n",
    "\n",
    "# ç»˜åˆ¶æ¢¯åº¦æ£€æŸ¥å¯è§†åŒ–\n",
    "if len(x) <= 10:  # åªå¯¹å°å¼ é‡è¿›è¡Œå¯è§†åŒ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    indices = range(len(auto_grad.flatten()))\n",
    "    \n",
    "    if device.type == 'cpu':\n",
    "        auto_grad_np = auto_grad.numpy().flatten()\n",
    "        numerical_grad_np = numerical_grad.numpy().flatten()\n",
    "    else:\n",
    "        auto_grad_np = auto_grad.cpu().numpy().flatten()\n",
    "        numerical_grad_np = numerical_grad.cpu().numpy().flatten()\n",
    "    \n",
    "    ax.plot(indices, auto_grad_np, 'bo-', label='è‡ªåŠ¨å¾®åˆ†', markersize=8)\n",
    "    ax.plot(indices, numerical_grad_np, 'r^-', label='æ•°å€¼è®¡ç®—', markersize=8)\n",
    "    ax.set_xlabel('å‚æ•°ç´¢å¼•')\n",
    "    ax.set_ylabel('æ¢¯åº¦å€¼')\n",
    "    ax.set_title('æ¢¯åº¦éªŒè¯ï¼šè‡ªåŠ¨å¾®åˆ† vs æ•°å€¼è®¡ç®—')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nè‡ªåŠ¨å¾®åˆ†ç³»ç»ŸéªŒè¯å®Œæˆï¼æ¢¯åº¦è®¡ç®—æ­£ç¡®æ€§: {'âœ“' if difference.max() < 1e-4 else 'âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e6113",
   "metadata": {},
   "source": [
    "## 4. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "\n",
    "åœ¨PyTorchä¸­ï¼Œæ„å»ºç¥ç»ç½‘ç»œæ¨¡å‹ä¸»è¦é€šè¿‡ç»§æ‰¿`nn.Module`ç±»æ¥å®ç°ã€‚æˆ‘ä»¬å°†ä»ç®€å•çš„å…¨è¿æ¥ç½‘ç»œå¼€å§‹ï¼Œé€æ­¥æ„å»ºå¤æ‚çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 åŸºç¡€ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "print(\"=== è‡ªå®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹æ„å»º ===\")\n",
    "\n",
    "# 4.1.1 ç®€å•çš„å…¨è¿æ¥ç½‘ç»œ\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œ\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºå¹¶æµ‹è¯•ç®€å•ç½‘ç»œ\n",
    "simple_model = SimpleNN(input_size=784, hidden_size=128, output_size=10).to(device)\n",
    "print(f\"1. ç®€å•å…¨è¿æ¥ç½‘ç»œ:\")\n",
    "print(simple_model)\n",
    "\n",
    "# æŸ¥çœ‹æ¨¡å‹å‚æ•°\n",
    "total_params = sum(p.numel() for p in simple_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in simple_model.parameters() if p.requires_grad)\n",
    "print(f\"\\næ€»å‚æ•°æ•°é‡: {total_params:,}\")\n",
    "print(f\"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "\n",
    "# æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "test_input = torch.randn(32, 784, device=device)  # batch_size=32\n",
    "output = simple_model(test_input)\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {test_input.shape}\")\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "\n",
    "# 4.1.2 ä½¿ç”¨Sequentialæ„å»ºç½‘ç»œ\n",
    "print(f\"\\n2. ä½¿ç”¨Sequentialæ„å»ºç½‘ç»œ:\")\n",
    "\n",
    "sequential_model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "print(sequential_model)\n",
    "\n",
    "# 4.1.3 å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"å·ç§¯ç¥ç»ç½‘ç»œç”¨äºå›¾åƒåˆ†ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # å·ç§¯å±‚\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # æ± åŒ–å±‚\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)  # 28->14->7->3 (after 3 pooling)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # æ¿€æ´»å‡½æ•°å’Œæ­£åˆ™åŒ–\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ç¬¬ä¸€ä¸ªå·ç§¯å—\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # 28x28 -> 14x14\n",
    "        \n",
    "        # ç¬¬äºŒä¸ªå·ç§¯å—\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # 14x14 -> 7x7\n",
    "        \n",
    "        # ç¬¬ä¸‰ä¸ªå·ç§¯å—\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # 7x7 -> 3x3\n",
    "        \n",
    "        # å±•å¹³\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºCNNæ¨¡å‹\n",
    "cnn_model = ConvNet(num_classes=10).to(device)\n",
    "print(f\"\\n3. å·ç§¯ç¥ç»ç½‘ç»œ:\")\n",
    "print(cnn_model)\n",
    "\n",
    "# æµ‹è¯•CNN\n",
    "test_image = torch.randn(32, 1, 28, 28, device=device)  # MNISTæ ¼å¼\n",
    "cnn_output = cnn_model(test_image)\n",
    "print(f\"\\nCNNæµ‹è¯•:\")\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {test_image.shape}\")\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {cnn_output.shape}\")\n",
    "\n",
    "# è®¡ç®—å‚æ•°é‡\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "print(f\"CNNå‚æ•°æ•°é‡: {cnn_params:,}\")\n",
    "\n",
    "# 4.1.4 æ®‹å·®å—å’ŒResNeté£æ ¼ç½‘ç»œ\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"æ®‹å·®å—\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # å¦‚æœè¾“å…¥è¾“å‡ºé€šé“æ•°ä¸åŒï¼Œéœ€è¦è°ƒæ•´ç»´åº¦\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # æ·»åŠ æ®‹å·®è¿æ¥\n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SimpleResNet(nn.Module):\n",
    "    \"\"\"ç®€åŒ–çš„ResNet\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # æ®‹å·®å—\n",
    "        self.layer1 = self._make_layer(16, 16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(16, 32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(32, 64, 2, stride=2)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºResNetæ¨¡å‹\n",
    "resnet_model = SimpleResNet(num_classes=10).to(device)\n",
    "print(f\"\\n4. ç®€åŒ–ResNet:\")\n",
    "print(resnet_model)\n",
    "\n",
    "# æµ‹è¯•ResNet\n",
    "resnet_output = resnet_model(test_image)\n",
    "print(f\"\\nResNetæµ‹è¯•:\")\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {test_image.shape}\")\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {resnet_output.shape}\")\n",
    "\n",
    "resnet_params = sum(p.numel() for p in resnet_model.parameters())\n",
    "print(f\"ResNetå‚æ•°æ•°é‡: {resnet_params:,}\")\n",
    "\n",
    "# 4.1.5 è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"Swishæ¿€æ´»å‡½æ•°: x * sigmoid(x)\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    \"\"\"GELUæ¿€æ´»å‡½æ•°çš„è¿‘ä¼¼å®ç°\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "# æµ‹è¯•è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°\n",
    "print(f\"\\n5. è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°æµ‹è¯•:\")\n",
    "x = torch.linspace(-3, 3, 100, device=device)\n",
    "\n",
    "relu = nn.ReLU()\n",
    "swish = Swish().to(device)\n",
    "gelu = GELU().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_relu = relu(x)\n",
    "    y_swish = swish(x)\n",
    "    y_gelu = gelu(x)\n",
    "\n",
    "# å¯è§†åŒ–æ¿€æ´»å‡½æ•°\n",
    "if device.type == 'cpu':\n",
    "    x_np = x.numpy()\n",
    "    y_relu_np = y_relu.numpy()\n",
    "    y_swish_np = y_swish.numpy()\n",
    "    y_gelu_np = y_gelu.numpy()\n",
    "else:\n",
    "    x_np = x.cpu().numpy()\n",
    "    y_relu_np = y_relu.cpu().numpy()\n",
    "    y_swish_np = y_swish.cpu().numpy()\n",
    "    y_gelu_np = y_gelu.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_np, y_relu_np, label='ReLU', linewidth=2)\n",
    "plt.plot(x_np, y_swish_np, label='Swish', linewidth=2)\n",
    "plt.plot(x_np, y_gelu_np, label='GELU', linewidth=2)\n",
    "plt.plot(x_np, np.tanh(x_np), label='Tanh', linewidth=2, linestyle='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('ä¸åŒæ¿€æ´»å‡½æ•°çš„æ¯”è¾ƒ')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 4.1.6 æ¨¡å‹ä¿¡æ¯å’Œå¯è§†åŒ–å·¥å…·\n",
    "def model_summary(model, input_size):\n",
    "    \"\"\"æ¨¡å‹æ‘˜è¦ä¿¡æ¯\"\"\"\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "            \n",
    "            m_key = f\"{class_name}-{module_idx+1}\"\n",
    "            summary[m_key] = {}\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"output_shape\"] = list(output.size())\n",
    "            \n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            \n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "        \n",
    "        if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "    \n",
    "    # æ£€æŸ¥è®¾å¤‡ç±»å‹\n",
    "    device_type = next(model.parameters()).device\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•è¾“å…¥\n",
    "    if isinstance(input_size, tuple):\n",
    "        x = torch.rand(1, *input_size).to(device_type)\n",
    "    else:\n",
    "        x = torch.rand(input_size).to(device_type)\n",
    "    \n",
    "    summary = {}\n",
    "    hooks = []\n",
    "    \n",
    "    model.apply(register_hook)\n",
    "    model(x)\n",
    "    \n",
    "    # ç§»é™¤hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Layer (type)':>25} {'Output Shape':>15} {'Param #':>10}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    \n",
    "    for layer in summary:\n",
    "        output_shape = str(summary[layer][\"output_shape\"])\n",
    "        nb_params = summary[layer][\"nb_params\"]\n",
    "        \n",
    "        total_params += nb_params\n",
    "        print(f\"{layer:>25} {output_shape:>15} {nb_params:>10,}\")\n",
    "    \n",
    "    # è®¡ç®—å¯è®­ç»ƒå‚æ•°\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Trainable params: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {total_params - trainable_params:,}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\n6. æ¨¡å‹æ‘˜è¦ä¿¡æ¯:\")\n",
    "print(f\"\\nCNNæ¨¡å‹æ‘˜è¦:\")\n",
    "model_summary(cnn_model, (1, 28, 28))\n",
    "\n",
    "print(f\"\\nResNetæ¨¡å‹æ‘˜è¦:\")\n",
    "model_summary(resnet_model, (1, 28, 28))\n",
    "\n",
    "# 4.1.7 æ¨¡å‹åˆå§‹åŒ–\n",
    "def init_weights(m):\n",
    "    \"\"\"è‡ªå®šä¹‰æƒé‡åˆå§‹åŒ–\"\"\"\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "print(f\"\\n7. æ¨¡å‹æƒé‡åˆå§‹åŒ–:\")\n",
    "\n",
    "# åˆ›å»ºæ–°æ¨¡å‹è¿›è¡Œåˆå§‹åŒ–æ¼”ç¤º\n",
    "test_model = ConvNet().to(device)\n",
    "\n",
    "# æŸ¥çœ‹åˆå§‹åŒ–å‰çš„æƒé‡\n",
    "first_conv_weight = test_model.conv1.weight.data.clone()\n",
    "print(f\"åˆå§‹åŒ–å‰ç¬¬ä¸€å±‚å·ç§¯æƒé‡ç»Ÿè®¡:\")\n",
    "print(f\"  å‡å€¼: {first_conv_weight.mean().item():.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {first_conv_weight.std().item():.6f}\")\n",
    "\n",
    "# åº”ç”¨è‡ªå®šä¹‰åˆå§‹åŒ–\n",
    "test_model.apply(init_weights)\n",
    "\n",
    "# æŸ¥çœ‹åˆå§‹åŒ–åçš„æƒé‡\n",
    "after_conv_weight = test_model.conv1.weight.data\n",
    "print(f\"åˆå§‹åŒ–åç¬¬ä¸€å±‚å·ç§¯æƒé‡ç»Ÿè®¡:\")\n",
    "print(f\"  å‡å€¼: {after_conv_weight.mean().item():.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {after_conv_weight.std().item():.6f}\")\n",
    "\n",
    "print(f\"\\nâœ“ ç¥ç»ç½‘ç»œæ¨¡å‹æ„å»ºå­¦ä¹ å®Œæˆï¼\")\n",
    "\n",
    "# 4.1.8 æ¨¡å‹æ¯”è¾ƒè¡¨\n",
    "print(f\"\\n8. æ¨¡å‹å¤æ‚åº¦å¯¹æ¯”:\")\n",
    "models_comparison = {\n",
    "    'Simple NN': {'model': simple_model, 'params': sum(p.numel() for p in simple_model.parameters())},\n",
    "    'Sequential': {'model': sequential_model, 'params': sum(p.numel() for p in sequential_model.parameters())},\n",
    "    'CNN': {'model': cnn_model, 'params': sum(p.numel() for p in cnn_model.parameters())},\n",
    "    'ResNet': {'model': resnet_model, 'params': sum(p.numel() for p in resnet_model.parameters())}\n",
    "}\n",
    "\n",
    "print(f\"{'æ¨¡å‹':>12} {'å‚æ•°æ•°é‡':>15} {'ç›¸å¯¹å¤æ‚åº¦':>12}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "min_params = min(info['params'] for info in models_comparison.values())\n",
    "\n",
    "for name, info in models_comparison.items():\n",
    "    params = info['params']\n",
    "    relative_complexity = params / min_params\n",
    "    print(f\"{name:>12} {params:>15,} {relative_complexity:>12.1f}x\")\n",
    "\n",
    "# å¯è§†åŒ–æ¨¡å‹å¤æ‚åº¦\n",
    "model_names = list(models_comparison.keys())\n",
    "param_counts = [models_comparison[name]['params'] for name in model_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names, param_counts, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "plt.yscale('log')\n",
    "plt.ylabel('å‚æ•°æ•°é‡ (å¯¹æ•°åˆ»åº¦)')\n",
    "plt.title('ä¸åŒæ¨¡å‹çš„å‚æ•°å¤æ‚åº¦å¯¹æ¯”')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for i, (bar, count) in enumerate(zip(bars, param_counts)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1, \n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\næ¨¡å‹æ¶æ„è®¾è®¡è¦ç‚¹:\")\n",
    "print(f\"âœ“ æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹è§„æ¨¡\")\n",
    "print(f\"âœ“ ä½¿ç”¨æ‰¹å½’ä¸€åŒ–ç¨³å®šè®­ç»ƒè¿‡ç¨‹\")\n",
    "print(f\"âœ“ é€‚å½“ä½¿ç”¨Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ\")\n",
    "print(f\"âœ“ æ®‹å·®è¿æ¥æœ‰åŠ©äºè®­ç»ƒæ·±å±‚ç½‘ç»œ\")\n",
    "print(f\"âœ“ åˆé€‚çš„æƒé‡åˆå§‹åŒ–å¾ˆé‡è¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef177fd5",
   "metadata": {},
   "source": [
    "## 5. è‡ªå®šä¹‰æ•°æ®é›†ä¸æ•°æ®åŠ è½½\n",
    "\n",
    "åœ¨æ·±åº¦å­¦ä¹ é¡¹ç›®ä¸­ï¼Œæ•°æ®å¤„ç†æ˜¯å…³é”®ç¯èŠ‚ã€‚PyTorchæä¾›äº†çµæ´»çš„æ•°æ®åŠ è½½æœºåˆ¶ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ã€è¿›è¡Œæ•°æ®å¢å¼ºï¼Œä»¥åŠé«˜æ•ˆçš„æ•°æ®åŠ è½½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 MNISTæ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†\n",
    "print(\"=== è‡ªå®šä¹‰æ•°æ®é›†ä¸æ•°æ®åŠ è½½ ===\")\n",
    "\n",
    "# 5.1.1 æ ‡å‡†MNISTæ•°æ®é›†åŠ è½½\n",
    "print(\"1. æ ‡å‡†MNISTæ•°æ®é›†åŠ è½½:\")\n",
    "\n",
    "# å®šä¹‰æ•°æ®å˜æ¢\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # è½¬æ¢ä¸ºå¼ é‡ï¼ŒèŒƒå›´[0,1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNISTçš„å‡å€¼å’Œæ ‡å‡†å·®\n",
    "])\n",
    "\n",
    "# åŠ è½½MNISTæ•°æ®é›†\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=basic_transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=basic_transform\n",
    ")\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\n",
    "print(f\"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}\")\n",
    "print(f\"å›¾åƒå½¢çŠ¶: {train_dataset[0][0].shape}\")\n",
    "print(f\"æ ‡ç­¾èŒƒå›´: {min([label for _, label in train_dataset])} - {max([label for _, label in train_dataset])}\")\n",
    "\n",
    "# 5.1.2 è‡ªå®šä¹‰æ•°æ®é›†ç±»\n",
    "class CustomMNIST(Dataset):\n",
    "    \"\"\"è‡ªå®šä¹‰MNISTæ•°æ®é›†ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, data, targets, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, target = self.data[idx], self.targets[idx]\n",
    "        \n",
    "        # å¦‚æœæ˜¯PILå›¾åƒæˆ–numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºPIL\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = transforms.ToPILImage()(image)\n",
    "        else:\n",
    "            image = transforms.ToPILImage()(image.squeeze())\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# ä»åŸå§‹æ•°æ®é›†åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†\n",
    "custom_dataset = CustomMNIST(\n",
    "    data=train_dataset.data[:1000],  # ä½¿ç”¨å‰1000ä¸ªæ ·æœ¬\n",
    "    targets=train_dataset.targets[:1000],\n",
    "    transform=basic_transform\n",
    ")\n",
    "\n",
    "print(f\"\\nè‡ªå®šä¹‰æ•°æ®é›†å¤§å°: {len(custom_dataset)}\")\n",
    "\n",
    "# 5.1.3 æ•°æ®å¢å¼º\n",
    "print(f\"\\n2. æ•°æ®å¢å¼ºæŠ€æœ¯:\")\n",
    "\n",
    "# å®šä¹‰å„ç§æ•°æ®å¢å¼ºå˜æ¢\n",
    "data_augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # éšæœºæ—‹è½¬Â±10åº¦\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # éšæœºå¹³ç§»\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# æ›´æ¿€è¿›çš„æ•°æ®å¢å¼º\n",
    "aggressive_augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.15, 0.15), scale=(0.85, 1.15)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))  # éšæœºæ“¦é™¤\n",
    "])\n",
    "\n",
    "# åˆ›å»ºå¢å¼ºæ•°æ®é›†\n",
    "augmented_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    transform=data_augmentation\n",
    ")\n",
    "\n",
    "# å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ\n",
    "def visualize_augmentation(dataset, original_dataset, num_samples=8):\n",
    "    \"\"\"å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(16, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # åŸå§‹å›¾åƒ\n",
    "        orig_img, label = original_dataset[i]\n",
    "        if orig_img.dim() == 3 and orig_img.shape[0] == 1:\n",
    "            orig_img = orig_img.squeeze(0)\n",
    "        \n",
    "        axes[0, i].imshow(orig_img, cmap='gray')\n",
    "        axes[0, i].set_title(f'åŸå§‹ ({label})')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # å¢å¼ºåå›¾åƒ\n",
    "        aug_img, _ = dataset[i]\n",
    "        if aug_img.dim() == 3 and aug_img.shape[0] == 1:\n",
    "            aug_img = aug_img.squeeze(0)\n",
    "        \n",
    "        axes[1, i].imshow(aug_img, cmap='gray')\n",
    "        axes[1, i].set_title(f'å¢å¼º ({label})')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('æ•°æ®å¢å¼ºæ•ˆæœå¯¹æ¯”', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"æ•°æ®å¢å¼ºæ•ˆæœå¯è§†åŒ–:\")\n",
    "visualize_augmentation(augmented_dataset, train_dataset)\n",
    "\n",
    "# 5.1.4 æ•°æ®åŠ è½½å™¨é…ç½®\n",
    "print(f\"\\n3. æ•°æ®åŠ è½½å™¨é…ç½®:\")\n",
    "\n",
    "# ä¸åŒçš„æ•°æ®åŠ è½½å™¨é…ç½®\n",
    "dataloaders = {}\n",
    "\n",
    "# åŸºç¡€é…ç½®\n",
    "dataloaders['basic'] = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# é«˜æ€§èƒ½é…ç½®\n",
    "dataloaders['optimized'] = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# æµ‹è¯•ä¸åŒé…ç½®çš„åŠ è½½é€Ÿåº¦\n",
    "def benchmark_dataloader(dataloader, name, num_batches=50):\n",
    "    \"\"\"æµ‹è¯•æ•°æ®åŠ è½½å™¨æ€§èƒ½\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, (data, target) in enumerate(dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        # æ¨¡æ‹Ÿæ•°æ®ä¼ è¾“åˆ°GPU\n",
    "        data = data.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    samples_per_second = (num_batches * dataloader.batch_size) / total_time\n",
    "    \n",
    "    print(f\"{name:12}: {total_time:.2f}s, {samples_per_second:.0f} samples/s\")\n",
    "\n",
    "print(\"æ•°æ®åŠ è½½å™¨æ€§èƒ½æµ‹è¯•:\")\n",
    "for name, dataloader in dataloaders.items():\n",
    "    benchmark_dataloader(dataloader, name)\n",
    "\n",
    "# 5.1.5 æ•°æ®é›†åˆ†å‰²\n",
    "print(f\"\\n4. æ•°æ®é›†åˆ†å‰²:\")\n",
    "\n",
    "# å°†è®­ç»ƒé›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(\n",
    "    train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"åŸå§‹è®­ç»ƒé›†: {len(train_dataset)}\")\n",
    "print(f\"åˆ†å‰²åè®­ç»ƒé›†: {len(train_subset)}\")\n",
    "print(f\"éªŒè¯é›†: {len(val_subset)}\")\n",
    "\n",
    "# åˆ›å»ºå¯¹åº”çš„æ•°æ®åŠ è½½å™¨\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\n",
    "print(f\"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}\")\n",
    "print(f\"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}\")\n",
    "\n",
    "# 5.1.6 æ•°æ®åˆ†æå’Œå¯è§†åŒ–\n",
    "print(f\"\\n5. æ•°æ®åˆ†æ:\")\n",
    "\n",
    "# åˆ†æç±»åˆ«åˆ†å¸ƒ\n",
    "def analyze_dataset(dataset, name):\n",
    "    \"\"\"åˆ†ææ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒ\"\"\"\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        targets = dataset.targets\n",
    "    else:\n",
    "        # å¯¹äºsubsetï¼Œéœ€è¦æå–targets\n",
    "        targets = [dataset.dataset.targets[i] for i in dataset.indices]\n",
    "        targets = torch.tensor(targets)\n",
    "    \n",
    "    unique, counts = torch.unique(targets, return_counts=True)\n",
    "    \n",
    "    print(f\"\\n{name} ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "    for digit, count in zip(unique.tolist(), counts.tolist()):\n",
    "        percentage = count / len(targets) * 100\n",
    "        print(f\"  æ•°å­— {digit}: {count:5d} æ ·æœ¬ ({percentage:5.1f}%)\")\n",
    "    \n",
    "    return targets\n",
    "\n",
    "# åˆ†æå„ä¸ªæ•°æ®é›†\n",
    "train_targets = analyze_dataset(train_subset, \"è®­ç»ƒé›†\")\n",
    "val_targets = analyze_dataset(val_subset, \"éªŒè¯é›†\")\n",
    "test_targets = analyze_dataset(test_dataset, \"æµ‹è¯•é›†\")\n",
    "\n",
    "# å¯è§†åŒ–ç±»åˆ«åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "datasets_info = [\n",
    "    (\"è®­ç»ƒé›†\", train_targets),\n",
    "    (\"éªŒè¯é›†\", val_targets), \n",
    "    (\"æµ‹è¯•é›†\", test_targets)\n",
    "]\n",
    "\n",
    "for idx, (name, targets) in enumerate(datasets_info):\n",
    "    unique, counts = torch.unique(targets, return_counts=True)\n",
    "    \n",
    "    axes[idx].bar(unique.numpy(), counts.numpy())\n",
    "    axes[idx].set_title(f'{name}ç±»åˆ«åˆ†å¸ƒ')\n",
    "    axes[idx].set_xlabel('æ•°å­—')\n",
    "    axes[idx].set_ylabel('æ ·æœ¬æ•°é‡')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.1.7 æ‰¹æ¬¡æ•°æ®å¯è§†åŒ–\n",
    "def visualize_batch(dataloader, num_samples=16):\n",
    "    \"\"\"å¯è§†åŒ–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®\"\"\"\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # é€‰æ‹©è¦æ˜¾ç¤ºçš„æ ·æœ¬æ•°\n",
    "    num_samples = min(num_samples, len(images))\n",
    "    \n",
    "    # è®¡ç®—ç½‘æ ¼å¤§å°\n",
    "    grid_size = int(np.ceil(np.sqrt(num_samples)))\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = images[i]\n",
    "        if img.dim() == 3 and img.shape[0] == 1:\n",
    "            img = img.squeeze(0)\n",
    "        \n",
    "        # åå½’ä¸€åŒ–ä»¥ä¾¿æ˜¾ç¤º\n",
    "        img = img * 0.3081 + 0.1307\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # éšè—å¤šä½™çš„å­å›¾\n",
    "    for i in range(num_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('è®­ç»ƒæ‰¹æ¬¡æ•°æ®æ ·æœ¬', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\n6. æ‰¹æ¬¡æ•°æ®å¯è§†åŒ–:\")\n",
    "visualize_batch(train_loader, 16)\n",
    "\n",
    "# 5.1.8 æ•°æ®ç»Ÿè®¡åˆ†æ\n",
    "print(f\"\\n7. æ•°æ®ç»Ÿè®¡åˆ†æ:\")\n",
    "\n",
    "def compute_dataset_stats(dataloader):\n",
    "    \"\"\"è®¡ç®—æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for data, _ in dataloader:\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        total_samples += batch_samples\n",
    "    \n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# è®¡ç®—è®­ç»ƒé›†ç»Ÿè®¡ä¿¡æ¯\n",
    "train_mean, train_std = compute_dataset_stats(train_loader)\n",
    "print(f\"è®­ç»ƒé›†ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "print(f\"  å‡å€¼: {train_mean.item():.4f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {train_std.item():.4f}\")\n",
    "\n",
    "# éªŒè¯é¢„å®šä¹‰çš„å½’ä¸€åŒ–å‚æ•°\n",
    "print(f\"é¢„å®šä¹‰MNISTå½’ä¸€åŒ–å‚æ•°:\")\n",
    "print(f\"  å‡å€¼: 0.1307\")\n",
    "print(f\"  æ ‡å‡†å·®: 0.3081\")\n",
    "\n",
    "# 5.1.9 å†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–\n",
    "print(f\"\\n8. å†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–:\")\n",
    "\n",
    "# å†…å­˜æ˜ å°„æ•°æ®é›†\n",
    "class MemoryMappedDataset(Dataset):\n",
    "    \"\"\"å†…å­˜æ˜ å°„æ•°æ®é›†ï¼Œé€‚ç”¨äºå¤§æ•°æ®é›†\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, transform=None):\n",
    "        # è¿™é‡Œç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶\n",
    "        self.data = train_dataset.data\n",
    "        self.targets = train_dataset.targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # æ‡’åŠ è½½ï¼Œåªåœ¨éœ€è¦æ—¶åŠ è½½æ•°æ®\n",
    "        image = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            # è½¬æ¢ä¸ºPILå›¾åƒä»¥åº”ç”¨transform\n",
    "            image = transforms.ToPILImage()(image)\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = image.float() / 255.0\n",
    "            image = image.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# é¢„å–æ•°æ®åŠ è½½å™¨\n",
    "class PrefetchLoader:\n",
    "    \"\"\"æ•°æ®é¢„å–åŠ è½½å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, loader):\n",
    "        self.loader = loader\n",
    "        self.stream = torch.cuda.Stream() if torch.cuda.is_available() else None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        loader_iter = iter(self.loader)\n",
    "        self.preload(loader_iter)\n",
    "        \n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream) if self.stream else None\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload(loader_iter)\n",
    "            yield input, target\n",
    "    \n",
    "    def preload(self, loader_iter):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(loader_iter)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        \n",
    "        if self.stream:\n",
    "            with torch.cuda.stream(self.stream):\n",
    "                self.next_input = self.next_input.cuda(non_blocking=True)\n",
    "                self.next_target = self.next_target.cuda(non_blocking=True)\n",
    "\n",
    "# æµ‹è¯•ä¼˜åŒ–åçš„æ•°æ®åŠ è½½\n",
    "optimized_dataset = MemoryMappedDataset('./data', basic_transform)\n",
    "optimized_loader = DataLoader(\n",
    "    optimized_dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(\"æ•°æ®åŠ è½½ä¼˜åŒ–æŠ€æœ¯:\")\n",
    "print(\"âœ“ å†…å­˜æ˜ å°„å‡å°‘å†…å­˜å ç”¨\")\n",
    "print(\"âœ“ pin_memoryåŠ é€ŸGPUä¼ è¾“\")\n",
    "print(\"âœ“ persistent_workerså‡å°‘è¿›ç¨‹åˆ›å»ºå¼€é”€\")\n",
    "print(\"âœ“ non_blockingä¼ è¾“æé«˜å¹¶è¡Œåº¦\")\n",
    "\n",
    "print(f\"\\nâœ“ æ•°æ®é›†å’Œæ•°æ®åŠ è½½å­¦ä¹ å®Œæˆï¼\")\n",
    "\n",
    "# ä¿å­˜æ•°æ®åŠ è½½å™¨é…ç½®ä¿¡æ¯\n",
    "data_config = {\n",
    "    'train_size': len(train_subset),\n",
    "    'val_size': len(val_subset),\n",
    "    'test_size': len(test_dataset),\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "    'normalize_mean': 0.1307,\n",
    "    'normalize_std': 0.3081\n",
    "}\n",
    "\n",
    "print(f\"\\næ•°æ®é…ç½®ä¿¡æ¯:\")\n",
    "for key, value in data_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# å°†æ•°æ®åŠ è½½å™¨ä¿å­˜ä¸ºå…¨å±€å˜é‡ä¾›åç»­ä½¿ç”¨\n",
    "globals()['train_loader'] = train_loader\n",
    "globals()['val_loader'] = val_loader\n",
    "globals()['test_loader'] = test_loader\n",
    "globals()['data_config'] = data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265743c8",
   "metadata": {},
   "source": [
    "## 6. å®Œæ•´è®­ç»ƒæµç¨‹\n",
    "\n",
    "å®ç°ä¸€ä¸ªå®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•çš„å¾ªç¯ï¼ŒæŸå¤±å‡½æ•°é€‰æ‹©ï¼Œä¼˜åŒ–å™¨é…ç½®ï¼Œä»¥åŠå­¦ä¹ ç‡è°ƒåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 è®­ç»ƒé…ç½®å’Œåˆå§‹åŒ–\n",
    "print(\"=== å®Œæ•´è®­ç»ƒæµç¨‹ ===\")\n",
    "\n",
    "# 6.1.1 è®­ç»ƒé…ç½®\n",
    "class TrainingConfig:\n",
    "    \"\"\"è®­ç»ƒé…ç½®ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # æ¨¡å‹é…ç½®\n",
    "        self.model_name = \"CNN_MNIST\"\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # è®­ç»ƒé…ç½®\n",
    "        self.epochs = 20\n",
    "        self.batch_size = 64\n",
    "        self.learning_rate = 0.001\n",
    "        self.weight_decay = 1e-4\n",
    "        \n",
    "        # ä¼˜åŒ–å™¨é…ç½®\n",
    "        self.optimizer_type = \"Adam\"  # Adam, SGD, AdamW\n",
    "        self.momentum = 0.9  # for SGD\n",
    "        \n",
    "        # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        self.scheduler_type = \"StepLR\"  # StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "        self.step_size = 7\n",
    "        self.gamma = 0.1\n",
    "        self.patience = 5  # for ReduceLROnPlateau\n",
    "        \n",
    "        # æ—©åœé…ç½®\n",
    "        self.early_stopping = True\n",
    "        self.early_stopping_patience = 10\n",
    "        self.min_delta = 0.001\n",
    "        \n",
    "        # è®¾å¤‡å’Œè·¯å¾„\n",
    "        self.device = device\n",
    "        self.save_dir = Path(\"checkpoints\")\n",
    "        self.log_dir = Path(\"logs\")\n",
    "        \n",
    "        # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "        self.use_amp = torch.cuda.is_available()\n",
    "        \n",
    "        # æ—¥å¿—å’Œä¿å­˜\n",
    "        self.save_best_only = True\n",
    "        self.save_frequency = 5  # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡\n",
    "        self.log_frequency = 100  # æ¯100ä¸ªbatchè®°å½•ä¸€æ¬¡\n",
    "\n",
    "config = TrainingConfig()\n",
    "\n",
    "print(f\"è®­ç»ƒé…ç½®:\")\n",
    "print(f\"  æ¨¡å‹: {config.model_name}\")\n",
    "print(f\"  è®­ç»ƒè½®æ•°: {config.epochs}\")\n",
    "print(f\"  æ‰¹æ¬¡å¤§å°: {config.batch_size}\")\n",
    "print(f\"  å­¦ä¹ ç‡: {config.learning_rate}\")\n",
    "print(f\"  ä¼˜åŒ–å™¨: {config.optimizer_type}\")\n",
    "print(f\"  è®¾å¤‡: {config.device}\")\n",
    "print(f\"  æ··åˆç²¾åº¦: {config.use_amp}\")\n",
    "\n",
    "# 6.1.2 æ¨¡å‹åˆå§‹åŒ–\n",
    "# ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„CNNæ¨¡å‹\n",
    "model = ConvNet(num_classes=config.num_classes).to(config.device)\n",
    "\n",
    "# åº”ç”¨æƒé‡åˆå§‹åŒ–\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f\"\\næ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 6.1.3 æŸå¤±å‡½æ•°\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6.1.4 ä¼˜åŒ–å™¨é…ç½®\n",
    "def get_optimizer(model, config):\n",
    "    \"\"\"æ ¹æ®é…ç½®è·å–ä¼˜åŒ–å™¨\"\"\"\n",
    "    if config.optimizer_type == \"Adam\":\n",
    "        return optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "    elif config.optimizer_type == \"SGD\":\n",
    "        return optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "            momentum=config.momentum,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "    elif config.optimizer_type == \"AdamW\":\n",
    "        return optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {config.optimizer_type}\")\n",
    "\n",
    "optimizer = get_optimizer(model, config)\n",
    "\n",
    "# 6.1.5 å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "def get_scheduler(optimizer, config):\n",
    "    \"\"\"æ ¹æ®é…ç½®è·å–å­¦ä¹ ç‡è°ƒåº¦å™¨\"\"\"\n",
    "    if config.scheduler_type == \"StepLR\":\n",
    "        return StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "    elif config.scheduler_type == \"ReduceLROnPlateau\":\n",
    "        return ReduceLROnPlateau(\n",
    "            optimizer, mode='min', patience=config.patience,\n",
    "            factor=config.gamma, verbose=True\n",
    "        )\n",
    "    elif config.scheduler_type == \"CosineAnnealingLR\":\n",
    "        return CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "scheduler = get_scheduler(optimizer, config)\n",
    "\n",
    "# 6.1.6 æ—©åœæœºåˆ¶\n",
    "class EarlyStopping:\n",
    "    \"\"\"æ—©åœæœºåˆ¶\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config.early_stopping_patience,\n",
    "    min_delta=config.min_delta\n",
    ") if config.early_stopping else None\n",
    "\n",
    "# 6.1.7 æ··åˆç²¾åº¦è®­ç»ƒè®¾ç½®\n",
    "scaler = torch.cuda.amp.GradScaler() if config.use_amp else None\n",
    "\n",
    "print(f\"\\nè®­ç»ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆ:\")\n",
    "print(f\"âœ“ æ¨¡å‹: {type(model).__name__}\")\n",
    "print(f\"âœ“ æŸå¤±å‡½æ•°: {type(criterion).__name__}\")\n",
    "print(f\"âœ“ ä¼˜åŒ–å™¨: {type(optimizer).__name__}\")\n",
    "print(f\"âœ“ è°ƒåº¦å™¨: {type(scheduler).__name__ if scheduler else None}\")\n",
    "print(f\"âœ“ æ—©åœ: {'å¯ç”¨' if early_stopping else 'ç¦ç”¨'}\")\n",
    "print(f\"âœ“ æ··åˆç²¾åº¦: {'å¯ç”¨' if scaler else 'ç¦ç”¨'}\")\n",
    "\n",
    "# 6.2 è®­ç»ƒå’ŒéªŒè¯å‡½æ•°\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scaler, device, epoch, config):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # åˆ›å»ºè¿›åº¦æ¡\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs} [Train]')\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler is not None:\n",
    "            # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # å¸¸è§„è®­ç»ƒ\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦æ¡\n",
    "        if batch_idx % config.log_frequency == 0:\n",
    "            current_acc = 100. * correct / total\n",
    "            current_loss = running_loss / (batch_idx + 1)\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{current_loss:.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, epoch, config):\n",
    "    \"\"\"éªŒè¯ä¸€ä¸ªepoch\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{config.epochs} [Val]')\n",
    "        \n",
    "        for data, target in pbar:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            current_acc = 100. * correct / total\n",
    "            current_loss = val_loss / (len(pbar.n) + 1) if hasattr(pbar, 'n') else 0\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{current_loss:.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = val_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# 6.3 è®­ç»ƒå†å²è®°å½•\n",
    "class TrainingHistory:\n",
    "    \"\"\"è®­ç»ƒå†å²è®°å½•\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        self.epochs = []\n",
    "        \n",
    "    def update(self, epoch, train_loss, train_acc, val_loss, val_acc, lr):\n",
    "        self.epochs.append(epoch)\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accuracies.append(train_acc)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accuracies.append(val_acc)\n",
    "        self.learning_rates.append(lr)\n",
    "    \n",
    "    def save(self, filepath):\n",
    "        \"\"\"ä¿å­˜è®­ç»ƒå†å²\"\"\"\n",
    "        history_dict = {\n",
    "            'epochs': self.epochs,\n",
    "            'train_losses': self.train_losses,\n",
    "            'train_accuracies': self.train_accuracies,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_accuracies': self.val_accuracies,\n",
    "            'learning_rates': self.learning_rates\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(history_dict, f, indent=2)\n",
    "    \n",
    "    def load(self, filepath):\n",
    "        \"\"\"åŠ è½½è®­ç»ƒå†å²\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            history_dict = json.load(f)\n",
    "        \n",
    "        self.epochs = history_dict['epochs']\n",
    "        self.train_losses = history_dict['train_losses']\n",
    "        self.train_accuracies = history_dict['train_accuracies']\n",
    "        self.val_losses = history_dict['val_losses']\n",
    "        self.val_accuracies = history_dict['val_accuracies']\n",
    "        self.learning_rates = history_dict['learning_rates']\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # æŸå¤±æ›²çº¿\n",
    "        axes[0, 0].plot(self.epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        axes[0, 0].plot(self.epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        axes[0, 0].set_title('Training and Validation Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # å‡†ç¡®ç‡æ›²çº¿\n",
    "        axes[0, 1].plot(self.epochs, self.train_accuracies, 'b-', label='Train Acc')\n",
    "        axes[0, 1].plot(self.epochs, self.val_accuracies, 'r-', label='Val Acc')\n",
    "        axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # å­¦ä¹ ç‡æ›²çº¿\n",
    "        axes[1, 0].plot(self.epochs, self.learning_rates, 'g-')\n",
    "        axes[1, 0].set_title('Learning Rate Schedule')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # éªŒè¯æŸå¤±vså‡†ç¡®ç‡æ•£ç‚¹å›¾\n",
    "        axes[1, 1].scatter(self.val_losses, self.val_accuracies, c=self.epochs, cmap='viridis')\n",
    "        axes[1, 1].set_title('Validation Loss vs Accuracy')\n",
    "        axes[1, 1].set_xlabel('Validation Loss')\n",
    "        axes[1, 1].set_ylabel('Validation Accuracy (%)')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "history = TrainingHistory()\n",
    "\n",
    "# 6.4 ä¸»è®­ç»ƒå¾ªç¯\n",
    "print(f\"\\nå¼€å§‹è®­ç»ƒ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # è®­ç»ƒé˜¶æ®µ\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, epoch, config\n",
    "        )\n",
    "        \n",
    "        # éªŒè¯é˜¶æ®µ\n",
    "        val_loss, val_acc = validate_epoch(\n",
    "            model, val_loader, criterion, device, epoch, config\n",
    "        )\n",
    "        \n",
    "        # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # è®°å½•å½“å‰å­¦ä¹ ç‡\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # æ›´æ–°è®­ç»ƒå†å²\n",
    "        history.update(epoch, train_loss, train_acc, val_loss, val_acc, current_lr)\n",
    "        \n",
    "        # è®¡ç®—epochæ—¶é—´\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # æ‰“å°epochç»“æœ\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "        print(f\"  Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'config': config.__dict__\n",
    "            }, config.save_dir / 'best_model.pth')\n",
    "            print(f\"  âœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (Val Acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹\n",
    "        if (epoch + 1) % config.save_frequency == 0:\n",
    "            checkpoint_path = config.save_dir / f'checkpoint_epoch_{epoch+1}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'history': history.__dict__,\n",
    "                'config': config.__dict__\n",
    "            }, checkpoint_path)\n",
    "            print(f\"  âœ“ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path.name}\")\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if early_stopping:\n",
    "            if early_stopping(val_loss, model):\n",
    "                print(f\"  Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "\n",
    "# è®­ç»ƒå®Œæˆç»Ÿè®¡\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"æ€»è®­ç»ƒæ—¶é—´: {total_time/60:.1f} åˆ†é’Ÿ\")\n",
    "print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "\n",
    "# ä¿å­˜è®­ç»ƒå†å²\n",
    "history.save(config.log_dir / 'training_history.json')\n",
    "print(f\"è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {config.log_dir / 'training_history.json'}\")\n",
    "\n",
    "# å¯è§†åŒ–è®­ç»ƒå†å²\n",
    "print(f\"\\nç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿:\")\n",
    "history.plot()\n",
    "\n",
    "print(f\"\\nâœ“ å®Œæ•´è®­ç»ƒæµç¨‹æ¼”ç¤ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe468d00",
   "metadata": {},
   "source": [
    "## 7. æ–­ç‚¹ä¿å­˜ä¸æ¢å¤ (Checkpoint & Resume)\n",
    "\n",
    "åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œæ–­ç‚¹ä¿å­˜ä¸æ¢å¤åŠŸèƒ½è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé•¿æ—¶é—´è®­ç»ƒçš„æ¨¡å‹ã€‚è¿™å¯ä»¥è®©æˆ‘ä»¬ï¼š\n",
    "- åœ¨è®­ç»ƒæ„å¤–ä¸­æ–­åæ¢å¤è®­ç»ƒ\n",
    "- åœ¨ä¸åŒå®éªŒä¹‹é—´ç»§ç»­è®­ç»ƒ\n",
    "- ä¿å­˜å’ŒåŠ è½½æœ€ä½³æ¨¡å‹\n",
    "- å®ç°å¢é‡è®­ç»ƒ\n",
    "\n",
    "### 7.1 æ–­ç‚¹ä¿å­˜ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d029216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "class CheckpointManager:\n",
    "    \"\"\"\n",
    "    æ–­ç‚¹ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤\n",
    "    \"\"\"\n",
    "    def __init__(self, save_dir, max_checkpoints=5):\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.max_checkpoints = max_checkpoints\n",
    "        \n",
    "    def save_checkpoint(self, state, epoch, is_best=False, suffix=\"\"):\n",
    "        \"\"\"ä¿å­˜æ–­ç‚¹\"\"\"\n",
    "        # åŸºæœ¬æ£€æŸ¥ç‚¹\n",
    "        checkpoint_name = f\"checkpoint_epoch_{epoch}{suffix}.pth\"\n",
    "        checkpoint_path = self.save_dir / checkpoint_name\n",
    "        \n",
    "        # æ·»åŠ æ—¶é—´æˆ³\n",
    "        state['save_time'] = datetime.now().isoformat()\n",
    "        \n",
    "        torch.save(state, checkpoint_path)\n",
    "        print(f\"âœ“ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}\")\n",
    "        \n",
    "        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜ä¸€ä»½\n",
    "        if is_best:\n",
    "            best_path = self.save_dir / \"best_model.pth\"\n",
    "            shutil.copy2(checkpoint_path, best_path)\n",
    "            print(f\"âœ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}\")\n",
    "        \n",
    "        # æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹\n",
    "        self._cleanup_checkpoints()\n",
    "        \n",
    "        return checkpoint_path\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path, model, optimizer=None, scheduler=None):\n",
    "        \"\"\"åŠ è½½æ–­ç‚¹\"\"\"\n",
    "        checkpoint_path = Path(checkpoint_path)\n",
    "        \n",
    "        if not checkpoint_path.exists():\n",
    "            raise FileNotFoundError(f\"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}\")\n",
    "        \n",
    "        print(f\"ğŸ”„ æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        # åŠ è½½æ¨¡å‹çŠ¶æ€\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€\n",
    "        if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€\n",
    "        if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "            if checkpoint['scheduler_state_dict'] is not None:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        print(f\"âœ“ æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹ (Epoch {checkpoint.get('epoch', 'Unknown')})\")\n",
    "        return checkpoint\n",
    "    \n",
    "    def find_latest_checkpoint(self):\n",
    "        \"\"\"æŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹\"\"\"\n",
    "        checkpoints = list(self.save_dir.glob(\"checkpoint_epoch_*.pth\"))\n",
    "        if not checkpoints:\n",
    "            return None\n",
    "        \n",
    "        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº\n",
    "        latest = max(checkpoints, key=lambda x: x.stat().st_mtime)\n",
    "        return latest\n",
    "    \n",
    "    def list_checkpoints(self):\n",
    "        \"\"\"åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹\"\"\"\n",
    "        checkpoints = list(self.save_dir.glob(\"checkpoint_epoch_*.pth\"))\n",
    "        checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        \n",
    "        print(f\"\\nğŸ“ æ£€æŸ¥ç‚¹ç›®å½•: {self.save_dir}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if not checkpoints:\n",
    "            print(\"æš‚æ— æ£€æŸ¥ç‚¹æ–‡ä»¶\")\n",
    "            return []\n",
    "        \n",
    "        for i, ckpt in enumerate(checkpoints):\n",
    "            # å°è¯•è¯»å–æ£€æŸ¥ç‚¹ä¿¡æ¯\n",
    "            try:\n",
    "                state = torch.load(ckpt, map_location='cpu')\n",
    "                epoch = state.get('epoch', 'Unknown')\n",
    "                val_acc = state.get('val_acc', 'Unknown')\n",
    "                save_time = state.get('save_time', 'Unknown')\n",
    "                size = ckpt.stat().st_size / (1024 * 1024)  # MB\n",
    "                \n",
    "                print(f\"{i+1:2d}. {ckpt.name}\")\n",
    "                print(f\"     Epoch: {epoch}, Val Acc: {val_acc}, Size: {size:.1f}MB\")\n",
    "                print(f\"     Time: {save_time}\")\n",
    "                print()\n",
    "            except Exception as e:\n",
    "                print(f\"{i+1:2d}. {ckpt.name} (æ— æ³•è¯»å–: {e})\")\n",
    "        \n",
    "        return checkpoints\n",
    "    \n",
    "    def _cleanup_checkpoints(self):\n",
    "        \"\"\"æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™æœ€æ–°çš„å‡ ä¸ª\"\"\"\n",
    "        checkpoints = list(self.save_dir.glob(\"checkpoint_epoch_*.pth\"))\n",
    "        if len(checkpoints) <= self.max_checkpoints:\n",
    "            return\n",
    "        \n",
    "        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„\n",
    "        checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        for old_ckpt in checkpoints[self.max_checkpoints:]:\n",
    "            old_ckpt.unlink()\n",
    "            print(f\"ğŸ—‘ï¸  å·²åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {old_ckpt.name}\")\n",
    "\n",
    "# ç¤ºä¾‹ï¼šåˆ›å»ºæ£€æŸ¥ç‚¹ç®¡ç†å™¨\n",
    "checkpoint_manager = CheckpointManager(save_dir=\"./checkpoints\", max_checkpoints=3)\n",
    "\n",
    "print(\"âœ“ æ–­ç‚¹ç®¡ç†å™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de3ae3",
   "metadata": {},
   "source": [
    "### 7.2 æ¢å¤è®­ç»ƒåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a502ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_training(checkpoint_path, model, optimizer, scheduler=None, config=None):\n",
    "    \"\"\"\n",
    "    ä»æ–­ç‚¹æ¢å¤è®­ç»ƒ\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: æ–­ç‚¹æ–‡ä»¶è·¯å¾„\n",
    "        model: æ¨¡å‹å®ä¾‹\n",
    "        optimizer: ä¼˜åŒ–å™¨\n",
    "        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "        config: é…ç½®å¯¹è±¡\n",
    "    \n",
    "    Returns:\n",
    "        start_epoch: å¼€å§‹çš„epoch\n",
    "        history: è®­ç»ƒå†å²\n",
    "        best_val_acc: æœ€ä½³éªŒè¯å‡†ç¡®ç‡\n",
    "    \"\"\"\n",
    "    \n",
    "    checkpoint = checkpoint_manager.load_checkpoint(\n",
    "        checkpoint_path, model, optimizer, scheduler\n",
    "    )\n",
    "    \n",
    "    # è·å–æ¢å¤ä¿¡æ¯\n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    best_val_acc = checkpoint.get('val_acc', 0.0)\n",
    "    \n",
    "    # æ¢å¤è®­ç»ƒå†å²\n",
    "    history = TrainingHistory()\n",
    "    if 'history' in checkpoint:\n",
    "        history.__dict__.update(checkpoint['history'])\n",
    "    \n",
    "    # æ¢å¤é…ç½®\n",
    "    if config is None and 'config' in checkpoint:\n",
    "        config = SimpleNamespace(**checkpoint['config'])\n",
    "    \n",
    "    print(f\"ğŸš€ å‡†å¤‡ä» Epoch {start_epoch} æ¢å¤è®­ç»ƒ\")\n",
    "    print(f\"ğŸ“Š å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return start_epoch, history, best_val_acc, config\n",
    "\n",
    "# æ¼”ç¤ºï¼šæ¨¡æ‹Ÿæ¢å¤è®­ç»ƒæµç¨‹\n",
    "def demo_resume_training():\n",
    "    \"\"\"æ¼”ç¤ºæ¢å¤è®­ç»ƒçš„å®Œæ•´æµç¨‹\"\"\"\n",
    "    \n",
    "    print(\"=== æ–­ç‚¹æ¢å¤è®­ç»ƒæ¼”ç¤º ===\\n\")\n",
    "    \n",
    "    # 1. æŸ¥çœ‹å¯ç”¨çš„æ£€æŸ¥ç‚¹\n",
    "    print(\"1. æŸ¥çœ‹å¯ç”¨çš„æ£€æŸ¥ç‚¹:\")\n",
    "    available_checkpoints = checkpoint_manager.list_checkpoints()\n",
    "    \n",
    "    if not available_checkpoints:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œä¸€äº›è®­ç»ƒ\")\n",
    "        return\n",
    "    \n",
    "    # 2. é€‰æ‹©æœ€æ–°çš„æ£€æŸ¥ç‚¹è¿›è¡Œæ¢å¤\n",
    "    latest_checkpoint = checkpoint_manager.find_latest_checkpoint()\n",
    "    print(f\"2. é€‰æ‹©æœ€æ–°æ£€æŸ¥ç‚¹: {latest_checkpoint.name}\")\n",
    "    \n",
    "    # 3. é‡æ–°åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨ï¼ˆæ¨¡æ‹Ÿæ–°çš„è®­ç»ƒä¼šè¯ï¼‰\n",
    "    print(\"\\n3. é‡æ–°åˆ›å»ºæ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨...\")\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    # 4. æ¢å¤è®­ç»ƒçŠ¶æ€\n",
    "    print(\"\\n4. æ¢å¤è®­ç»ƒçŠ¶æ€...\")\n",
    "    try:\n",
    "        start_epoch, history, best_val_acc, restored_config = resume_training(\n",
    "            latest_checkpoint, model, optimizer, scheduler\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ æˆåŠŸæ¢å¤è®­ç»ƒçŠ¶æ€!\")\n",
    "        print(f\"  - ä¸‹ä¸€ä¸ªè®­ç»ƒepoch: {start_epoch}\")\n",
    "        print(f\"  - å†å²æœ€ä½³å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "        print(f\"  - å·²æ¢å¤è®­ç»ƒå†å²: {len(history.train_losses)} ä¸ªepochs\")\n",
    "        \n",
    "        # 5. å¯ä»¥ç»§ç»­è®­ç»ƒï¼ˆè¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œä¸å®é™…è¿è¡Œï¼‰\n",
    "        print(f\"\\n5. ç°åœ¨å¯ä»¥ä» epoch {start_epoch} ç»§ç»­è®­ç»ƒ...\")\n",
    "        print(\"   (ä¸ºäº†æ¼”ç¤ºç›®çš„ï¼Œè¿™é‡Œä¸å®é™…æ‰§è¡Œè®­ç»ƒå¾ªç¯)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¢å¤è®­ç»ƒå¤±è´¥: {e}\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demo_resume_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a1193",
   "metadata": {},
   "source": [
    "## 8. TensorBoard å¯è§†åŒ–\n",
    "\n",
    "TensorBoard æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬ï¼š\n",
    "- ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å’ŒæŒ‡æ ‡\n",
    "- å¯è§†åŒ–æ¨¡å‹ç»“æ„\n",
    "- è§‚å¯Ÿæƒé‡å’Œæ¢¯åº¦çš„åˆ†å¸ƒ\n",
    "- æ¯”è¾ƒä¸åŒå®éªŒçš„ç»“æœ\n",
    "\n",
    "### 8.1 TensorBoard åŸºç¡€ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "class TensorBoardLogger:\n",
    "    \"\"\"\n",
    "    TensorBoard æ—¥å¿—è®°å½•å™¨\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir, experiment_name=None):\n",
    "        if experiment_name is None:\n",
    "            experiment_name = f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        self.log_dir = Path(log_dir) / experiment_name\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir=str(self.log_dir))\n",
    "        self.step = 0\n",
    "        \n",
    "        print(f\"ğŸ“Š TensorBoard æ—¥å¿—ç›®å½•: {self.log_dir}\")\n",
    "        print(f\"ğŸ’¡ å¯åŠ¨TensorBoard: tensorboard --logdir {log_dir}\")\n",
    "    \n",
    "    def log_scalar(self, tag, value, step=None):\n",
    "        \"\"\"è®°å½•æ ‡é‡å€¼\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        self.writer.add_scalar(tag, value, step)\n",
    "    \n",
    "    def log_scalars(self, tag_dict, step=None):\n",
    "        \"\"\"è®°å½•å¤šä¸ªæ ‡é‡å€¼\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        for tag, value in tag_dict.items():\n",
    "            self.writer.add_scalar(tag, value, step)\n",
    "    \n",
    "    def log_histogram(self, tag, values, step=None):\n",
    "        \"\"\"è®°å½•ç›´æ–¹å›¾\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        self.writer.add_histogram(tag, values, step)\n",
    "    \n",
    "    def log_image(self, tag, image, step=None):\n",
    "        \"\"\"è®°å½•å›¾åƒ\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        self.writer.add_image(tag, image, step)\n",
    "    \n",
    "    def log_images(self, tag, images, step=None):\n",
    "        \"\"\"è®°å½•å›¾åƒç½‘æ ¼\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        grid = vutils.make_grid(images, normalize=True, scale_each=True)\n",
    "        self.writer.add_image(tag, grid, step)\n",
    "    \n",
    "    def log_model_graph(self, model, input_tensor):\n",
    "        \"\"\"è®°å½•æ¨¡å‹è®¡ç®—å›¾\"\"\"\n",
    "        self.writer.add_graph(model, input_tensor)\n",
    "    \n",
    "    def log_model_weights(self, model, step=None):\n",
    "        \"\"\"è®°å½•æ¨¡å‹æƒé‡åˆ†å¸ƒ\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.writer.add_histogram(f\"weights/{name}\", param.data, step)\n",
    "                if param.grad is not None:\n",
    "                    self.writer.add_histogram(f\"gradients/{name}\", param.grad.data, step)\n",
    "    \n",
    "    def log_learning_rate(self, optimizer, step=None):\n",
    "        \"\"\"è®°å½•å­¦ä¹ ç‡\"\"\"\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "        \n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = param_group['lr']\n",
    "            self.writer.add_scalar(f\"learning_rate/group_{i}\", lr, step)\n",
    "    \n",
    "    def increment_step(self):\n",
    "        \"\"\"å¢åŠ æ­¥æ•°\"\"\"\n",
    "        self.step += 1\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"å…³é—­writer\"\"\"\n",
    "        self.writer.close()\n",
    "\n",
    "# åˆ›å»º TensorBoard logger\n",
    "tb_logger = TensorBoardLogger(\n",
    "    log_dir=\"./tensorboard_logs\", \n",
    "    experiment_name=\"mnist_cnn_demo\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ TensorBoard è®°å½•å™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea78bf3",
   "metadata": {},
   "source": [
    "### 8.2 TensorBoard å¯è§†åŒ–æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_tensorboard_logging():\n",
    "    \"\"\"æ¼”ç¤º TensorBoard çš„å„ç§åŠŸèƒ½\"\"\"\n",
    "    \n",
    "    print(\"=== TensorBoard å¯è§†åŒ–æ¼”ç¤º ===\\n\")\n",
    "    \n",
    "    # 1. åˆ›å»ºç¤ºä¾‹æ¨¡å‹å’Œæ•°æ®\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # è·å–ä¸€ä¸ªbatchçš„æ•°æ®ç”¨äºæ¼”ç¤º\n",
    "    sample_data, sample_labels = next(iter(train_loader))\n",
    "    sample_data = sample_data.to(device)\n",
    "    \n",
    "    print(\"1. è®°å½•æ¨¡å‹è®¡ç®—å›¾...\")\n",
    "    # è®°å½•æ¨¡å‹è®¡ç®—å›¾\n",
    "    tb_logger.log_model_graph(model, sample_data[:1])  # åªç”¨ä¸€ä¸ªæ ·æœ¬\n",
    "    \n",
    "    print(\"2. è®°å½•æ ·æœ¬å›¾åƒ...\")\n",
    "    # è®°å½•æ ·æœ¬å›¾åƒ\n",
    "    tb_logger.log_images(\"samples/train_images\", sample_data[:8])  # å‰8å¼ å›¾åƒ\n",
    "    \n",
    "    print(\"3. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹è®°å½•...\")\n",
    "    # æ¨¡æ‹Ÿä¸€ä¸ªçŸ­è®­ç»ƒè¿‡ç¨‹æ¥æ¼”ç¤ºæ—¥å¿—è®°å½•\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for step in range(10):  # åªæ¼”ç¤º10æ­¥\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = model(sample_data)\n",
    "        loss = criterion(outputs, sample_labels.to(device))\n",
    "        \n",
    "        # è®¡ç®—å‡†ç¡®ç‡\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == sample_labels.to(device)).float().mean().item() * 100\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # è®°å½•åˆ° TensorBoard\n",
    "        tb_logger.log_scalar(\"loss/train\", loss.item(), step)\n",
    "        tb_logger.log_scalar(\"accuracy/train\", accuracy, step)\n",
    "        tb_logger.log_learning_rate(optimizer, step)\n",
    "        \n",
    "        # æ¯5æ­¥è®°å½•ä¸€æ¬¡æƒé‡åˆ†å¸ƒ\n",
    "        if step % 5 == 0:\n",
    "            tb_logger.log_model_weights(model, step)\n",
    "        \n",
    "        print(f\"Step {step+1}/10: Loss={loss.item():.4f}, Acc={accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"\\n4. è®°å½•è¶…å‚æ•°å’Œæœ€ç»ˆç»“æœ...\")\n",
    "    # è®°å½•è¶…å‚æ•°\n",
    "    hparams = {\n",
    "        'lr': 0.001,\n",
    "        'batch_size': 64,\n",
    "        'model': 'SimpleCNN',\n",
    "        'optimizer': 'Adam'\n",
    "    }\n",
    "    metrics = {\n",
    "        'final_loss': loss.item(),\n",
    "        'final_accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # TensorBoard çš„è¶…å‚æ•°è®°å½•\n",
    "    tb_logger.writer.add_hparams(hparams, metrics)\n",
    "    \n",
    "    print(\"5. ç”Ÿæˆæ··æ·†çŸ©é˜µå¯è§†åŒ–...\")\n",
    "    # ç®€å•çš„é¢„æµ‹ç»“æœåˆ†æ\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "            if len(all_predictions) > 500:  # åªç”¨å‰500ä¸ªæ ·æœ¬æ¼”ç¤º\n",
    "                break\n",
    "        \n",
    "        # åˆ›å»ºæ··æ·†çŸ©é˜µ\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sns\n",
    "        \n",
    "        cm = confusion_matrix(all_labels[:500], all_predictions[:500])\n",
    "        \n",
    "        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        \n",
    "        # ä¿å­˜åˆ° TensorBoard\n",
    "        tb_logger.writer.add_figure(\"confusion_matrix\", plt.gcf(), 0)\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"\\nâœ“ TensorBoard æ¼”ç¤ºå®Œæˆ!\")\n",
    "    print(f\"ğŸ“Š æ—¥å¿—å·²ä¿å­˜åˆ°: {tb_logger.log_dir}\")\n",
    "    print(f\"ğŸŒ å¯åŠ¨ TensorBoard: tensorboard --logdir {tb_logger.log_dir.parent}\")\n",
    "    print(\"   ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://localhost:6006\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demo_tensorboard_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87374f0d",
   "metadata": {},
   "source": [
    "## 9. å®éªŒç®¡ç†ä¸æ—¥å¿—è®°å½•\n",
    "\n",
    "åœ¨æ·±åº¦å­¦ä¹ ç ”ç©¶ä¸­ï¼Œå®éªŒç®¡ç†å’Œè¯¦ç»†çš„æ—¥å¿—è®°å½•æ˜¯éå¸¸é‡è¦çš„ï¼Œå®ƒä»¬å¯ä»¥å¸®åŠ©æˆ‘ä»¬ï¼š\n",
    "- è¿½è¸ªä¸åŒå®éªŒçš„è¶…å‚æ•°å’Œç»“æœ\n",
    "- å¤ç°å®éªŒç»“æœ\n",
    "- æ¯”è¾ƒä¸åŒæ–¹æ³•çš„æ€§èƒ½\n",
    "- è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯\n",
    "\n",
    "### 9.1 å®éªŒç®¡ç†ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ac89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "import psutil\n",
    "import platform\n",
    "\n",
    "class ExperimentManager:\n",
    "    \"\"\"\n",
    "    å®éªŒç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å®éªŒçš„é…ç½®ã€æ—¥å¿—å’Œç»“æœ\n",
    "    \"\"\"\n",
    "    def __init__(self, experiment_name, base_dir=\"./experiments\"):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.exp_dir = self.base_dir / experiment_name\n",
    "        \n",
    "        # åˆ›å»ºå®éªŒç›®å½•ç»“æ„\n",
    "        self.exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (self.exp_dir / \"checkpoints\").mkdir(exist_ok=True)\n",
    "        (self.exp_dir / \"logs\").mkdir(exist_ok=True)\n",
    "        (self.exp_dir / \"results\").mkdir(exist_ok=True)\n",
    "        (self.exp_dir / \"tensorboard\").mkdir(exist_ok=True)\n",
    "        \n",
    "        # è®¾ç½®æ—¥å¿—\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # è®°å½•å®éªŒå¼€å§‹æ—¶é—´å’Œç³»ç»Ÿä¿¡æ¯\n",
    "        self.start_time = datetime.now()\n",
    "        self.log_system_info()\n",
    "        \n",
    "        print(f\"ğŸ”¬ å®éªŒ '{experiment_name}' å·²åˆå§‹åŒ–\")\n",
    "        print(f\"ğŸ“ å®éªŒç›®å½•: {self.exp_dir}\")\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"è®¾ç½®æ—¥å¿—ç³»ç»Ÿ\"\"\"\n",
    "        log_file = self.exp_dir / \"logs\" / \"experiment.log\"\n",
    "        \n",
    "        # åˆ›å»ºlogger\n",
    "        self.logger = logging.getLogger(self.experiment_name)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # é¿å…é‡å¤æ·»åŠ handler\n",
    "        if not self.logger.handlers:\n",
    "            # æ–‡ä»¶handler\n",
    "            file_handler = logging.FileHandler(log_file)\n",
    "            file_handler.setLevel(logging.INFO)\n",
    "            \n",
    "            # æ§åˆ¶å°handler\n",
    "            console_handler = logging.StreamHandler(sys.stdout)\n",
    "            console_handler.setLevel(logging.INFO)\n",
    "            \n",
    "            # æ ¼å¼åŒ–\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                datefmt='%Y-%m-%d %H:%M:%S'\n",
    "            )\n",
    "            file_handler.setFormatter(formatter)\n",
    "            console_handler.setFormatter(formatter)\n",
    "            \n",
    "            # æ·»åŠ handlers\n",
    "            self.logger.addHandler(file_handler)\n",
    "            self.logger.addHandler(console_handler)\n",
    "    \n",
    "    def log_system_info(self):\n",
    "        \"\"\"è®°å½•ç³»ç»Ÿä¿¡æ¯\"\"\"\n",
    "        info = {\n",
    "            \"experiment_name\": self.experiment_name,\n",
    "            \"start_time\": self.start_time.isoformat(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            \"cuda_available\": torch.cuda.is_available(),\n",
    "            \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else None,\n",
    "            \"gpu_count\": torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "        }\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            info[\"gpu_names\"] = [torch.cuda.get_device_name(i) \n",
    "                               for i in range(torch.cuda.device_count())]\n",
    "        \n",
    "        # ä¿å­˜ç³»ç»Ÿä¿¡æ¯\n",
    "        with open(self.exp_dir / \"system_info.json\", \"w\") as f:\n",
    "            json.dump(info, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"System info: {json.dumps(info, indent=2)}\")\n",
    "    \n",
    "    def log_config(self, config: Dict[str, Any]):\n",
    "        \"\"\"è®°å½•å®éªŒé…ç½®\"\"\"\n",
    "        config_file = self.exp_dir / \"config.json\"\n",
    "        \n",
    "        with open(config_file, \"w\") as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"Configuration: {json.dumps(config, indent=2)}\")\n",
    "    \n",
    "    def log_info(self, message: str):\n",
    "        \"\"\"è®°å½•ä¿¡æ¯\"\"\"\n",
    "        self.logger.info(message)\n",
    "    \n",
    "    def log_results(self, results: Dict[str, Any], epoch: int = None):\n",
    "        \"\"\"è®°å½•ç»“æœ\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        result_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"epoch\": epoch,\n",
    "            \"results\": results\n",
    "        }\n",
    "        \n",
    "        # è¿½åŠ åˆ°ç»“æœæ–‡ä»¶\n",
    "        results_file = self.exp_dir / \"results\" / \"results.jsonl\"\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(json.dumps(result_entry) + \"\\n\")\n",
    "        \n",
    "        self.logger.info(f\"Results (epoch {epoch}): {json.dumps(results)}\")\n",
    "    \n",
    "    def save_model(self, model, filename, **kwargs):\n",
    "        \"\"\"ä¿å­˜æ¨¡å‹\"\"\"\n",
    "        save_path = self.exp_dir / \"checkpoints\" / filename\n",
    "        \n",
    "        save_dict = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            **kwargs\n",
    "        }\n",
    "        \n",
    "        torch.save(save_dict, save_path)\n",
    "        self.logger.info(f\"Model saved: {filename}\")\n",
    "        return save_path\n",
    "    \n",
    "    def get_tensorboard_dir(self):\n",
    "        \"\"\"è·å–TensorBoardç›®å½•\"\"\"\n",
    "        return str(self.exp_dir / \"tensorboard\")\n",
    "    \n",
    "    def finalize(self, final_results: Dict[str, Any] = None):\n",
    "        \"\"\"ç»“æŸå®éªŒï¼Œè®°å½•æœ€ç»ˆç»“æœ\"\"\"\n",
    "        end_time = datetime.now()\n",
    "        duration = end_time - self.start_time\n",
    "        \n",
    "        summary = {\n",
    "            \"experiment_name\": self.experiment_name,\n",
    "            \"start_time\": self.start_time.isoformat(),\n",
    "            \"end_time\": end_time.isoformat(),\n",
    "            \"duration_seconds\": duration.total_seconds(),\n",
    "            \"duration_formatted\": str(duration),\n",
    "            \"final_results\": final_results or {}\n",
    "        }\n",
    "        \n",
    "        # ä¿å­˜å®éªŒæ€»ç»“\n",
    "        with open(self.exp_dir / \"experiment_summary.json\", \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"Experiment completed. Duration: {duration}\")\n",
    "        if final_results:\n",
    "            self.logger.info(f\"Final results: {json.dumps(final_results)}\")\n",
    "\n",
    "# ç¤ºä¾‹ï¼šåˆ›å»ºå®éªŒç®¡ç†å™¨\n",
    "exp_manager = ExperimentManager(\"mnist_cnn_v1\")\n",
    "\n",
    "# ç¤ºä¾‹é…ç½®\n",
    "sample_config = {\n",
    "    \"model\": \"SimpleCNN\",\n",
    "    \"dataset\": \"MNIST\",\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 10,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"CrossEntropyLoss\"\n",
    "}\n",
    "\n",
    "exp_manager.log_config(sample_config)\n",
    "exp_manager.log_info(\"å®éªŒç®¡ç†å™¨æ¼”ç¤ºå®Œæˆ\")\n",
    "\n",
    "print(\"âœ“ å®éªŒç®¡ç†å™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c4f08",
   "metadata": {},
   "source": [
    "## 10. å®Œæ•´çš„ MNIST åˆ†ç±»æ¡ˆä¾‹\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†æ‰€æœ‰å‰é¢å­¦åˆ°çš„æŠ€æœ¯æ•´åˆèµ·æ¥ï¼Œåˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ã€ç”Ÿäº§å°±ç»ªçš„ MNIST åˆ†ç±»é¡¹ç›®ã€‚è¿™ä¸ªæ¡ˆä¾‹å°†åŒ…æ‹¬ï¼š\n",
    "- å®Œæ•´çš„é¡¹ç›®ç»“æ„\n",
    "- é…ç½®ç®¡ç†\n",
    "- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†\n",
    "- æ¨¡å‹å®šä¹‰å’Œè®­ç»ƒ\n",
    "- æ–­ç‚¹ä¿å­˜å’Œæ¢å¤\n",
    "- TensorBoard å¯è§†åŒ–\n",
    "- å®éªŒç®¡ç†\n",
    "- æ¨¡å‹è¯„ä¼°å’Œæµ‹è¯•\n",
    "\n",
    "### 10.1 é¡¹ç›®é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTConfig:\n",
    "    \"\"\"MNISTé¡¹ç›®çš„å®Œæ•´é…ç½®\"\"\"\n",
    "    def __init__(self):\n",
    "        # æ•°æ®ç›¸å…³\n",
    "        self.data_dir = \"./data\"\n",
    "        self.batch_size = 64\n",
    "        self.num_workers = 4\n",
    "        self.pin_memory = True\n",
    "        \n",
    "        # æ¨¡å‹ç›¸å…³\n",
    "        self.model_name = \"SimpleCNN\"\n",
    "        self.num_classes = 10\n",
    "        self.dropout_rate = 0.5\n",
    "        \n",
    "        # è®­ç»ƒç›¸å…³\n",
    "        self.epochs = 10\n",
    "        self.learning_rate = 0.001\n",
    "        self.weight_decay = 1e-4\n",
    "        self.optimizer = \"Adam\"\n",
    "        \n",
    "        # è°ƒåº¦å™¨ç›¸å…³\n",
    "        self.scheduler = \"StepLR\"\n",
    "        self.step_size = 5\n",
    "        self.gamma = 0.5\n",
    "        \n",
    "        # æ—©åœç›¸å…³\n",
    "        self.early_stopping = True\n",
    "        self.patience = 5\n",
    "        self.min_delta = 0.001\n",
    "        \n",
    "        # ä¿å­˜ç›¸å…³\n",
    "        self.save_frequency = 2\n",
    "        self.max_checkpoints = 3\n",
    "        \n",
    "        # å®éªŒç›¸å…³\n",
    "        self.experiment_name = f\"mnist_cnn_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "        self.use_amp = torch.cuda.is_available()\n",
    "        \n",
    "        # TensorBoard\n",
    "        self.log_every = 100  # æ¯å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡\n",
    "        \n",
    "        # éšæœºç§å­\n",
    "        self.seed = 42\n",
    "\n",
    "def complete_mnist_training():\n",
    "    \"\"\"å®Œæ•´çš„MNISTè®­ç»ƒæµç¨‹\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ å¼€å§‹å®Œæ•´çš„ MNIST åˆ†ç±»è®­ç»ƒ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. åˆå§‹åŒ–é…ç½®\n",
    "    config = MNISTConfig()\n",
    "    \n",
    "    # è®¾ç½®éšæœºç§å­\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(config.seed)\n",
    "    \n",
    "    # 2. åˆå§‹åŒ–å®éªŒç®¡ç†å™¨\n",
    "    exp_manager = ExperimentManager(config.experiment_name)\n",
    "    exp_manager.log_config(config.__dict__)\n",
    "    \n",
    "    # 3. åˆå§‹åŒ– TensorBoard\n",
    "    tb_logger = TensorBoardLogger(\n",
    "        log_dir=exp_manager.get_tensorboard_dir(),\n",
    "        experiment_name=\"training\"\n",
    "    )\n",
    "    \n",
    "    # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    exp_manager.log_info(\"åˆ›å»ºæ•°æ®åŠ è½½å™¨...\")\n",
    "    train_loader = create_dataloader(\n",
    "        dataset_type='train',\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory\n",
    "    )\n",
    "    \n",
    "    val_loader = create_dataloader(\n",
    "        dataset_type='val',\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory\n",
    "    )\n",
    "    \n",
    "    test_loader = create_dataloader(\n",
    "        dataset_type='test',\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory\n",
    "    )\n",
    "    \n",
    "    # 5. åˆ›å»ºæ¨¡å‹\n",
    "    exp_manager.log_info(\"åˆ›å»ºæ¨¡å‹...\")\n",
    "    model = SimpleCNN(num_classes=config.num_classes, dropout_rate=config.dropout_rate)\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # è®°å½•æ¨¡å‹ä¿¡æ¯\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    exp_manager.log_info(f\"æ¨¡å‹æ€»å‚æ•°æ•°: {total_params:,}\")\n",
    "    exp_manager.log_info(f\"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}\")\n",
    "    \n",
    "    # 6. åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=config.step_size,\n",
    "        gamma=config.gamma\n",
    "    )\n",
    "    \n",
    "    # 7. åˆ›å»ºæŸå¤±å‡½æ•°\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 8. åˆ›å»ºæ—©åœå’Œæ£€æŸ¥ç‚¹ç®¡ç†å™¨\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=config.patience,\n",
    "        min_delta=config.min_delta\n",
    "    ) if config.early_stopping else None\n",
    "    \n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        save_dir=exp_manager.exp_dir / \"checkpoints\",\n",
    "        max_checkpoints=config.max_checkpoints\n",
    "    )\n",
    "    \n",
    "    # 9. æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    scaler = torch.cuda.amp.GradScaler() if config.use_amp else None\n",
    "    \n",
    "    # 10. è®°å½•æ¨¡å‹å›¾\n",
    "    sample_input = next(iter(train_loader))[0][:1].to(config.device)\n",
    "    tb_logger.log_model_graph(model, sample_input)\n",
    "    \n",
    "    # 11. è®­ç»ƒå¾ªç¯\n",
    "    exp_manager.log_info(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "    history = TrainingHistory()\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # è®­ç»ƒ\n",
    "        train_loss, train_acc = train_epoch_with_amp(\n",
    "            model, train_loader, criterion, optimizer, config.device,\n",
    "            scaler if config.use_amp else None, epoch, config, tb_logger\n",
    "        )\n",
    "        \n",
    "        # éªŒè¯\n",
    "        val_loss, val_acc = validate_epoch(\n",
    "            model, val_loader, criterion, config.device, epoch, config\n",
    "        )\n",
    "        \n",
    "        # æ›´æ–°è°ƒåº¦å™¨\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # æ›´æ–°å†å²\n",
    "        history.update(epoch, train_loss, train_acc, val_loss, val_acc, current_lr)\n",
    "        \n",
    "        # TensorBoard è®°å½•\n",
    "        tb_logger.log_scalars({\n",
    "            'Loss/Train': train_loss,\n",
    "            'Loss/Validation': val_loss,\n",
    "            'Accuracy/Train': train_acc,\n",
    "            'Accuracy/Validation': val_acc,\n",
    "            'Learning_Rate': current_lr\n",
    "        }, epoch)\n",
    "        \n",
    "        # è®°å½•æƒé‡åˆ†å¸ƒ\n",
    "        if epoch % 2 == 0:\n",
    "            tb_logger.log_model_weights(model, epoch)\n",
    "        \n",
    "        # è®¡ç®—æ—¶é—´\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # è®°å½•ç»“æœ\n",
    "        epoch_results = {\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'learning_rate': current_lr,\n",
    "            'epoch_time': epoch_time\n",
    "        }\n",
    "        exp_manager.log_results(epoch_results, epoch)\n",
    "        \n",
    "        # è¾“å‡ºç»“æœ\n",
    "        exp_manager.log_info(\n",
    "            f\"Epoch {epoch+1}/{config.epochs} - \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% - \"\n",
    "            f\"LR: {current_lr:.6f} - Time: {epoch_time:.2f}s\"\n",
    "        )\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        is_best = val_acc > best_val_acc\n",
    "        if is_best:\n",
    "            best_val_acc = val_acc\n",
    "            exp_manager.log_info(f\"æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%\")\n",
    "        \n",
    "        # ä¿å­˜æ£€æŸ¥ç‚¹\n",
    "        if (epoch + 1) % config.save_frequency == 0 or is_best:\n",
    "            checkpoint_state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'history': history.__dict__,\n",
    "                'config': config.__dict__,\n",
    "                'best_val_acc': best_val_acc\n",
    "            }\n",
    "            \n",
    "            checkpoint_manager.save_checkpoint(\n",
    "                checkpoint_state, epoch, is_best=is_best\n",
    "            )\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if early_stopping:\n",
    "            if early_stopping(val_loss, model):\n",
    "                exp_manager.log_info(f\"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ\")\n",
    "                break\n",
    "    \n",
    "    # 12. æµ‹è¯•æœ€ä½³æ¨¡å‹\n",
    "    exp_manager.log_info(\"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹...\")\n",
    "    \n",
    "    # åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "    best_checkpoint = checkpoint_manager.save_dir / \"best_model.pth\"\n",
    "    if best_checkpoint.exists():\n",
    "        checkpoint = torch.load(best_checkpoint, map_location=config.device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # æµ‹è¯•\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion, config.device)\n",
    "    \n",
    "    # 13. æœ€ç»ˆç»“æœ\n",
    "    final_results = {\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'total_epochs': epoch + 1,\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params\n",
    "    }\n",
    "    \n",
    "    exp_manager.log_info(f\"è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%\")\n",
    "    \n",
    "    # 14. ä¿å­˜æœ€ç»ˆç»“æœå’Œå…³é—­èµ„æº\n",
    "    history.save(exp_manager.exp_dir / \"training_history.json\")\n",
    "    exp_manager.finalize(final_results)\n",
    "    tb_logger.close()\n",
    "    \n",
    "    print(\"\\nğŸ‰ å®Œæ•´çš„ MNIST è®­ç»ƒæµç¨‹ç»“æŸ!\")\n",
    "    print(f\"ğŸ“Š å®éªŒç›®å½•: {exp_manager.exp_dir}\")\n",
    "    print(f\"ğŸ† æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%\")\n",
    "    \n",
    "    return model, history, final_results\n",
    "\n",
    "# è¿™é‡Œæˆ‘ä»¬åˆ›å»ºé…ç½®ä½†æš‚ä¸è¿è¡Œå®Œæ•´è®­ç»ƒï¼ˆè®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼‰\n",
    "config = MNISTConfig()\n",
    "print(\"âœ“ MNIST å®Œæ•´é¡¹ç›®é…ç½®åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"ğŸ“‹ å®éªŒåç§°: {config.experiment_name}\")\n",
    "print(\"ğŸ’¡ è¿è¡Œ complete_mnist_training() å¼€å§‹å®Œæ•´è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_with_amp(model, dataloader, criterion, optimizer, device, \n",
    "                        scaler, epoch, config, tb_logger):\n",
    "    \"\"\"å¸¦æœ‰æ··åˆç²¾åº¦çš„è®­ç»ƒepoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler is not None:  # ä½¿ç”¨æ··åˆç²¾åº¦\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:  # æ ‡å‡†è®­ç»ƒ\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # TensorBoard è®°å½•\n",
    "        if batch_idx % config.log_every == 0:\n",
    "            step = epoch * len(dataloader) + batch_idx\n",
    "            tb_logger.log_scalar('Batch/Loss', loss.item(), step)\n",
    "            tb_logger.log_scalar('Batch/Accuracy', \n",
    "                               100. * correct / total, step)\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    \"\"\"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "            \n",
    "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "print(\"âœ“ è¾…åŠ©å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4516c5",
   "metadata": {},
   "source": [
    "## 11. PyTorch æœ€ä½³å®è·µæ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬å­¦ä¹ äº† PyTorch çš„å„ä¸ªæ–¹é¢ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›é‡è¦çš„æœ€ä½³å®è·µï¼š\n",
    "\n",
    "### 11.1 ä»£ç ç»„ç»‡\n",
    "\n",
    "1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†æ•°æ®åŠ è½½ã€æ¨¡å‹å®šä¹‰ã€è®­ç»ƒå¾ªç¯åˆ†ç¦»\n",
    "2. **é…ç½®ç®¡ç†**ï¼šä½¿ç”¨é…ç½®ç±»ç»Ÿä¸€ç®¡ç†è¶…å‚æ•°\n",
    "3. **å®éªŒç®¡ç†**ï¼šä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºç‹¬ç«‹çš„ç›®å½•å’Œæ—¥å¿—\n",
    "4. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ Git ç®¡ç†ä»£ç ï¼Œè®°å½•æ¯æ¬¡å®éªŒçš„ä»£ç ç‰ˆæœ¬\n",
    "\n",
    "### 11.2 è®­ç»ƒä¼˜åŒ–\n",
    "\n",
    "1. **æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šåœ¨æ”¯æŒçš„ç¡¬ä»¶ä¸Šä½¿ç”¨ AMP åŠ é€Ÿè®­ç»ƒ\n",
    "2. **æ•°æ®åŠ è½½ä¼˜åŒ–**ï¼šåˆç†è®¾ç½® `num_workers` å’Œ `pin_memory`\n",
    "3. **å­¦ä¹ ç‡è°ƒåº¦**ï¼šä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "4. **æ—©åœæœºåˆ¶**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒèŠ‚çœè®­ç»ƒæ—¶é—´\n",
    "\n",
    "### 11.3 è°ƒè¯•å’Œç›‘æ§\n",
    "\n",
    "1. **TensorBoard å¯è§†åŒ–**ï¼šç›‘æ§è®­ç»ƒè¿‡ç¨‹å’Œæ¨¡å‹æ€§èƒ½\n",
    "2. **è¯¦ç»†æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰é‡è¦ä¿¡æ¯ä¾¿äºå¤ç°\n",
    "3. **æ–­ç‚¹ä¿å­˜**ï¼šæ”¯æŒè®­ç»ƒä¸­æ–­åçš„æ¢å¤\n",
    "4. **æ€§èƒ½åˆ†æ**ï¼šç›‘æ§ GPU åˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨\n",
    "\n",
    "### 11.4 æ¨¡å‹éƒ¨ç½²å‡†å¤‡\n",
    "\n",
    "1. **æ¨¡å‹ä¿å­˜**ï¼šä¿å­˜å®Œæ•´çš„æ¨¡å‹çŠ¶æ€\n",
    "2. **æ¨ç†ä¼˜åŒ–**ï¼šä½¿ç”¨ `torch.jit` æˆ– TorchScript\n",
    "3. **æ¨¡å‹å‹ç¼©**ï¼šé‡åŒ–ã€å‰ªæç­‰æŠ€æœ¯\n",
    "4. **ç«¯åˆ°ç«¯æµ‹è¯•**ï¼šç¡®ä¿æ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ­£å¸¸å·¥ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75558876",
   "metadata": {},
   "source": [
    "### 11.5 å¸¸ç”¨ä»£ç æ¨¡æ¿\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„ PyTorch ä»£ç æ¨¡æ¿ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŸºæœ¬è®­ç»ƒå¾ªç¯æ¨¡æ¿\n",
    "basic_training_template = \"\"\"\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.6f}')\n",
    "\"\"\"\n",
    "\n",
    "# 2. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½æ¨¡æ¿\n",
    "save_load_template = \"\"\"\n",
    "# ä¿å­˜\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "}, checkpoint_path)\n",
    "\n",
    "# åŠ è½½\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\"\"\"\n",
    "\n",
    "# 3. è‡ªå®šä¹‰æ•°æ®é›†æ¨¡æ¿\n",
    "custom_dataset_template = \"\"\"\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.samples = self._load_samples()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        data = self._load_data(sample)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data, sample['label']\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        # å®ç°æ ·æœ¬åŠ è½½é€»è¾‘\n",
    "        pass\n",
    "    \n",
    "    def _load_data(self, sample):\n",
    "        # å®ç°æ•°æ®åŠ è½½é€»è¾‘\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“‹ å¸¸ç”¨ä»£ç æ¨¡æ¿:\")\n",
    "print(\"1. åŸºæœ¬è®­ç»ƒå¾ªç¯\")\n",
    "print(\"2. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½\")\n",
    "print(\"3. è‡ªå®šä¹‰æ•°æ®é›†\")\n",
    "print(\"\\nğŸ’¡ è¿™äº›æ¨¡æ¿å¯ä»¥ä½œä¸ºä½ é¡¹ç›®çš„èµ·ç‚¹è¿›è¡Œä¿®æ”¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ccb8d",
   "metadata": {},
   "source": [
    "### 11.6 è¿›é˜¶å­¦ä¹ å»ºè®®\n",
    "\n",
    "å®Œæˆæœ¬æ•™ç¨‹åï¼Œä½ å¯ä»¥ç»§ç»­å­¦ä¹ ä»¥ä¸‹é«˜çº§ä¸»é¢˜ï¼š\n",
    "\n",
    "1. **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼š\n",
    "   - æ•°æ®å¹¶è¡Œ (DataParallel, DistributedDataParallel)\n",
    "   - æ¨¡å‹å¹¶è¡Œ\n",
    "   - æ··åˆå¹¶è¡Œç­–ç•¥\n",
    "\n",
    "2. **æ¨¡å‹ä¼˜åŒ–**ï¼š\n",
    "   - é‡åŒ– (Quantization)\n",
    "   - å‰ªæ (Pruning)\n",
    "   - çŸ¥è¯†è’¸é¦ (Knowledge Distillation)\n",
    "   - TorchScript å’Œ ONNX\n",
    "\n",
    "3. **é«˜çº§æ¶æ„**ï¼š\n",
    "   - Transformer æ¨¡å‹\n",
    "   - ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GANs)\n",
    "   - å˜åˆ†è‡ªç¼–ç å™¨ (VAEs)\n",
    "   - å›¾ç¥ç»ç½‘ç»œ (GNNs)\n",
    "\n",
    "4. **ä¸“é—¨é¢†åŸŸ**ï¼š\n",
    "   - è®¡ç®—æœºè§†è§‰ï¼šç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²\n",
    "   - è‡ªç„¶è¯­è¨€å¤„ç†ï¼šBERTã€GPT ç­‰\n",
    "   - å¼ºåŒ–å­¦ä¹ ï¼šDQNã€PPO ç­‰\n",
    "   - æ—¶é—´åºåˆ—åˆ†æï¼šLSTMã€Transformer\n",
    "\n",
    "### 11.7 æ¨èèµ„æº\n",
    "\n",
    "- **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://pytorch.org/docs/\n",
    "- **å®˜æ–¹æ•™ç¨‹**ï¼šhttps://pytorch.org/tutorials/\n",
    "- **PyTorch ç¤ºä¾‹**ï¼šhttps://github.com/pytorch/examples\n",
    "- **Papers with Code**ï¼šhttps://paperswithcode.com/\n",
    "- **Awesome PyTorch**ï¼šhttps://github.com/bharathgs/Awesome-pytorch-list\n",
    "\n",
    "## 12. æ€»ç»“\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº† PyTorch æ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼ğŸ‰\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ï¼š\n",
    "\n",
    "âœ… **PyTorch åŸºç¡€**ï¼šå¼ é‡æ“ä½œã€è‡ªåŠ¨å¾®åˆ†æœºåˆ¶\n",
    "âœ… **ç¥ç»ç½‘ç»œæ„å»º**ï¼šä»ç®€å•çš„å…¨è¿æ¥åˆ°å¤æ‚çš„CNN\n",
    "âœ… **æ•°æ®å¤„ç†**ï¼šè‡ªå®šä¹‰æ•°æ®é›†ã€æ•°æ®åŠ è½½ä¼˜åŒ–\n",
    "âœ… **è®­ç»ƒä¼˜åŒ–**ï¼šä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "âœ… **å®éªŒç®¡ç†**ï¼šæ–­ç‚¹ä¿å­˜ã€TensorBoard å¯è§†åŒ–ã€æ—¥å¿—è®°å½•\n",
    "âœ… **å®Œæ•´é¡¹ç›®**ï¼šç«¯åˆ°ç«¯çš„ MNIST åˆ†ç±»æ¡ˆä¾‹\n",
    "\n",
    "ç°åœ¨ä½ å·²ç»å…·å¤‡äº†ä½¿ç”¨ PyTorch è¿›è¡Œæ·±åº¦å­¦ä¹ ç ”ç©¶å’Œå¼€å‘çš„åŸºç¡€æŠ€èƒ½ã€‚è®°ä½ï¼Œæ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸï¼ŒæŒç»­å­¦ä¹ å’Œå®è·µæ˜¯æˆåŠŸçš„å…³é”®ã€‚\n",
    "\n",
    "**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š\n",
    "1. å°è¯•åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šåº”ç”¨æ‰€å­¦çŸ¥è¯†\n",
    "2. å‚ä¸å¼€æºé¡¹ç›®ï¼Œè´¡çŒ®ä»£ç \n",
    "3. é˜…è¯»æœ€æ–°çš„ç ”ç©¶è®ºæ–‡å¹¶å°è¯•å¤ç°\n",
    "4. å…³æ³¨ PyTorch çš„æœ€æ–°å‘å±•å’Œæœ€ä½³å®è·µ\n",
    "\n",
    "ç¥ä½ åœ¨æ·±åº¦å­¦ä¹ çš„é“è·¯ä¸Šå–å¾—æˆåŠŸï¼ğŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
