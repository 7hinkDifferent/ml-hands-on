{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f7ffa3",
   "metadata": {},
   "source": [
    "# Pandas - 数据处理与分析\n",
    "\n",
    "Pandas是Python中最重要的数据分析库，提供了高效的数据结构和数据操作工具。\n",
    "\n",
    "## 主要特性\n",
    "- 📊 **DataFrame**: 类似Excel的二维数据结构\n",
    "- 🔄 **数据清洗**: 处理缺失值、重复值\n",
    "- 📈 **数据分析**: 分组、聚合、统计\n",
    "- 📁 **文件I/O**: 读写CSV、Excel、JSON等格式\n",
    "- 🕒 **时间序列**: 强大的时间数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Pandas版本: {pd.__version__}\")\n",
    "\n",
    "# 创建DataFrame\n",
    "data = {\n",
    "    '姓名': ['张三', '李四', '王五', '赵六', '钱七'],\n",
    "    '年龄': [25, 30, 35, 28, 32],\n",
    "    '城市': ['北京', '上海', '广州', '深圳', '杭州'],\n",
    "    '薪资': [8000, 12000, 15000, 11000, 13000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"创建的DataFrame:\")\n",
    "print(df)\n",
    "print(f\"\\n数据形状: {df.shape}\")\n",
    "print(f\"数据类型:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd96d7",
   "metadata": {},
   "source": [
    "## 1. Pandas数据结构详解\n",
    "\n",
    "Pandas提供了两种主要的数据结构：Series（一维）和DataFrame（二维）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series - 一维数据结构\n",
    "print(\"=== Series 创建和操作 ===\")\n",
    "\n",
    "# 从列表创建Series\n",
    "scores = pd.Series([85, 92, 78, 96, 88], name='考试成绩')\n",
    "print(f\"成绩Series:\\n{scores}\")\n",
    "print(f\"数据类型: {scores.dtype}\")\n",
    "print(f\"索引: {scores.index.tolist()}\")\n",
    "\n",
    "# 带自定义索引的Series\n",
    "student_scores = pd.Series(\n",
    "    [85, 92, 78, 96, 88], \n",
    "    index=['张三', '李四', '王五', '赵六', '钱七'],\n",
    "    name='期末成绩'\n",
    ")\n",
    "print(f\"\\n带索引的Series:\\n{student_scores}\")\n",
    "\n",
    "# 从字典创建Series\n",
    "grade_dict = {'语文': 85, '数学': 92, '英语': 78, '物理': 96, '化学': 88}\n",
    "subjects = pd.Series(grade_dict, name='科目成绩')\n",
    "print(f\"\\n科目成绩:\\n{subjects}\")\n",
    "\n",
    "# Series基本操作\n",
    "print(f\"\\n=== Series 基本操作 ===\")\n",
    "print(f\"平均分: {subjects.mean():.2f}\")\n",
    "print(f\"最高分: {subjects.max()}\")\n",
    "print(f\"最低分科目: {subjects.idxmin()}\")\n",
    "print(f\"及格科目数: {(subjects >= 80).sum()}\")\n",
    "print(f\"成绩排序:\\n{subjects.sort_values(ascending=False)}\")\n",
    "\n",
    "# DataFrame创建的多种方式\n",
    "print(\"\\n=== DataFrame 创建方式 ===\")\n",
    "\n",
    "# 方式1：从字典创建\n",
    "employee_data = {\n",
    "    '员工ID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    '姓名': ['张三', '李四', '王五', '赵六', '钱七'],\n",
    "    '部门': ['技术部', '销售部', '技术部', '人事部', '财务部'],\n",
    "    '入职日期': ['2020-01-15', '2019-03-20', '2021-07-10', '2018-11-05', '2020-09-30'],\n",
    "    '薪资': [12000, 8500, 15000, 9000, 11000],\n",
    "    '年龄': [28, 32, 26, 35, 30]\n",
    "}\n",
    "\n",
    "df_employees = pd.DataFrame(employee_data)\n",
    "print(\"员工信息DataFrame:\")\n",
    "print(df_employees)\n",
    "\n",
    "# 方式2：从Series字典创建\n",
    "name_series = pd.Series(['Alice', 'Bob', 'Charlie', 'Diana'])\n",
    "age_series = pd.Series([25, 30, 35, 28])\n",
    "salary_series = pd.Series([50000, 60000, 70000, 55000])\n",
    "\n",
    "df_from_series = pd.DataFrame({\n",
    "    'Name': name_series,\n",
    "    'Age': age_series,\n",
    "    'Salary': salary_series\n",
    "})\n",
    "print(f\"\\n从Series创建的DataFrame:\\n{df_from_series}\")\n",
    "\n",
    "# 方式3：从NumPy数组创建\n",
    "np.random.seed(42)\n",
    "array_data = np.random.rand(4, 3)\n",
    "df_from_array = pd.DataFrame(\n",
    "    array_data, \n",
    "    columns=['特征1', '特征2', '特征3'],\n",
    "    index=['样本1', '样本2', '样本3', '样本4']\n",
    ")\n",
    "print(f\"\\n从NumPy数组创建的DataFrame:\\n{df_from_array}\")\n",
    "\n",
    "# DataFrame基本信息\n",
    "print(\"\\n=== DataFrame 基本信息 ===\")\n",
    "print(f\"形状: {df_employees.shape}\")\n",
    "print(f\"列名: {df_employees.columns.tolist()}\")\n",
    "print(f\"索引: {df_employees.index.tolist()}\")\n",
    "print(f\"数据类型:\\n{df_employees.dtypes}\")\n",
    "print(f\"\\n内存使用情况:\")\n",
    "print(df_employees.info())\n",
    "\n",
    "# 数据预览\n",
    "print(\"\\n=== 数据预览 ===\")\n",
    "print(\"前3行:\")\n",
    "print(df_employees.head(3))\n",
    "print(\"\\n后2行:\")\n",
    "print(df_employees.tail(2))\n",
    "print(\"\\n随机采样2行:\")\n",
    "print(df_employees.sample(2, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389aeab",
   "metadata": {},
   "source": [
    "## 2. 数据索引和选择\n",
    "\n",
    "Pandas提供了多种灵活的数据选择和索引方法，这是数据分析的基础操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101edf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例数据\n",
    "np.random.seed(42)\n",
    "sales_data = pd.DataFrame({\n",
    "    '日期': pd.date_range('2024-01-01', periods=100, freq='D'),\n",
    "    '产品': np.random.choice(['手机', '电脑', '平板', '耳机'], 100),\n",
    "    '销售额': np.random.randint(1000, 10000, 100),\n",
    "    '销量': np.random.randint(1, 50, 100),\n",
    "    '地区': np.random.choice(['北京', '上海', '广州', '深圳'], 100),\n",
    "    '销售员': np.random.choice(['张三', '李四', '王五', '赵六'], 100)\n",
    "})\n",
    "\n",
    "print(\"销售数据示例:\")\n",
    "print(sales_data.head())\n",
    "\n",
    "print(\"\\n=== 列选择 ===\")\n",
    "# 单列选择\n",
    "product_column = sales_data['产品']\n",
    "print(f\"产品列类型: {type(product_column)}\")\n",
    "print(f\"产品前5个: {product_column.head().tolist()}\")\n",
    "\n",
    "# 多列选择\n",
    "selected_cols = sales_data[['产品', '销售额', '销量']]\n",
    "print(f\"\\n选择多列的形状: {selected_cols.shape}\")\n",
    "print(selected_cols.head(3))\n",
    "\n",
    "# 列选择的不同方式\n",
    "sales_amount = sales_data.销售额  # 点号访问（注意：列名不能有空格或特殊字符）\n",
    "print(f\"\\n点号访问销售额平均值: {sales_amount.mean():.2f}\")\n",
    "\n",
    "print(\"\\n=== 行选择 ===\")\n",
    "# 基于位置的选择 (iloc)\n",
    "first_row = sales_data.iloc[0]  # 第一行\n",
    "print(f\"第一行数据:\\n{first_row}\")\n",
    "\n",
    "first_5_rows = sales_data.iloc[:5]  # 前5行\n",
    "print(f\"\\n前5行的形状: {first_5_rows.shape}\")\n",
    "\n",
    "# 基于标签的选择 (loc)\n",
    "# 首先设置一个有意义的索引\n",
    "sales_indexed = sales_data.set_index('日期')\n",
    "print(\"\\n基于日期索引的前3行:\")\n",
    "print(sales_indexed.head(3))\n",
    "\n",
    "# 选择特定日期\n",
    "specific_date = sales_indexed.loc['2024-01-01']\n",
    "print(f\"\\n2024-01-01的数据类型: {type(specific_date)}\")\n",
    "if isinstance(specific_date, pd.Series):\n",
    "    print(f\"该日期只有一条记录:\\n{specific_date}\")\n",
    "else:\n",
    "    print(f\"该日期有{len(specific_date)}条记录\")\n",
    "\n",
    "# 日期范围选择\n",
    "jan_data = sales_indexed.loc['2024-01-01':'2024-01-10']\n",
    "print(f\"\\n1月前10天的数据条数: {len(jan_data)}\")\n",
    "\n",
    "print(\"\\n=== 条件选择 ===\")\n",
    "# 单条件筛选\n",
    "high_sales = sales_data[sales_data['销售额'] > 8000]\n",
    "print(f\"高销售额记录数: {len(high_sales)}\")\n",
    "print(f\"高销售额平均值: {high_sales['销售额'].mean():.2f}\")\n",
    "\n",
    "# 多条件筛选\n",
    "beijing_phones = sales_data[\n",
    "    (sales_data['地区'] == '北京') & \n",
    "    (sales_data['产品'] == '手机')\n",
    "]\n",
    "print(f\"\\n北京手机销售记录数: {len(beijing_phones)}\")\n",
    "\n",
    "# 使用 isin() 方法\n",
    "tier1_cities = sales_data[sales_data['地区'].isin(['北京', '上海'])]\n",
    "print(f\"一线城市销售记录数: {len(tier1_cities)}\")\n",
    "\n",
    "# 字符串条件\n",
    "sales_person_zhang = sales_data[sales_data['销售员'].str.contains('张')]\n",
    "print(f\"销售员姓张的记录数: {len(sales_person_zhang)}\")\n",
    "\n",
    "print(\"\\n=== 复杂选择操作 ===\")\n",
    "# 组合选择：特定行和列\n",
    "specific_selection = sales_data.loc[\n",
    "    sales_data['销售额'] > 7000, \n",
    "    ['产品', '销售额', '地区']\n",
    "]\n",
    "print(f\"高销售额的产品和地区信息:\\n{specific_selection.head()}\")\n",
    "\n",
    "# 使用 query() 方法\n",
    "query_result = sales_data.query('销售额 > 8000 and 地区 == \"上海\"')\n",
    "print(f\"\\n使用query筛选的结果数: {len(query_result)}\")\n",
    "\n",
    "# 随机采样\n",
    "random_sample = sales_data.sample(n=5, random_state=42)\n",
    "print(f\"\\n随机采样5条记录:\\n{random_sample[['产品', '销售额', '地区']]}\")\n",
    "\n",
    "print(\"\\n=== 数据排序 ===\")\n",
    "# 单列排序\n",
    "sorted_by_sales = sales_data.sort_values('销售额', ascending=False)\n",
    "print(\"按销售额降序排列的前3名:\")\n",
    "print(sorted_by_sales[['产品', '销售额', '销售员']].head(3))\n",
    "\n",
    "# 多列排序\n",
    "multi_sorted = sales_data.sort_values(['地区', '销售额'], ascending=[True, False])\n",
    "print(f\"\\n按地区升序、销售额降序排列的前5条:\")\n",
    "print(multi_sorted[['地区', '产品', '销售额']].head())\n",
    "\n",
    "# 索引排序\n",
    "index_sorted = sales_data.sort_index()\n",
    "print(f\"按索引排序后的前3行:\\n{index_sorted.head(3)}\")\n",
    "\n",
    "print(\"\\n=== 去重操作 ===\")\n",
    "# 查看重复值\n",
    "duplicate_products = sales_data['产品'].duplicated()\n",
    "print(f\"产品列重复值数量: {duplicate_products.sum()}\")\n",
    "\n",
    "# 去除重复的产品\n",
    "unique_products = sales_data['产品'].drop_duplicates()\n",
    "print(f\"唯一产品: {unique_products.tolist()}\")\n",
    "\n",
    "# 基于多列去重\n",
    "unique_combinations = sales_data[['产品', '地区']].drop_duplicates()\n",
    "print(f\"\\n产品-地区唯一组合数: {len(unique_combinations)}\")\n",
    "print(unique_combinations)\n",
    "\n",
    "print(\"\\n=== 设置和重置索引 ===\")\n",
    "# 设置单列为索引\n",
    "product_indexed = sales_data.set_index('产品')\n",
    "print(f\"以产品为索引的数据形状: {product_indexed.shape}\")\n",
    "\n",
    "# 设置多级索引\n",
    "multi_indexed = sales_data.set_index(['地区', '产品'])\n",
    "print(f\"多级索引的前5行:\\n{multi_indexed.head()}\")\n",
    "\n",
    "# 重置索引\n",
    "reset_index_df = multi_indexed.reset_index()\n",
    "print(f\"重置索引后的列名: {reset_index_df.columns.tolist()}\")\n",
    "\n",
    "# 索引操作示例\n",
    "print(\"\\n=== 高级索引示例 ===\")\n",
    "# 透视表预览\n",
    "pivot_preview = sales_data.groupby(['地区', '产品'])['销售额'].sum().unstack(fill_value=0)\n",
    "print(\"地区-产品销售额透视表:\")\n",
    "print(pivot_preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73147fe5",
   "metadata": {},
   "source": [
    "## 3. 数据清洗和预处理\n",
    "\n",
    "数据清洗是数据分析的重要步骤，包括处理缺失值、重复值、异常值等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建包含问题的示例数据\n",
    "np.random.seed(42)\n",
    "dirty_data = pd.DataFrame({\n",
    "    '姓名': ['张三', '李四', '王五', '张三', '赵六', None, '钱七', '张三'],\n",
    "    '年龄': [25, 30, np.nan, 25, 28, 35, 32, 25],\n",
    "    '收入': [5000, 8000, 12000, 5000, np.nan, 15000, 11000, 5000],\n",
    "    '城市': ['北京', '上海', '  广州  ', '北京', '深圳', '杭州', '', '北京'],\n",
    "    '学历': ['本科', '硕士', '本科', '本科', '博士', '硕士', '本科', '本科'],\n",
    "    '邮箱': ['zhang@qq.com', 'li@163.com', 'wang@gmail.com', 'zhang@qq.com', \n",
    "             'zhao@sina.com', 'invalid-email', 'qian@126.com', 'zhang@qq.com']\n",
    "})\n",
    "\n",
    "print(\"原始脏数据:\")\n",
    "print(dirty_data)\n",
    "print(f\"\\n数据形状: {dirty_data.shape}\")\n",
    "\n",
    "print(\"\\n=== 缺失值处理 ===\")\n",
    "# 检查缺失值\n",
    "print(\"各列缺失值统计:\")\n",
    "print(dirty_data.isnull().sum())\n",
    "\n",
    "print(\"\\n缺失值位置:\")\n",
    "print(dirty_data.isnull())\n",
    "\n",
    "# 缺失值可视化统计\n",
    "missing_percentage = (dirty_data.isnull().sum() / len(dirty_data)) * 100\n",
    "print(f\"\\n各列缺失值比例:\")\n",
    "for col, pct in missing_percentage.items():\n",
    "    if pct > 0:\n",
    "        print(f\"{col}: {pct:.1f}%\")\n",
    "\n",
    "# 处理缺失值的不同策略\n",
    "print(\"\\n=== 缺失值处理策略 ===\")\n",
    "\n",
    "# 策略1：删除含缺失值的行\n",
    "cleaned_drop_rows = dirty_data.dropna()\n",
    "print(f\"删除缺失行后数据形状: {cleaned_drop_rows.shape}\")\n",
    "\n",
    "# 策略2：删除含缺失值的列\n",
    "cleaned_drop_cols = dirty_data.dropna(axis=1)\n",
    "print(f\"删除缺失列后数据形状: {cleaned_drop_cols.shape}\")\n",
    "\n",
    "# 策略3：填充缺失值\n",
    "cleaned_filled = dirty_data.copy()\n",
    "\n",
    "# 用平均值填充数值列\n",
    "cleaned_filled['年龄'].fillna(cleaned_filled['年龄'].mean(), inplace=True)\n",
    "cleaned_filled['收入'].fillna(cleaned_filled['收入'].median(), inplace=True)\n",
    "\n",
    "# 用众数填充分类列\n",
    "cleaned_filled['姓名'].fillna('未知', inplace=True)\n",
    "\n",
    "print(f\"填充后的缺失值统计:\")\n",
    "print(cleaned_filled.isnull().sum())\n",
    "\n",
    "# 前向填充和后向填充\n",
    "ff_data = dirty_data.copy()\n",
    "ff_data['年龄'] = ff_data['年龄'].fillna(method='ffill')  # 前向填充\n",
    "bf_data = dirty_data.copy()\n",
    "bf_data['年龄'] = bf_data['年龄'].fillna(method='bfill')  # 后向填充\n",
    "\n",
    "print(f\"\\n前向填充年龄列: {ff_data['年龄'].tolist()}\")\n",
    "print(f\"后向填充年龄列: {bf_data['年龄'].tolist()}\")\n",
    "\n",
    "print(\"\\n=== 重复值处理 ===\")\n",
    "# 检查完全重复的行\n",
    "duplicate_rows = dirty_data.duplicated()\n",
    "print(f\"完全重复的行数: {duplicate_rows.sum()}\")\n",
    "print(f\"重复行索引: {dirty_data[duplicate_rows].index.tolist()}\")\n",
    "\n",
    "# 基于特定列检查重复\n",
    "name_duplicates = dirty_data.duplicated(subset=['姓名'])\n",
    "print(f\"姓名重复的行数: {name_duplicates.sum()}\")\n",
    "\n",
    "# 查看重复的具体内容\n",
    "print(f\"\\n重复的姓名记录:\")\n",
    "duplicated_names = dirty_data[dirty_data.duplicated(subset=['姓名'], keep=False)]\n",
    "print(duplicated_names.sort_values('姓名'))\n",
    "\n",
    "# 去除重复值\n",
    "no_duplicates = dirty_data.drop_duplicates()\n",
    "print(f\"\\n去除完全重复后的数据形状: {no_duplicates.shape}\")\n",
    "\n",
    "# 基于特定列去重，保留第一个\n",
    "no_name_duplicates = dirty_data.drop_duplicates(subset=['姓名'], keep='first')\n",
    "print(f\"去除姓名重复后的数据形状: {no_name_duplicates.shape}\")\n",
    "\n",
    "print(\"\\n=== 数据类型转换 ===\")\n",
    "# 查看当前数据类型\n",
    "print(\"当前数据类型:\")\n",
    "print(cleaned_filled.dtypes)\n",
    "\n",
    "# 类型转换\n",
    "type_converted = cleaned_filled.copy()\n",
    "\n",
    "# 数值类型转换\n",
    "type_converted['年龄'] = type_converted['年龄'].astype(int)\n",
    "type_converted['收入'] = type_converted['收入'].astype(float)\n",
    "\n",
    "# 分类类型转换\n",
    "type_converted['学历'] = type_converted['学历'].astype('category')\n",
    "type_converted['城市'] = type_converted['城市'].astype('category')\n",
    "\n",
    "print(f\"\\n转换后的数据类型:\")\n",
    "print(type_converted.dtypes)\n",
    "\n",
    "# 查看分类数据的类别\n",
    "print(f\"\\n学历类别: {type_converted['学历'].cat.categories.tolist()}\")\n",
    "print(f\"城市类别: {type_converted['城市'].cat.categories.tolist()}\")\n",
    "\n",
    "print(\"\\n=== 字符串处理 ===\")\n",
    "# 字符串清洗\n",
    "string_cleaned = dirty_data.copy()\n",
    "\n",
    "# 去除字符串前后空格\n",
    "string_cleaned['城市'] = string_cleaned['城市'].str.strip()\n",
    "\n",
    "# 替换空字符串为NaN\n",
    "string_cleaned['城市'] = string_cleaned['城市'].replace('', np.nan)\n",
    "\n",
    "# 字符串大小写转换\n",
    "string_cleaned['邮箱_lower'] = string_cleaned['邮箱'].str.lower()\n",
    "\n",
    "# 提取邮箱域名\n",
    "string_cleaned['邮箱域名'] = string_cleaned['邮箱'].str.extract(r'@(.+)')\n",
    "\n",
    "print(\"字符串处理后的结果:\")\n",
    "print(string_cleaned[['城市', '邮箱', '邮箱_lower', '邮箱域名']].head())\n",
    "\n",
    "# 字符串包含判断\n",
    "gmail_users = string_cleaned['邮箱'].str.contains('gmail', na=False)\n",
    "print(f\"\\nGmail用户数量: {gmail_users.sum()}\")\n",
    "\n",
    "print(\"\\n=== 异常值检测和处理 ===\")\n",
    "# 创建包含异常值的数据\n",
    "np.random.seed(42)\n",
    "outlier_data = pd.DataFrame({\n",
    "    '收入': np.concatenate([\n",
    "        np.random.normal(8000, 2000, 95),  # 正常收入\n",
    "        [50000, 80000, 100000, 120000, 200000]  # 异常值\n",
    "    ])\n",
    "})\n",
    "\n",
    "print(f\"收入数据统计:\")\n",
    "print(outlier_data['收入'].describe())\n",
    "\n",
    "# 使用IQR方法检测异常值\n",
    "Q1 = outlier_data['收入'].quantile(0.25)\n",
    "Q3 = outlier_data['收入'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"\\n异常值边界: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "# 识别异常值\n",
    "outliers = (outlier_data['收入'] < lower_bound) | (outlier_data['收入'] > upper_bound)\n",
    "print(f\"异常值数量: {outliers.sum()}\")\n",
    "print(f\"异常值: {outlier_data[outliers]['收入'].tolist()}\")\n",
    "\n",
    "# 处理异常值：限制在合理范围内\n",
    "outlier_data['收入_capped'] = outlier_data['收入'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "print(f\"\\n处理后的收入范围: {outlier_data['收入_capped'].min():.2f} - {outlier_data['收入_capped'].max():.2f}\")\n",
    "\n",
    "print(\"\\n=== 数据验证 ===\")\n",
    "# 创建数据验证规则\n",
    "validation_data = cleaned_filled.copy()\n",
    "\n",
    "# 年龄验证\n",
    "valid_age = (validation_data['年龄'] >= 18) & (validation_data['年龄'] <= 65)\n",
    "print(f\"有效年龄记录数: {valid_age.sum()}/{len(validation_data)}\")\n",
    "\n",
    "# 邮箱格式验证\n",
    "email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "valid_email = validation_data['邮箱'].str.match(email_pattern, na=False)\n",
    "print(f\"有效邮箱记录数: {valid_email.sum()}/{len(validation_data)}\")\n",
    "\n",
    "# 收入合理性验证\n",
    "valid_income = (validation_data['收入'] >= 1000) & (validation_data['收入'] <= 50000)\n",
    "print(f\"合理收入记录数: {valid_income.sum()}/{len(validation_data)}\")\n",
    "\n",
    "# 创建综合验证结果\n",
    "validation_data['数据有效'] = valid_age & valid_email & valid_income\n",
    "print(f\"\\n完全有效的记录数: {validation_data['数据有效'].sum()}/{len(validation_data)}\")\n",
    "\n",
    "print(\"\\n=== 数据标准化和归一化 ===\")\n",
    "# 创建数值数据进行标准化\n",
    "numerical_data = pd.DataFrame({\n",
    "    '身高': np.random.normal(170, 10, 100),\n",
    "    '体重': np.random.normal(65, 15, 100),\n",
    "    '年龄': np.random.randint(18, 60, 100)\n",
    "})\n",
    "\n",
    "print(\"原始数据统计:\")\n",
    "print(numerical_data.describe())\n",
    "\n",
    "# Z-score标准化\n",
    "from scipy import stats\n",
    "standardized_data = numerical_data.copy()\n",
    "for col in numerical_data.columns:\n",
    "    standardized_data[col + '_标准化'] = stats.zscore(numerical_data[col])\n",
    "\n",
    "print(f\"\\n标准化后的数据统计:\")\n",
    "print(standardized_data[['身高_标准化', '体重_标准化', '年龄_标准化']].describe())\n",
    "\n",
    "# Min-Max归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(\n",
    "    scaler.fit_transform(numerical_data),\n",
    "    columns=[col + '_归一化' for col in numerical_data.columns]\n",
    ")\n",
    "\n",
    "print(f\"\\n归一化后的数据统计:\")\n",
    "print(normalized_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ded170",
   "metadata": {},
   "source": [
    "## 5. 分组与聚合操作 (GroupBy)\n",
    "\n",
    "分组操作是pandas中的核心功能，允许我们将数据按某些条件分组，然后对每组数据进行聚合计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建销售数据示例\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'region': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West'] * 3,\n",
    "    'product': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'] * 3,\n",
    "    'salesperson': ['Alice', 'Bob', 'Charlie', 'David'] * 6,\n",
    "    'month': ['Jan', 'Jan', 'Jan', 'Jan', 'Feb', 'Feb', 'Feb', 'Feb', 'Mar', 'Mar', 'Mar', 'Mar'] * 2,\n",
    "    'sales': np.random.randint(100, 1000, 24),\n",
    "    'units': np.random.randint(10, 100, 24)\n",
    "})\n",
    "\n",
    "print(\"销售数据样本:\")\n",
    "print(sales_data.head(10))\n",
    "print(f\"\\n数据形状: {sales_data.shape}\")\n",
    "\n",
    "# 基本分组操作\n",
    "print(\"\\n=== 基本分组操作 ===\")\n",
    "\n",
    "# 按地区分组，计算总销售额\n",
    "region_sales = sales_data.groupby('region')['sales'].sum()\n",
    "print(\"\\n按地区分组的总销售额:\")\n",
    "print(region_sales)\n",
    "\n",
    "# 按产品分组，计算平均销售额和总销量\n",
    "product_stats = sales_data.groupby('product').agg({\n",
    "    'sales': ['sum', 'mean', 'count'],\n",
    "    'units': 'sum'\n",
    "})\n",
    "print(\"\\n按产品分组的统计信息:\")\n",
    "print(product_stats)\n",
    "\n",
    "# 多列分组\n",
    "region_product_sales = sales_data.groupby(['region', 'product'])['sales'].sum()\n",
    "print(\"\\n按地区和产品分组的销售额:\")\n",
    "print(region_product_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc747922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高级分组操作\n",
    "print(\"=== 高级分组操作 ===\")\n",
    "\n",
    "# 使用transform进行组内标准化\n",
    "sales_data['sales_zscore'] = sales_data.groupby('region')['sales'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "print(\"\\n添加组内标准化后的数据:\")\n",
    "print(sales_data[['region', 'sales', 'sales_zscore']].head())\n",
    "\n",
    "# 使用apply进行复杂计算\n",
    "def region_analysis(group):\n",
    "    return pd.Series({\n",
    "        'total_sales': group['sales'].sum(),\n",
    "        'avg_sales': group['sales'].mean(),\n",
    "        'top_performer': group.loc[group['sales'].idxmax(), 'salesperson'],\n",
    "        'sales_range': group['sales'].max() - group['sales'].min(),\n",
    "        'coefficient_of_variation': group['sales'].std() / group['sales'].mean()\n",
    "    })\n",
    "\n",
    "region_detailed = sales_data.groupby('region').apply(region_analysis)\n",
    "print(\"\\n地区详细分析:\")\n",
    "print(region_detailed)\n",
    "\n",
    "# 分位数和百分位数\n",
    "print(\"\\n各地区销售额分位数:\")\n",
    "region_quantiles = sales_data.groupby('region')['sales'].quantile([0.25, 0.5, 0.75]).unstack()\n",
    "print(region_quantiles)\n",
    "\n",
    "# 自定义聚合函数\n",
    "def sales_metrics(series):\n",
    "    return pd.Series({\n",
    "        'total': series.sum(),\n",
    "        'average': series.mean(),\n",
    "        'volatility': series.std(),\n",
    "        'peak_to_trough': series.max() - series.min(),\n",
    "        'above_avg_count': (series > series.mean()).sum()\n",
    "    })\n",
    "\n",
    "custom_agg = sales_data.groupby('product')['sales'].apply(sales_metrics)\n",
    "print(\"\\n产品销售指标:\")\n",
    "print(custom_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de47c9",
   "metadata": {},
   "source": [
    "## 6. 数据合并与连接\n",
    "\n",
    "数据合并是数据分析中的重要操作，pandas提供了多种合并数据的方法：join、merge、concat等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b689aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例数据集\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
    "    'age': [25, 30, 35, 28, 32]\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105, 106],\n",
    "    'customer_id': [1, 2, 2, 3, 6, 7],  # 注意：6和7不在customers表中\n",
    "    'product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse'],\n",
    "    'amount': [1200, 800, 500, 300, 50, 25],\n",
    "    'order_date': pd.to_datetime(['2023-01-15', '2023-01-16', '2023-01-17', \n",
    "                                  '2023-01-18', '2023-01-19', '2023-01-20'])\n",
    "})\n",
    "\n",
    "product_info = pd.DataFrame({\n",
    "    'product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Speaker'],\n",
    "    'category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Audio'],\n",
    "    'cost': [800, 500, 300, 200, 100]\n",
    "})\n",
    "\n",
    "print(\"客户数据:\")\n",
    "print(customers)\n",
    "print(\"\\n订单数据:\")\n",
    "print(orders)\n",
    "print(\"\\n产品信息:\")\n",
    "print(product_info)\n",
    "\n",
    "print(\"\\n=== 不同类型的合并 ===\")\n",
    "\n",
    "# 内连接 (Inner Join) - 只保留两个表都有的记录\n",
    "inner_join = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "print(\"\\n内连接 (Inner Join):\")\n",
    "print(inner_join)\n",
    "\n",
    "# 左连接 (Left Join) - 保留左表所有记录\n",
    "left_join = pd.merge(customers, orders, on='customer_id', how='left')\n",
    "print(\"\\n左连接 (Left Join):\")\n",
    "print(left_join)\n",
    "\n",
    "# 右连接 (Right Join) - 保留右表所有记录\n",
    "right_join = pd.merge(customers, orders, on='customer_id', how='right')\n",
    "print(\"\\n右连接 (Right Join):\")\n",
    "print(right_join)\n",
    "\n",
    "# 外连接 (Outer Join) - 保留两个表的所有记录\n",
    "outer_join = pd.merge(customers, orders, on='customer_id', how='outer')\n",
    "print(\"\\n外连接 (Outer Join):\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多表连接\n",
    "print(\"=== 多表连接 ===\")\n",
    "\n",
    "# 三表连接：客户 -> 订单 -> 产品信息\n",
    "multi_join = (customers\n",
    "              .merge(orders, on='customer_id', how='inner')\n",
    "              .merge(product_info, on='product', how='left'))\n",
    "\n",
    "print(\"\\n三表连接结果:\")\n",
    "print(multi_join)\n",
    "\n",
    "# 计算利润\n",
    "multi_join['profit'] = multi_join['amount'] - multi_join['cost']\n",
    "print(\"\\n添加利润计算:\")\n",
    "print(multi_join[['name', 'product', 'amount', 'cost', 'profit']])\n",
    "\n",
    "print(\"\\n=== 不同连接键的合并 ===\")\n",
    "\n",
    "# 不同列名的连接\n",
    "customers_alt = customers.rename(columns={'customer_id': 'cust_id'})\n",
    "diff_key_merge = pd.merge(customers_alt, orders, \n",
    "                         left_on='cust_id', right_on='customer_id', how='inner')\n",
    "print(\"\\n不同列名连接:\")\n",
    "print(diff_key_merge[['cust_id', 'name', 'order_id', 'product']])\n",
    "\n",
    "# 基于索引的连接\n",
    "customers_indexed = customers.set_index('customer_id')\n",
    "orders_indexed = orders.set_index('customer_id')\n",
    "index_join = customers_indexed.join(orders_indexed, how='inner', rsuffix='_order')\n",
    "print(\"\\n基于索引的连接:\")\n",
    "print(index_join)\n",
    "\n",
    "print(\"\\n=== 使用concat进行数据连接 ===\")\n",
    "\n",
    "# 创建额外数据用于演示concat\n",
    "customers_2023_q1 = pd.DataFrame({\n",
    "    'customer_id': [6, 7, 8],\n",
    "    'name': ['Frank', 'Grace', 'Henry'],\n",
    "    'city': ['Seattle', 'Boston', 'Miami'],\n",
    "    'age': [29, 31, 27]\n",
    "})\n",
    "\n",
    "customers_2023_q2 = pd.DataFrame({\n",
    "    'customer_id': [9, 10, 11],\n",
    "    'name': ['Ivy', 'Jack', 'Kate'],\n",
    "    'city': ['Denver', 'Portland', 'Atlanta'],\n",
    "    'age': [26, 33, 30]\n",
    "})\n",
    "\n",
    "# 垂直连接 (行拼接)\n",
    "all_customers = pd.concat([customers, customers_2023_q1, customers_2023_q2], \n",
    "                         ignore_index=True)\n",
    "print(\"\\n垂直连接 (行拼接):\")\n",
    "print(all_customers)\n",
    "\n",
    "# 水平连接 (列拼接)\n",
    "customer_details = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'email': ['alice@email.com', 'bob@email.com', 'charlie@email.com', \n",
    "              'david@email.com', 'eve@email.com'],\n",
    "    'phone': ['123-456-7890', '234-567-8901', '345-678-9012', \n",
    "              '456-789-0123', '567-890-1234']\n",
    "})\n",
    "\n",
    "# 基于索引的水平连接\n",
    "customers_extended = pd.concat([customers.set_index('customer_id'), \n",
    "                               customer_details.set_index('customer_id')], \n",
    "                              axis=1)\n",
    "print(\"\\n水平连接 (列拼接):\")\n",
    "print(customers_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de417f82",
   "metadata": {},
   "source": [
    "## 7. 时间序列处理\n",
    "\n",
    "时间序列数据在金融、业务分析等领域非常常见。pandas提供了强大的时间序列处理功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建时间序列数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 生成日期范围\n",
    "date_range = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "print(f\"日期范围: {date_range[:5]}...{date_range[-3:]}\")\n",
    "print(f\"总天数: {len(date_range)}\")\n",
    "\n",
    "# 创建时间序列DataFrame\n",
    "np.random.seed(42)\n",
    "ts_data = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'temperature': 20 + 10 * np.sin(2 * np.pi * np.arange(len(date_range)) / 365.25) + np.random.normal(0, 2, len(date_range)),\n",
    "    'humidity': 50 + 20 * np.sin(2 * np.pi * np.arange(len(date_range)) / 365.25 + np.pi/4) + np.random.normal(0, 5, len(date_range)),\n",
    "    'precipitation': np.random.exponential(2, len(date_range))\n",
    "})\n",
    "\n",
    "# 设置日期为索引\n",
    "ts_data.set_index('date', inplace=True)\n",
    "print(\"\\n时间序列数据样本:\")\n",
    "print(ts_data.head())\n",
    "\n",
    "print(\"\\n=== 基本时间序列操作 ===\")\n",
    "\n",
    "# 日期时间属性提取\n",
    "ts_data['year'] = ts_data.index.year\n",
    "ts_data['month'] = ts_data.index.month\n",
    "ts_data['day_of_week'] = ts_data.index.dayofweek\n",
    "ts_data['day_name'] = ts_data.index.day_name()\n",
    "ts_data['is_weekend'] = ts_data.index.dayofweek >= 5\n",
    "\n",
    "print(\"\\n添加日期属性后:\")\n",
    "print(ts_data[['temperature', 'year', 'month', 'day_of_week', 'day_name', 'is_weekend']].head())\n",
    "\n",
    "# 时间范围选择\n",
    "print(\"\\n2023年3月的数据:\")\n",
    "march_data = ts_data['2023-03']\n",
    "print(march_data.head())\n",
    "\n",
    "print(f\"\\n3月平均温度: {march_data['temperature'].mean():.2f}°C\")\n",
    "\n",
    "# 季度重采样\n",
    "quarterly_avg = ts_data.resample('Q').mean()\n",
    "print(\"\\n季度平均值:\")\n",
    "print(quarterly_avg)\n",
    "\n",
    "# 月度统计\n",
    "monthly_stats = ts_data.resample('M').agg({\n",
    "    'temperature': ['mean', 'min', 'max'],\n",
    "    'humidity': 'mean',\n",
    "    'precipitation': 'sum'\n",
    "})\n",
    "print(\"\\n月度统计:\")\n",
    "print(monthly_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滑动窗口分析\n",
    "print(\"=== 滑动窗口分析 ===\")\n",
    "\n",
    "# 7天移动平均\n",
    "ts_data['temp_7day_ma'] = ts_data['temperature'].rolling(window=7).mean()\n",
    "ts_data['temp_30day_ma'] = ts_data['temperature'].rolling(window=30).mean()\n",
    "\n",
    "print(\"\\n移动平均:\")\n",
    "print(ts_data[['temperature', 'temp_7day_ma', 'temp_30day_ma']].head(10))\n",
    "\n",
    "# 滑动窗口统计\n",
    "rolling_stats = ts_data['temperature'].rolling(window=30).agg(['mean', 'std', 'min', 'max'])\n",
    "rolling_stats.columns = ['30day_mean', '30day_std', '30day_min', '30day_max']\n",
    "ts_data = pd.concat([ts_data, rolling_stats], axis=1)\n",
    "\n",
    "print(\"\\n30天滑动窗口统计:\")\n",
    "print(ts_data[['temperature', '30day_mean', '30day_std', '30day_min', '30day_max']].dropna().head())\n",
    "\n",
    "# 指数移动平均\n",
    "ts_data['temp_ema'] = ts_data['temperature'].ewm(span=14).mean()\n",
    "print(\"\\n指数移动平均 vs 简单移动平均:\")\n",
    "comparison = ts_data[['temperature', 'temp_7day_ma', 'temp_ema']].dropna()\n",
    "print(comparison.head())\n",
    "\n",
    "print(\"\\n=== 时间序列分析 ===\")\n",
    "\n",
    "# 季节性分解 (简单版本)\n",
    "ts_data['month_avg'] = ts_data.groupby('month')['temperature'].transform('mean')\n",
    "ts_data['seasonal'] = ts_data['temperature'] - ts_data['month_avg']\n",
    "ts_data['trend'] = ts_data['temperature'].rolling(window=30, center=True).mean()\n",
    "ts_data['residual'] = ts_data['temperature'] - ts_data['trend'] - ts_data['seasonal']\n",
    "\n",
    "print(\"\\n季节性分解:\")\n",
    "decomposition = ts_data[['temperature', 'trend', 'seasonal', 'residual']].dropna()\n",
    "print(decomposition.head())\n",
    "\n",
    "# 滞后变量和差分\n",
    "ts_data['temp_lag1'] = ts_data['temperature'].shift(1)\n",
    "ts_data['temp_lag7'] = ts_data['temperature'].shift(7)\n",
    "ts_data['temp_diff1'] = ts_data['temperature'].diff()\n",
    "ts_data['temp_diff7'] = ts_data['temperature'].diff(7)\n",
    "\n",
    "print(\"\\n滞后和差分变量:\")\n",
    "lag_diff = ts_data[['temperature', 'temp_lag1', 'temp_lag7', 'temp_diff1', 'temp_diff7']].dropna()\n",
    "print(lag_diff.head())\n",
    "\n",
    "# 相关性分析\n",
    "correlation_matrix = ts_data[['temperature', 'humidity', 'precipitation']].corr()\n",
    "print(\"\\n气象变量相关性:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 异常值检测 (基于标准差)\n",
    "ts_data['temp_zscore'] = (ts_data['temperature'] - ts_data['temperature'].mean()) / ts_data['temperature'].std()\n",
    "outliers = ts_data[abs(ts_data['temp_zscore']) > 2.5]\n",
    "print(f\"\\n异常值数量 (|z-score| > 2.5): {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(\"异常值示例:\")\n",
    "    print(outliers[['temperature', 'temp_zscore']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460c0d9",
   "metadata": {},
   "source": [
    "## 8. 数据透视表与交叉表\n",
    "\n",
    "数据透视表是数据分析中强大的工具，可以快速汇总和重组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建扩展的销售数据用于透视表演示\n",
    "np.random.seed(42)\n",
    "extended_sales = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', '2023-12-31', freq='D'),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 365),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'], 365),\n",
    "    'salesperson': np.random.choice(['Alice', 'Bob', 'Charlie', 'David', 'Eve'], 365),\n",
    "    'customer_type': np.random.choice(['Individual', 'Business'], 365),\n",
    "    'sales_amount': np.random.randint(100, 2000, 365),\n",
    "    'units_sold': np.random.randint(1, 20, 365)\n",
    "})\n",
    "\n",
    "extended_sales['month'] = extended_sales['date'].dt.month\n",
    "extended_sales['quarter'] = extended_sales['date'].dt.quarter\n",
    "extended_sales['day_of_week'] = extended_sales['date'].dt.day_name()\n",
    "\n",
    "print(\"扩展销售数据样本:\")\n",
    "print(extended_sales.head())\n",
    "\n",
    "print(\"\\n=== 基础透视表 ===\")\n",
    "\n",
    "# 简单透视表：按地区和产品汇总销售额\n",
    "pivot_basic = pd.pivot_table(extended_sales, \n",
    "                            values='sales_amount', \n",
    "                            index='region', \n",
    "                            columns='product', \n",
    "                            aggfunc='sum')\n",
    "print(\"\\n按地区和产品的销售额透视表:\")\n",
    "print(pivot_basic)\n",
    "\n",
    "# 添加总计\n",
    "pivot_with_totals = pd.pivot_table(extended_sales, \n",
    "                                  values='sales_amount', \n",
    "                                  index='region', \n",
    "                                  columns='product', \n",
    "                                  aggfunc='sum',\n",
    "                                  margins=True,\n",
    "                                  margins_name='总计')\n",
    "print(\"\\n带总计的透视表:\")\n",
    "print(pivot_with_totals)\n",
    "\n",
    "print(\"\\n=== 多值透视表 ===\")\n",
    "\n",
    "# 多个聚合值\n",
    "multi_value_pivot = pd.pivot_table(extended_sales,\n",
    "                                  values=['sales_amount', 'units_sold'],\n",
    "                                  index='region',\n",
    "                                  columns='customer_type',\n",
    "                                  aggfunc={'sales_amount': 'sum', 'units_sold': 'sum'})\n",
    "print(\"\\n多值透视表 (销售额和销量):\")\n",
    "print(multi_value_pivot)\n",
    "\n",
    "print(\"\\n=== 多级索引透视表 ===\")\n",
    "\n",
    "# 多级行和列索引\n",
    "multi_level_pivot = pd.pivot_table(extended_sales,\n",
    "                                  values='sales_amount',\n",
    "                                  index=['region', 'salesperson'],\n",
    "                                  columns=['quarter', 'customer_type'],\n",
    "                                  aggfunc='mean')\n",
    "print(\"\\n多级索引透视表:\")\n",
    "print(multi_level_pivot.head(10))\n",
    "\n",
    "print(\"\\n=== 不同聚合函数 ===\")\n",
    "\n",
    "# 使用不同的聚合函数\n",
    "agg_functions_pivot = pd.pivot_table(extended_sales,\n",
    "                                    values='sales_amount',\n",
    "                                    index='product',\n",
    "                                    columns='quarter',\n",
    "                                    aggfunc=['sum', 'mean', 'count', 'std'])\n",
    "print(\"\\n多种聚合函数透视表:\")\n",
    "print(agg_functions_pivot)\n",
    "\n",
    "# 自定义聚合函数\n",
    "def sales_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "custom_agg_pivot = pd.pivot_table(extended_sales,\n",
    "                                 values='sales_amount',\n",
    "                                 index='region',\n",
    "                                 columns='product',\n",
    "                                 aggfunc=[np.mean, sales_range])\n",
    "print(\"\\n自定义聚合函数透视表:\")\n",
    "print(custom_agg_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93354e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉表分析\n",
    "print(\"=== 交叉表 ===\")\n",
    "\n",
    "# 简单交叉表：地区 vs 客户类型\n",
    "crosstab_basic = pd.crosstab(extended_sales['region'], \n",
    "                           extended_sales['customer_type'])\n",
    "print(\"\\n地区 vs 客户类型交叉表:\")\n",
    "print(crosstab_basic)\n",
    "\n",
    "# 带比例的交叉表\n",
    "crosstab_prop = pd.crosstab(extended_sales['region'], \n",
    "                          extended_sales['customer_type'], \n",
    "                          normalize='index')  # 按行标准化\n",
    "print(\"\\n地区 vs 客户类型比例交叉表:\")\n",
    "print(crosstab_prop)\n",
    "\n",
    "# 三维交叉表\n",
    "crosstab_3d = pd.crosstab([extended_sales['region'], extended_sales['quarter']], \n",
    "                         extended_sales['customer_type'],\n",
    "                         margins=True)\n",
    "print(\"\\n三维交叉表 (地区+季度 vs 客户类型):\")\n",
    "print(crosstab_3d)\n",
    "\n",
    "# 带值的交叉表\n",
    "crosstab_values = pd.crosstab(extended_sales['region'], \n",
    "                            extended_sales['product'],\n",
    "                            values=extended_sales['sales_amount'],\n",
    "                            aggfunc='mean')\n",
    "print(\"\\n带平均销售额的交叉表:\")\n",
    "print(crosstab_values)\n",
    "\n",
    "print(\"\\n=== 数据重塑 ===\")\n",
    "\n",
    "# 创建宽格式数据\n",
    "sales_monthly = extended_sales.groupby(['region', 'month'])['sales_amount'].sum().reset_index()\n",
    "print(\"\\n月度销售数据:\")\n",
    "print(sales_monthly.head(10))\n",
    "\n",
    "# 长格式转宽格式 (pivot)\n",
    "wide_format = sales_monthly.pivot(index='region', columns='month', values='sales_amount')\n",
    "print(\"\\n宽格式数据 (每列是一个月):\")\n",
    "print(wide_format.head())\n",
    "\n",
    "# 宽格式转长格式 (melt)\n",
    "long_format = wide_format.reset_index().melt(id_vars='region', \n",
    "                                           var_name='month', \n",
    "                                           value_name='sales_amount')\n",
    "print(\"\\n转回长格式:\")\n",
    "print(long_format.head(10))\n",
    "\n",
    "# 复杂的melt操作\n",
    "complex_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['A', 'B', 'C'],\n",
    "    'math_q1': [85, 90, 78],\n",
    "    'math_q2': [88, 92, 80],\n",
    "    'science_q1': [92, 88, 85],\n",
    "    'science_q2': [90, 90, 87]\n",
    "})\n",
    "\n",
    "print(\"\\n原始成绩数据:\")\n",
    "print(complex_data)\n",
    "\n",
    "# 使用melt重塑数据\n",
    "melted_scores = pd.melt(complex_data, \n",
    "                       id_vars=['id', 'name'],\n",
    "                       var_name='subject_quarter', \n",
    "                       value_name='score')\n",
    "\n",
    "# 分离科目和季度\n",
    "melted_scores[['subject', 'quarter']] = melted_scores['subject_quarter'].str.split('_', expand=True)\n",
    "melted_scores = melted_scores.drop('subject_quarter', axis=1)\n",
    "\n",
    "print(\"\\n重塑后的成绩数据:\")\n",
    "print(melted_scores)\n",
    "\n",
    "# stack和unstack操作\n",
    "print(\"\\n=== Stack和Unstack ===\")\n",
    "\n",
    "# 创建多级索引数据\n",
    "multi_index_data = extended_sales.groupby(['region', 'product'])['sales_amount'].sum()\n",
    "print(\"\\n多级索引数据:\")\n",
    "print(multi_index_data.head(10))\n",
    "\n",
    "# unstack：将内层索引转为列\n",
    "unstacked = multi_index_data.unstack()\n",
    "print(\"\\n Unstack后 (产品作为列):\")\n",
    "print(unstacked.head())\n",
    "\n",
    "# stack：将列转为内层索引\n",
    "restacked = unstacked.stack()\n",
    "print(\"\\n重新Stack:\")\n",
    "print(restacked.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9dc03",
   "metadata": {},
   "source": [
    "## 9. 基础数据可视化\n",
    "\n",
    "虽然专门的可视化会在matplotlib教程中详细介绍，但pandas提供了快速绘图功能，对数据探索非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas内置绘图功能\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体和图形样式\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']  # 支持中文\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "print(\"=== 基础绘图 ===\")\n",
    "\n",
    "# 创建示例数据\n",
    "sample_data = extended_sales.groupby('date')['sales_amount'].sum().resample('W').mean()\n",
    "\n",
    "# 线图\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sample_data.plot(title='周平均销售额趋势', color='blue')\n",
    "plt.ylabel('销售额')\n",
    "\n",
    "# 柱状图\n",
    "plt.subplot(2, 2, 2)\n",
    "region_sales = extended_sales.groupby('region')['sales_amount'].sum()\n",
    "region_sales.plot(kind='bar', title='各地区总销售额', color='green')\n",
    "plt.ylabel('销售额')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 饼图\n",
    "plt.subplot(2, 2, 3)\n",
    "product_sales = extended_sales.groupby('product')['sales_amount'].sum()\n",
    "product_sales.plot(kind='pie', title='产品销售额分布', autopct='%1.1f%%')\n",
    "\n",
    "# 直方图\n",
    "plt.subplot(2, 2, 4)\n",
    "extended_sales['sales_amount'].plot(kind='hist', bins=30, title='销售额分布', alpha=0.7)\n",
    "plt.xlabel('销售额')\n",
    "plt.ylabel('频次')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== 高级绘图 ===\")\n",
    "\n",
    "# 箱线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "extended_sales.boxplot(column='sales_amount', by='region', ax=plt.gca())\n",
    "plt.title('各地区销售额箱线图')\n",
    "plt.suptitle('')  # 移除默认标题\n",
    "\n",
    "# 散点图矩阵\n",
    "plt.subplot(1, 2, 2)\n",
    "numeric_data = extended_sales[['sales_amount', 'units_sold', 'month', 'quarter']]\n",
    "pd.plotting.scatter_matrix(numeric_data, alpha=0.5, figsize=(6, 6), diagonal='hist')\n",
    "plt.suptitle('数值变量散点图矩阵')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 时间序列可视化\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# 月度趋势\n",
    "monthly_sales = extended_sales.groupby([extended_sales['date'].dt.to_period('M'), 'region'])['sales_amount'].sum().unstack()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "monthly_sales.plot(title='各地区月度销售趋势', marker='o')\n",
    "plt.ylabel('销售额')\n",
    "plt.legend(title='地区')\n",
    "\n",
    "# 累计销售额\n",
    "plt.subplot(2, 1, 2)\n",
    "cumulative_sales = extended_sales.groupby('date')['sales_amount'].sum().cumsum()\n",
    "cumulative_sales.plot(title='累计销售额', color='red', linewidth=2)\n",
    "plt.ylabel('累计销售额')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== 相关性热力图 ===\")\n",
    "\n",
    "# 计算相关性矩阵\n",
    "correlation_data = extended_sales[['sales_amount', 'units_sold', 'month', 'quarter']].corr()\n",
    "\n",
    "# 使用matplotlib绘制热力图\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(correlation_data, cmap='coolwarm', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(correlation_data.columns)), correlation_data.columns, rotation=45)\n",
    "plt.yticks(range(len(correlation_data.columns)), correlation_data.columns)\n",
    "plt.title('变量相关性热力图')\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(len(correlation_data.columns)):\n",
    "    for j in range(len(correlation_data.columns)):\n",
    "        plt.text(j, i, f'{correlation_data.iloc[i, j]:.2f}', \n",
    "                ha='center', va='center', color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"可视化完成！注意：\")\n",
    "print(\"1. pandas的plot()方法基于matplotlib\")\n",
    "print(\"2. 适合快速数据探索和原型制作\")\n",
    "print(\"3. 更复杂的可视化建议使用matplotlib或seaborn\")\n",
    "print(\"4. 交互式可视化可以考虑plotly或bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935c3b4",
   "metadata": {},
   "source": [
    "## 10. 高级特性与最佳实践\n",
    "\n",
    "这一节涵盖pandas的高级功能和在实际项目中的最佳实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能优化与内存管理\n",
    "import time\n",
    "import sys\n",
    "\n",
    "print(\"=== 性能优化技巧 ===\")\n",
    "\n",
    "# 创建大数据集用于性能测试\n",
    "large_data = pd.DataFrame({\n",
    "    'id': range(100000),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], 100000),\n",
    "    'value': np.random.randn(100000),\n",
    "    'date': pd.date_range('2020-01-01', periods=100000, freq='min')\n",
    "})\n",
    "\n",
    "print(f\"数据集大小: {large_data.shape}\")\n",
    "print(f\"内存使用: {large_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 数据类型优化\n",
    "print(\"\\n=== 数据类型优化 ===\")\n",
    "\n",
    "# 查看原始数据类型\n",
    "print(\"原始数据类型:\")\n",
    "print(large_data.dtypes)\n",
    "print(f\"原始内存使用: {large_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 优化数据类型\n",
    "optimized_data = large_data.copy()\n",
    "\n",
    "# 将category列转为category类型\n",
    "optimized_data['category'] = optimized_data['category'].astype('category')\n",
    "\n",
    "# 将value列转为float32（如果精度允许）\n",
    "optimized_data['value'] = optimized_data['value'].astype('float32')\n",
    "\n",
    "print(\"\\n优化后数据类型:\")\n",
    "print(optimized_data.dtypes)\n",
    "print(f\"优化后内存使用: {optimized_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "memory_saved = (large_data.memory_usage(deep=True).sum() - optimized_data.memory_usage(deep=True).sum()) / 1024**2\n",
    "print(f\"节省内存: {memory_saved:.2f} MB ({memory_saved/large_data.memory_usage(deep=True).sum()*1024**2*100:.1f}%)\")\n",
    "\n",
    "# 向量化操作 vs 循环\n",
    "print(\"\\n=== 向量化操作性能对比 ===\")\n",
    "\n",
    "# 创建测试数据\n",
    "test_data = pd.Series(np.random.randn(50000))\n",
    "\n",
    "# 方法1：使用循环（不推荐）\n",
    "start_time = time.time()\n",
    "result_loop = []\n",
    "for value in test_data:\n",
    "    if value > 0:\n",
    "        result_loop.append(value * 2)\n",
    "    else:\n",
    "        result_loop.append(value / 2)\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# 方法2：使用向量化操作（推荐）\n",
    "start_time = time.time()\n",
    "result_vectorized = np.where(test_data > 0, test_data * 2, test_data / 2)\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "print(f\"循环方法耗时: {loop_time:.4f} 秒\")\n",
    "print(f\"向量化方法耗时: {vectorized_time:.4f} 秒\")\n",
    "print(f\"向量化提速: {loop_time/vectorized_time:.1f}x\")\n",
    "\n",
    "# 使用eval()和query()进行快速计算\n",
    "print(\"\\n=== eval()和query()优化 ===\")\n",
    "\n",
    "# 创建测试数据\n",
    "df_eval = pd.DataFrame({\n",
    "    'A': np.random.randn(10000),\n",
    "    'B': np.random.randn(10000),\n",
    "    'C': np.random.randn(10000)\n",
    "})\n",
    "\n",
    "# 传统方法\n",
    "start_time = time.time()\n",
    "result_traditional = df_eval[(df_eval['A'] > 0) & (df_eval['B'] < 0.5)]['C'].sum()\n",
    "traditional_time = time.time() - start_time\n",
    "\n",
    "# 使用query()\n",
    "start_time = time.time()\n",
    "result_query = df_eval.query('A > 0 and B < 0.5')['C'].sum()\n",
    "query_time = time.time() - start_time\n",
    "\n",
    "# 使用eval()进行计算\n",
    "start_time = time.time()\n",
    "df_eval['D'] = df_eval.eval('A + B * C')\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "print(f\"传统筛选耗时: {traditional_time:.4f} 秒\")\n",
    "print(f\"query()筛选耗时: {query_time:.4f} 秒\")\n",
    "print(f\"eval()计算耗时: {eval_time:.4f} 秒\")\n",
    "\n",
    "print(\"\\n=== 大文件处理技巧 ===\")\n",
    "\n",
    "# 分块读取大文件\n",
    "def process_large_file_demo():\n",
    "    \"\"\"演示分块处理大文件的方法\"\"\"\n",
    "    \n",
    "    # 模拟创建大文件\n",
    "    sample_large_data = pd.DataFrame({\n",
    "        'id': range(50000),\n",
    "        'value': np.random.randn(50000),\n",
    "        'category': np.random.choice(['X', 'Y', 'Z'], 50000)\n",
    "    })\n",
    "    \n",
    "    # 保存为CSV\n",
    "    sample_large_data.to_csv('/tmp/large_file.csv', index=False)\n",
    "    \n",
    "    # 分块读取和处理\n",
    "    chunk_size = 10000\n",
    "    total_sum = 0\n",
    "    category_counts = {}\n",
    "    \n",
    "    for chunk in pd.read_csv('/tmp/large_file.csv', chunksize=chunk_size):\n",
    "        # 处理每个chunk\n",
    "        total_sum += chunk['value'].sum()\n",
    "        \n",
    "        # 累计类别计数\n",
    "        for category, count in chunk['category'].value_counts().items():\n",
    "            category_counts[category] = category_counts.get(category, 0) + count\n",
    "    \n",
    "    print(f\"总和: {total_sum:.2f}\")\n",
    "    print(f\"类别计数: {category_counts}\")\n",
    "\n",
    "# 调用演示函数\n",
    "process_large_file_demo()\n",
    "\n",
    "print(\"\\n=== 索引优化 ===\")\n",
    "\n",
    "# 创建测试数据\n",
    "test_df = pd.DataFrame({\n",
    "    'key': np.random.choice(['A', 'B', 'C'], 10000),\n",
    "    'value': np.random.randn(10000)\n",
    "})\n",
    "\n",
    "# 无索引查询\n",
    "start_time = time.time()\n",
    "result_no_index = test_df[test_df['key'] == 'A']['value'].mean()\n",
    "no_index_time = time.time() - start_time\n",
    "\n",
    "# 设置索引后查询\n",
    "indexed_df = test_df.set_index('key')\n",
    "start_time = time.time()\n",
    "result_with_index = indexed_df.loc['A']['value'].mean()\n",
    "with_index_time = time.time() - start_time\n",
    "\n",
    "print(f\"无索引查询耗时: {no_index_time:.4f} 秒\")\n",
    "print(f\"有索引查询耗时: {with_index_time:.4f} 秒\")\n",
    "print(f\"索引提速: {no_index_time/with_index_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa97b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最佳实践和代码风格\n",
    "print(\"=== 最佳实践 ===\")\n",
    "\n",
    "# 1. 方法链式调用\n",
    "print(\"1. 方法链式调用 (Method Chaining):\")\n",
    "\n",
    "# 不推荐的方式\n",
    "df_temp = extended_sales.copy()\n",
    "df_temp = df_temp[df_temp['sales_amount'] > 500]\n",
    "df_temp = df_temp.groupby('region')['sales_amount'].mean()\n",
    "df_temp = df_temp.sort_values(ascending=False)\n",
    "\n",
    "# 推荐的链式调用\n",
    "result_chained = (extended_sales\n",
    "                 .query('sales_amount > 500')\n",
    "                 .groupby('region')['sales_amount']\n",
    "                 .mean()\n",
    "                 .sort_values(ascending=False))\n",
    "\n",
    "print(\"链式调用结果:\")\n",
    "print(result_chained)\n",
    "\n",
    "# 2. 使用assign创建新列\n",
    "print(\"\\n2. 使用assign()创建新列:\")\n",
    "\n",
    "# 传统方式\n",
    "df_traditional = extended_sales.copy()\n",
    "df_traditional['profit_margin'] = df_traditional['sales_amount'] * 0.2\n",
    "df_traditional['is_high_value'] = df_traditional['sales_amount'] > 1000\n",
    "\n",
    "# 使用assign（更优雅）\n",
    "df_assigned = (extended_sales\n",
    "              .assign(profit_margin=lambda x: x['sales_amount'] * 0.2,\n",
    "                     is_high_value=lambda x: x['sales_amount'] > 1000))\n",
    "\n",
    "print(\"使用assign创建的列:\")\n",
    "print(df_assigned[['sales_amount', 'profit_margin', 'is_high_value']].head())\n",
    "\n",
    "# 3. 条件逻辑的优雅处理\n",
    "print(\"\\n3. 条件逻辑处理:\")\n",
    "\n",
    "# 使用np.select进行多条件分类\n",
    "conditions = [\n",
    "    extended_sales['sales_amount'] < 300,\n",
    "    extended_sales['sales_amount'] < 700,\n",
    "    extended_sales['sales_amount'] < 1200\n",
    "]\n",
    "choices = ['低', '中', '高']\n",
    "extended_sales['销售等级'] = np.select(conditions, choices, default='很高')\n",
    "\n",
    "print(\"销售等级分布:\")\n",
    "print(extended_sales['销售等级'].value_counts())\n",
    "\n",
    "print(\"\\n=== 实际案例：电商数据分析 ===\")\n",
    "\n",
    "# 创建模拟电商数据\n",
    "np.random.seed(42)\n",
    "ecommerce_data = pd.DataFrame({\n",
    "    'order_id': range(1, 1001),\n",
    "    'customer_id': np.random.randint(1, 201, 1000),\n",
    "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports'], 1000),\n",
    "    'order_value': np.random.exponential(100, 1000) + 20,\n",
    "    'order_date': pd.date_range('2023-01-01', periods=1000, freq='H'),\n",
    "    'shipping_cost': np.random.uniform(5, 50, 1000),\n",
    "    'customer_rating': np.random.choice([1, 2, 3, 4, 5], 1000, p=[0.05, 0.1, 0.15, 0.35, 0.35])\n",
    "})\n",
    "\n",
    "print(\"电商数据样本:\")\n",
    "print(ecommerce_data.head())\n",
    "\n",
    "# 综合分析流程\n",
    "analysis_result = (ecommerce_data\n",
    "    # 1. 数据清洗\n",
    "    .assign(\n",
    "        net_value=lambda x: x['order_value'] - x['shipping_cost'],\n",
    "        order_month=lambda x: x['order_date'].dt.to_period('M'),\n",
    "        is_high_rating=lambda x: x['customer_rating'] >= 4\n",
    "    )\n",
    "    # 2. 筛选有效订单\n",
    "    .query('order_value > 0 and shipping_cost > 0')\n",
    "    # 3. 分组分析\n",
    "    .groupby(['product_category', 'order_month'])\n",
    "    .agg({\n",
    "        'order_value': ['count', 'mean', 'sum'],\n",
    "        'net_value': 'mean',\n",
    "        'customer_rating': 'mean',\n",
    "        'is_high_rating': 'mean'\n",
    "    })\n",
    "    # 4. 重新整理列名\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\n电商数据综合分析结果:\")\n",
    "print(analysis_result.head(10))\n",
    "\n",
    "# 客户价值分析\n",
    "customer_analysis = (ecommerce_data\n",
    "    .groupby('customer_id')\n",
    "    .agg({\n",
    "        'order_id': 'count',  # 订单频次\n",
    "        'order_value': ['sum', 'mean'],  # 总消费和平均消费\n",
    "        'customer_rating': 'mean',  # 平均评分\n",
    "        'order_date': ['min', 'max']  # 首次和最近购买时间\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# 展平多级列名\n",
    "customer_analysis.columns = ['_'.join(col).strip() for col in customer_analysis.columns]\n",
    "\n",
    "# 计算客户生命周期\n",
    "customer_analysis['days_between_orders'] = (\n",
    "    pd.to_datetime(customer_analysis['order_date_max']) - \n",
    "    pd.to_datetime(customer_analysis['order_date_min'])\n",
    ").dt.days\n",
    "\n",
    "# 客户分层\n",
    "customer_analysis['customer_tier'] = pd.cut(\n",
    "    customer_analysis['order_value_sum'], \n",
    "    bins=[0, 200, 500, 1000, float('inf')],\n",
    "    labels=['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    ")\n",
    "\n",
    "print(\"\\n客户价值分析 (前10名):\")\n",
    "top_customers = customer_analysis.sort_values('order_value_sum', ascending=False).head(10)\n",
    "print(top_customers[['order_id_count', 'order_value_sum', 'order_value_mean', 'customer_tier']])\n",
    "\n",
    "print(\"\\n客户分层统计:\")\n",
    "print(customer_analysis['customer_tier'].value_counts())\n",
    "\n",
    "print(\"\\n=== 练习题 ===\")\n",
    "print(\"基于上面的电商数据，尝试完成以下分析：\")\n",
    "print(\"1. 找出每个产品类别中评分最高的订单\")\n",
    "print(\"2. 计算每月的收入增长率\")\n",
    "print(\"3. 识别可能流失的客户（最近30天无订单）\")\n",
    "print(\"4. 分析不同评分等级的订单价值分布\")\n",
    "print(\"5. 计算各产品类别的利润率（假设成本为订单价值的60%）\")\n",
    "\n",
    "# 提供部分解答示例\n",
    "print(\"\\n解答示例1 - 每个产品类别中评分最高的订单:\")\n",
    "best_orders = (ecommerce_data\n",
    "              .loc[ecommerce_data.groupby('product_category')['customer_rating'].idxmax()]\n",
    "              [['product_category', 'order_id', 'customer_rating', 'order_value']])\n",
    "print(best_orders)\n",
    "\n",
    "print(\"\\n本节总结:\")\n",
    "print(\"- 掌握了pandas的核心功能：数据结构、操作、分组、合并、时间序列\")\n",
    "print(\"- 学会了数据清洗、预处理和质量控制\")\n",
    "print(\"- 了解了透视表、交叉表等数据分析工具\")\n",
    "print(\"- 掌握了性能优化和最佳实践\")\n",
    "print(\"- 通过实际案例练习了综合数据分析流程\")\n",
    "print(\"\\n下一步：学习matplotlib进行高级数据可视化！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af7908b",
   "metadata": {},
   "source": [
    "## 11. 总结与进阶方向\n",
    "\n",
    "### 本节学习内容回顾\n",
    "\n",
    "✅ **数据结构基础**: Series和DataFrame的创建、属性和基本操作  \n",
    "✅ **索引与选择**: 各种索引方法、条件筛选、布尔索引  \n",
    "✅ **数据清洗**: 处理缺失值、重复值、数据类型转换、异常值检测  \n",
    "✅ **分组与聚合**: GroupBy操作、自定义聚合函数、数据变换  \n",
    "✅ **数据合并**: merge、join、concat的不同用法和场景  \n",
    "✅ **时间序列**: 日期时间处理、重采样、滑动窗口分析  \n",
    "✅ **透视表**: pivot_table、交叉表、数据重塑  \n",
    "✅ **数据可视化**: pandas内置绘图功能  \n",
    "✅ **性能优化**: 内存管理、向量化操作、最佳实践  \n",
    "✅ **实际应用**: 电商数据分析综合案例  \n",
    "\n",
    "### 核心技能掌握检查\n",
    "\n",
    "**基础操作** (必须掌握)\n",
    "- [ ] 创建和操作DataFrame和Series\n",
    "- [ ] 数据选择和筛选\n",
    "- [ ] 基本统计分析\n",
    "- [ ] 数据导入导出\n",
    "\n",
    "**中级技能** (重要)\n",
    "- [ ] 数据清洗和预处理\n",
    "- [ ] 分组聚合操作\n",
    "- [ ] 数据合并和连接\n",
    "- [ ] 基础可视化\n",
    "\n",
    "**高级技能** (推荐)\n",
    "- [ ] 时间序列分析\n",
    "- [ ] 透视表和数据重塑\n",
    "- [ ] 性能优化\n",
    "- [ ] 复杂数据分析流程\n",
    "\n",
    "### 实践建议\n",
    "\n",
    "1. **多做项目**: 用真实数据集练习，如Kaggle数据集\n",
    "2. **建立习惯**: 始终进行数据质量检查和探索性分析\n",
    "3. **性能意识**: 处理大数据时考虑内存和计算效率\n",
    "4. **文档化**: 为复杂的数据处理流程写注释和文档\n",
    "\n",
    "### 常见错误和注意事项\n",
    "\n",
    "⚠️ **避免的错误**:\n",
    "- 忘记检查数据类型和缺失值\n",
    "- 过度使用循环而不用向量化操作\n",
    "- 不备份原始数据就进行修改\n",
    "- 忽略索引对齐问题\n",
    "\n",
    "✅ **推荐做法**:\n",
    "- 数据分析前先做.info()和.describe()\n",
    "- 使用方法链提高代码可读性\n",
    "- 适当使用category类型节省内存\n",
    "- 为重要的中间结果创建检查点\n",
    "\n",
    "### 下一步学习路径\n",
    "\n",
    "**立即可学**:\n",
    "- **Matplotlib** (`04_matplotlib.ipynb`): 深入学习数据可视化\n",
    "- **NumPy高级特性**: 结合numpy进行更高效的数值计算\n",
    "\n",
    "**后续深入**:\n",
    "- **机器学习**: 使用pandas为scikit-learn准备数据\n",
    "- **大数据工具**: Dask、Vaex等处理超大数据集\n",
    "- **数据库**: 学习SQL与pandas的结合使用\n",
    "\n",
    "### 推荐资源\n",
    "\n",
    "📚 **官方文档和教程**:\n",
    "- [Pandas官方文档](https://pandas.pydata.org/docs/)\n",
    "- [10 Minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "\n",
    "📊 **实践平台**:\n",
    "- [Kaggle Learn - Pandas](https://www.kaggle.com/learn/pandas)\n",
    "- [DataCamp - Pandas课程](https://www.datacamp.com/courses/data-manipulation-with-python)\n",
    "\n",
    "🎯 **练习数据集**:\n",
    "- Titanic数据集 (Kaggle)\n",
    "- 股票价格数据\n",
    "- 天气数据\n",
    "- 电商销售数据\n",
    "\n",
    "### 进阶主题\n",
    "\n",
    "当你熟练掌握基础pandas后，可以探索：\n",
    "\n",
    "1. **Pandas扩展**: \n",
    "   - pandas-profiling (自动数据分析报告)\n",
    "   - plotly.express (交互式可视化)\n",
    "   - seaborn (统计可视化)\n",
    "\n",
    "2. **大数据处理**:\n",
    "   - Dask (并行计算)\n",
    "   - Vaex (内存外计算)\n",
    "   - Apache Arrow (列式存储)\n",
    "\n",
    "3. **专业领域应用**:\n",
    "   - 金融数据分析 (pandas-ta, yfinance)\n",
    "   - 时间序列分析 (statsmodels, prophet)\n",
    "   - 地理数据 (geopandas)\n",
    "\n",
    "现在你已经具备了强大的数据处理能力，可以开始学习数据可视化和机器学习了！"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
