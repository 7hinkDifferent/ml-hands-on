{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85849f6",
   "metadata": {},
   "source": [
    "# æœåŠ¡å™¨ä½¿ç”¨å’Œå·¥ä½œæµ\n",
    "\n",
    "æœ¬æ•™ç¨‹ä»‹ç»å¦‚ä½•åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œæœºå™¨å­¦ä¹ ä»£ç ï¼ŒåŒ…æ‹¬ç§æœ‰é›†ç¾¤å’Œä½¿ç”¨SLURMçš„å…¬å…±é›†ç¾¤ã€‚\n",
    "\n",
    "## å†…å®¹æ¦‚è§ˆ\n",
    "1. æœåŠ¡å™¨è¿æ¥å’ŒåŸºæœ¬æ“ä½œ\n",
    "2. æ–‡ä»¶ä¼ è¾“ï¼ˆä¸Šä¼ /ä¸‹è½½ï¼‰\n",
    "3. ç¯å¢ƒé…ç½®å’ŒåŒ…ç®¡ç†\n",
    "4. ä»»åŠ¡æäº¤å’Œç›‘æ§\n",
    "5. SLURMä½œä¸šè°ƒåº¦ç³»ç»Ÿ\n",
    "6. æœ€ä½³å®è·µå’Œå¸¸è§é—®é¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2536c03",
   "metadata": {},
   "source": [
    "## 1. æœåŠ¡å™¨è¿æ¥\n",
    "\n",
    "### SSHè¿æ¥\n",
    "```bash\n",
    "# åŸºæœ¬è¿æ¥\n",
    "ssh username@server_address\n",
    "\n",
    "# æŒ‡å®šç«¯å£\n",
    "ssh -p 2222 username@server_address\n",
    "\n",
    "# ä½¿ç”¨å¯†é’¥è¿æ¥\n",
    "ssh -i ~/.ssh/private_key username@server_address\n",
    "\n",
    "# ä¿æŒè¿æ¥æ´»è·ƒ\n",
    "ssh -o ServerAliveInterval=60 username@server_address\n",
    "```\n",
    "\n",
    "### é…ç½®SSHå…å¯†ç™»å½•\n",
    "```bash\n",
    "# 1. ç”ŸæˆSSHå¯†é’¥å¯¹\n",
    "ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n",
    "\n",
    "# 2. å¤åˆ¶å…¬é’¥åˆ°æœåŠ¡å™¨\n",
    "ssh-copy-id username@server_address\n",
    "\n",
    "# 3. æˆ–æ‰‹åŠ¨æ·»åŠ \n",
    "cat ~/.ssh/id_rsa.pub | ssh username@server_address \"mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56d8a7",
   "metadata": {},
   "source": [
    "## 2. æ–‡ä»¶ä¼ è¾“\n",
    "\n",
    "### SCPå‘½ä»¤\n",
    "```bash\n",
    "# ä¸Šä¼ æ–‡ä»¶\n",
    "scp local_file.py username@server:/remote/path/\n",
    "\n",
    "# ä¸Šä¼ æ–‡ä»¶å¤¹\n",
    "scp -r local_folder/ username@server:/remote/path/\n",
    "\n",
    "# ä¸‹è½½æ–‡ä»¶\n",
    "scp username@server:/remote/file.py ./local_path/\n",
    "\n",
    "# ä¸‹è½½æ–‡ä»¶å¤¹\n",
    "scp -r username@server:/remote/folder/ ./local_path/\n",
    "```\n",
    "\n",
    "### RsyncåŒæ­¥\n",
    "```bash\n",
    "# å¢é‡åŒæ­¥ï¼ˆæ¨èï¼‰\n",
    "rsync -avz --progress local_folder/ username@server:/remote/path/\n",
    "\n",
    "# æ’é™¤ç‰¹å®šæ–‡ä»¶\n",
    "rsync -avz --exclude='*.log' --exclude='__pycache__' local_folder/ username@server:/remote/path/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœåŠ¡å™¨ç¯å¢ƒæ£€æŸ¥è„šæœ¬\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def check_server_environment():\n",
    "    \"\"\"æ£€æŸ¥æœåŠ¡å™¨ç¯å¢ƒä¿¡æ¯\"\"\"\n",
    "    print(\"=== æœåŠ¡å™¨ç¯å¢ƒä¿¡æ¯ ===\")\n",
    "    \n",
    "    # ç³»ç»Ÿä¿¡æ¯\n",
    "    print(f\"æ“ä½œç³»ç»Ÿ: {os.uname().sysname} {os.uname().release}\")\n",
    "    print(f\"ä¸»æœºå: {os.uname().nodename}\")\n",
    "    print(f\"Pythonç‰ˆæœ¬: {sys.version}\")\n",
    "    \n",
    "    # ç¡¬ä»¶ä¿¡æ¯\n",
    "    print(f\"CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}\")\n",
    "    print(f\"å†…å­˜æ€»é‡: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "    print(f\"å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "    \n",
    "    # GPUä¿¡æ¯\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.used', '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"GPUä¿¡æ¯:\")\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                print(f\"  {line}\")\n",
    "        else:\n",
    "            print(\"æœªæ£€æµ‹åˆ°GPUæˆ–nvidia-smiä¸å¯ç”¨\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smiå‘½ä»¤æœªæ‰¾åˆ°\")\n",
    "    \n",
    "    # ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "    disk_usage = psutil.disk_usage('/')\n",
    "    print(f\"ç£ç›˜ä½¿ç”¨: {disk_usage.used / (1024**3):.1f} GB / {disk_usage.total / (1024**3):.1f} GB\")\n",
    "    \n",
    "    # ç¯å¢ƒå˜é‡\n",
    "    important_vars = ['CUDA_VISIBLE_DEVICES', 'PATH', 'PYTHONPATH']\n",
    "    print(\"\\né‡è¦ç¯å¢ƒå˜é‡:\")\n",
    "    for var in important_vars:\n",
    "        value = os.environ.get(var, 'æœªè®¾ç½®')\n",
    "        print(f\"  {var}: {value[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
    "\n",
    "# è¿è¡Œæ£€æŸ¥\n",
    "check_server_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50618a",
   "metadata": {},
   "source": [
    "## 3. SSHè¿æ¥ç®¡ç†å’Œé…ç½®\n",
    "\n",
    "### 3.1 SSHé…ç½®æ–‡ä»¶\n",
    "\n",
    "åˆ›å»º `~/.ssh/config` æ–‡ä»¶æ¥ç®€åŒ–è¿æ¥ç®¡ç†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "def create_ssh_config():\n",
    "    \"\"\"åˆ›å»ºSSHé…ç½®æ–‡ä»¶ç¤ºä¾‹\"\"\"\n",
    "    \n",
    "    ssh_config_content = \"\"\"\n",
    "# ~/.ssh/config ç¤ºä¾‹æ–‡ä»¶\n",
    "\n",
    "# ç§æœ‰é›†ç¾¤æœåŠ¡å™¨\n",
    "Host gpu-server1\n",
    "    HostName 192.168.1.100\n",
    "    User your_username\n",
    "    Port 22\n",
    "    IdentityFile ~/.ssh/id_rsa\n",
    "    ServerAliveInterval 60\n",
    "    ServerAliveCountMax 3\n",
    "    \n",
    "Host gpu-server2\n",
    "    HostName gpu2.university.edu\n",
    "    User research_account\n",
    "    Port 2222\n",
    "    IdentityFile ~/.ssh/gpu_server_key\n",
    "    ServerAliveInterval 60\n",
    "    \n",
    "# å…¬å…±é›†ç¾¤ï¼ˆSLURMï¼‰\n",
    "Host hpc-cluster\n",
    "    HostName login.hpc.university.edu\n",
    "    User student_id\n",
    "    Port 22\n",
    "    IdentityFile ~/.ssh/hpc_key\n",
    "    ServerAliveInterval 120\n",
    "    \n",
    "# è·³æ¿æœºé…ç½®\n",
    "Host internal-server\n",
    "    HostName 10.0.0.50\n",
    "    User admin\n",
    "    ProxyJump gateway-server\n",
    "    \n",
    "Host gateway-server\n",
    "    HostName gateway.company.com\n",
    "    User gateway_user\n",
    "    Port 2222\n",
    "\n",
    "# é€šç”¨è®¾ç½®\n",
    "Host *\n",
    "    UseKeychain yes\n",
    "    AddKeysToAgent yes\n",
    "    Compression yes\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"SSHé…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼š\")\n",
    "    print(ssh_config_content)\n",
    "    \n",
    "    print(\"\\nğŸ”§ ä½¿ç”¨æ–¹æ³•ï¼š\")\n",
    "    print(\"1. å¤åˆ¶ä¸Šè¿°å†…å®¹åˆ° ~/.ssh/config\")\n",
    "    print(\"2. ä¿®æ”¹ç›¸åº”çš„ä¸»æœºåã€ç”¨æˆ·åå’Œå¯†é’¥è·¯å¾„\")\n",
    "    print(\"3. ç„¶åå°±å¯ä»¥ç›´æ¥ä½¿ç”¨: ssh gpu-server1\")\n",
    "\n",
    "def test_ssh_connection(host_alias):\n",
    "    \"\"\"æµ‹è¯•SSHè¿æ¥\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ”„ æµ‹è¯•è¿æ¥åˆ° {host_alias}...\")\n",
    "        \n",
    "        # æµ‹è¯•è¿æ¥ï¼ˆä¸æ‰§è¡Œå‘½ä»¤ï¼Œåªæµ‹è¯•è¿é€šæ€§ï¼‰\n",
    "        result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=10', '-o', 'BatchMode=yes', \n",
    "             host_alias, 'echo \"Connection successful\"'],\n",
    "            capture_output=True, text=True, timeout=15\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… æˆåŠŸè¿æ¥åˆ° {host_alias}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ è¿æ¥å¤±è´¥: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"â±ï¸ è¿æ¥è¶…æ—¶: {host_alias}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¿æ¥é”™è¯¯: {e}\")\n",
    "        return False\n",
    "\n",
    "def generate_ssh_key():\n",
    "    \"\"\"ç”ŸæˆSSHå¯†é’¥å¯¹\"\"\"\n",
    "    print(\"ğŸ”‘ SSHå¯†é’¥ç”ŸæˆæŒ‡å—ï¼š\")\n",
    "    \n",
    "    commands = [\n",
    "        \"# 1. ç”ŸæˆRSAå¯†é’¥å¯¹ï¼ˆæ¨è4096ä½ï¼‰\",\n",
    "        \"ssh-keygen -t rsa -b 4096 -C 'your_email@example.com'\",\n",
    "        \"\",\n",
    "        \"# 2. ç”ŸæˆED25519å¯†é’¥å¯¹ï¼ˆæ›´å®‰å…¨ï¼Œæ¨èï¼‰\",\n",
    "        \"ssh-keygen -t ed25519 -C 'your_email@example.com'\",\n",
    "        \"\",\n",
    "        \"# 3. ä¸ºç‰¹å®šæœåŠ¡å™¨ç”Ÿæˆä¸“ç”¨å¯†é’¥\",\n",
    "        \"ssh-keygen -t rsa -b 4096 -f ~/.ssh/gpu_server_key -C 'gpu_server_access'\",\n",
    "        \"\",\n",
    "        \"# 4. å¤åˆ¶å…¬é’¥åˆ°æœåŠ¡å™¨\",\n",
    "        \"ssh-copy-id -i ~/.ssh/id_rsa.pub username@server_address\",\n",
    "        \"\",\n",
    "        \"# 5. æ‰‹åŠ¨å¤åˆ¶å…¬é’¥ï¼ˆå¦‚æœssh-copy-idä¸å¯ç”¨ï¼‰\",\n",
    "        \"cat ~/.ssh/id_rsa.pub | ssh username@server 'mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys'\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        print(cmd)\n",
    "\n",
    "# è¿è¡Œç¤ºä¾‹\n",
    "create_ssh_config()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "generate_ssh_key()\n",
    "\n",
    "# æ³¨æ„ï¼šå®é™…æµ‹è¯•è¿æ¥éœ€è¦çœŸå®çš„æœåŠ¡å™¨é…ç½®\n",
    "# test_ssh_connection(\"gpu-server1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d307",
   "metadata": {},
   "source": [
    "## 4. é«˜æ•ˆæ–‡ä»¶ä¼ è¾“\n",
    "\n",
    "### 4.1 æ–‡ä»¶ä¼ è¾“å·¥å…·å¯¹æ¯”\n",
    "\n",
    "| å·¥å…· | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ | å‘½ä»¤ç¤ºä¾‹ |\n",
    "|------|------|----------|----------|\n",
    "| `scp` | ç®€å•ç›´æ¥ | å°æ–‡ä»¶ï¼Œä¸€æ¬¡æ€§ä¼ è¾“ | `scp file.py user@server:/path/` |\n",
    "| `rsync` | å¢é‡åŒæ­¥ï¼Œæ–­ç‚¹ç»­ä¼  | å¤§æ–‡ä»¶ï¼Œé¢‘ç¹åŒæ­¥ | `rsync -avz --progress local/ user@server:/path/` |\n",
    "| `sftp` | äº¤äº’å¼æ–‡ä»¶ç®¡ç† | æ–‡ä»¶æµè§ˆå’Œç®¡ç† | `sftp user@server` |\n",
    "| `git` | ç‰ˆæœ¬æ§åˆ¶ | ä»£ç åŒæ­¥ | `git push/pull` |\n",
    "\n",
    "### 4.2 æ–‡ä»¶ä¼ è¾“æœ€ä½³å®è·µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "class FileTransferManager:\n",
    "    \"\"\"æ–‡ä»¶ä¼ è¾“ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, server_config):\n",
    "        self.server_config = server_config\n",
    "        \n",
    "    def generate_rsync_command(self, local_path, remote_path, \n",
    "                              exclude_patterns=None, dry_run=False):\n",
    "        \"\"\"ç”Ÿæˆrsyncå‘½ä»¤\"\"\"\n",
    "        if exclude_patterns is None:\n",
    "            exclude_patterns = [\n",
    "                '*.pyc', '__pycache__/', '*.log', '.git/', \n",
    "                '.vscode/', '.idea/', '*.DS_Store', '*.tmp'\n",
    "            ]\n",
    "        \n",
    "        # åŸºç¡€å‘½ä»¤\n",
    "        cmd = ['rsync', '-avz', '--progress']\n",
    "        \n",
    "        # æ·»åŠ æ’é™¤æ¨¡å¼\n",
    "        for pattern in exclude_patterns:\n",
    "            cmd.extend(['--exclude', pattern])\n",
    "        \n",
    "        # å¹²è¿è¡Œæ¨¡å¼\n",
    "        if dry_run:\n",
    "            cmd.append('--dry-run')\n",
    "        \n",
    "        # æ·»åŠ è·¯å¾„\n",
    "        cmd.append(local_path)\n",
    "        cmd.append(f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}\")\n",
    "        \n",
    "        return cmd\n",
    "    \n",
    "    def upload_project(self, project_path, remote_base_path, dry_run=True):\n",
    "        \"\"\"ä¸Šä¼ é¡¹ç›®åˆ°æœåŠ¡å™¨\"\"\"\n",
    "        print(f\"ğŸ“¤ å‡†å¤‡ä¸Šä¼ é¡¹ç›®: {project_path}\")\n",
    "        print(f\"ğŸ¯ ç›®æ ‡è·¯å¾„: {remote_base_path}\")\n",
    "        \n",
    "        # ç”Ÿæˆå‘½ä»¤\n",
    "        cmd = self.generate_rsync_command(\n",
    "            f\"{project_path}/\", remote_base_path, dry_run=dry_run\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ”§ æ‰§è¡Œå‘½ä»¤:\")\n",
    "        print(\" \".join(cmd))\n",
    "        \n",
    "        if dry_run:\n",
    "            print(\"\\nâš ï¸  è¿™æ˜¯å¹²è¿è¡Œæ¨¡å¼ï¼Œå®é™…ä¸ä¼šä¼ è¾“æ–‡ä»¶\")\n",
    "            print(\"   ç§»é™¤ dry_run=True å‚æ•°æ¥æ‰§è¡Œå®é™…ä¼ è¾“\")\n",
    "        \n",
    "        return cmd\n",
    "    \n",
    "    def download_results(self, remote_path, local_path, patterns=None):\n",
    "        \"\"\"ä¸‹è½½ç»“æœæ–‡ä»¶\"\"\"\n",
    "        if patterns is None:\n",
    "            patterns = ['*.pth', '*.pkl', '*.json', '*.png', '*.jpg', '*.log']\n",
    "        \n",
    "        print(f\"ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶...\")\n",
    "        \n",
    "        commands = []\n",
    "        for pattern in patterns:\n",
    "            cmd = [\n",
    "                'rsync', '-avz', '--progress',\n",
    "                f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}/{pattern}\",\n",
    "                local_path\n",
    "            ]\n",
    "            commands.append(cmd)\n",
    "        \n",
    "        return commands\n",
    "    \n",
    "    def sync_code_only(self, local_path, remote_path, dry_run=True):\n",
    "        \"\"\"åªåŒæ­¥ä»£ç æ–‡ä»¶\"\"\"\n",
    "        code_patterns = ['*.py', '*.ipynb', '*.yml', '*.yaml', '*.json', '*.txt', '*.md']\n",
    "        \n",
    "        cmd = ['rsync', '-avz', '--progress']\n",
    "        \n",
    "        # åªåŒ…å«ä»£ç æ–‡ä»¶\n",
    "        for pattern in code_patterns:\n",
    "            cmd.extend(['--include', pattern])\n",
    "        \n",
    "        cmd.extend(['--include', '*/'])  # åŒ…å«ç›®å½•\n",
    "        cmd.append('--exclude=*')  # æ’é™¤å…¶ä»–æ‰€æœ‰æ–‡ä»¶\n",
    "        \n",
    "        if dry_run:\n",
    "            cmd.append('--dry-run')\n",
    "            \n",
    "        cmd.append(f\"{local_path}/\")\n",
    "        cmd.append(f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}\")\n",
    "        \n",
    "        return cmd\n",
    "\n",
    "def create_transfer_script():\n",
    "    \"\"\"åˆ›å»ºæ–‡ä»¶ä¼ è¾“è„šæœ¬\"\"\"\n",
    "    \n",
    "    script_content = '''#!/bin/bash\n",
    "# æ–‡ä»¶ä¼ è¾“è„šæœ¬ - transfer.sh\n",
    "\n",
    "# é…ç½®\n",
    "SERVER_USER=\"your_username\"\n",
    "SERVER_HOST=\"gpu-server1\"\n",
    "LOCAL_PROJECT_PATH=\"./my_ml_project\"\n",
    "REMOTE_BASE_PATH=\"/home/$SERVER_USER/projects\"\n",
    "\n",
    "# é¢œè‰²è¾“å‡º\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "NC='\\\\033[0m' # No Color\n",
    "\n",
    "echo_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }\n",
    "echo_warn() { echo -e \"${YELLOW}[WARN]${NC} $1\"; }\n",
    "echo_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }\n",
    "\n",
    "# å‡½æ•°ï¼šä¸Šä¼ é¡¹ç›®\n",
    "upload_project() {\n",
    "    echo_info \"å¼€å§‹ä¸Šä¼ é¡¹ç›®...\"\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        --exclude='*.pyc' \\\\\n",
    "        --exclude='__pycache__/' \\\\\n",
    "        --exclude='*.log' \\\\\n",
    "        --exclude='.git/' \\\\\n",
    "        --exclude='*.DS_Store' \\\\\n",
    "        --exclude='data/raw/' \\\\\n",
    "        --exclude='checkpoints/' \\\\\n",
    "        \"$LOCAL_PROJECT_PATH/\" \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)/\"\n",
    "    \n",
    "    if [ $? -eq 0 ]; then\n",
    "        echo_info \"é¡¹ç›®ä¸Šä¼ å®Œæˆ!\"\n",
    "    else\n",
    "        echo_error \"é¡¹ç›®ä¸Šä¼ å¤±è´¥!\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šä¸‹è½½ç»“æœ\n",
    "download_results() {\n",
    "    echo_info \"ä¸‹è½½ç»“æœæ–‡ä»¶...\"\n",
    "    \n",
    "    local remote_project=\"$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)\"\n",
    "    local local_results=\"./results/$(date +%Y%m%d_%H%M%S)\"\n",
    "    \n",
    "    mkdir -p \"$local_results\"\n",
    "    \n",
    "    # ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/checkpoints/\" \\\\\n",
    "        \"$local_results/checkpoints/\" 2>/dev/null || echo_warn \"æ²¡æœ‰æ‰¾åˆ°checkpointsç›®å½•\"\n",
    "    \n",
    "    # ä¸‹è½½æ—¥å¿—æ–‡ä»¶\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/logs/\" \\\\\n",
    "        \"$local_results/logs/\" 2>/dev/null || echo_warn \"æ²¡æœ‰æ‰¾åˆ°logsç›®å½•\"\n",
    "    \n",
    "    # ä¸‹è½½ç»“æœå›¾åƒ\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/*.png\" \\\\\n",
    "        \"$local_results/\" 2>/dev/null || echo_warn \"æ²¡æœ‰æ‰¾åˆ°PNGæ–‡ä»¶\"\n",
    "        \n",
    "    echo_info \"ç»“æœå·²ä¸‹è½½åˆ°: $local_results\"\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šå¿«é€ŸåŒæ­¥ä»£ç \n",
    "sync_code() {\n",
    "    echo_info \"å¿«é€ŸåŒæ­¥ä»£ç æ–‡ä»¶...\"\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        --include='*.py' \\\\\n",
    "        --include='*.ipynb' \\\\\n",
    "        --include='*.yml' \\\\\n",
    "        --include='*.yaml' \\\\\n",
    "        --include='*.json' \\\\\n",
    "        --include='*.txt' \\\\\n",
    "        --include='*.md' \\\\\n",
    "        --include='*/' \\\\\n",
    "        --exclude='*' \\\\\n",
    "        \"$LOCAL_PROJECT_PATH/\" \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)/\"\n",
    "    \n",
    "    echo_info \"ä»£ç åŒæ­¥å®Œæˆ!\"\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"upload\"|\"up\")\n",
    "        upload_project\n",
    "        ;;\n",
    "    \"download\"|\"down\")\n",
    "        download_results\n",
    "        ;;\n",
    "    \"sync\")\n",
    "        sync_code\n",
    "        ;;\n",
    "    \"all\")\n",
    "        upload_project\n",
    "        echo_info \"é¡¹ç›®ä¸Šä¼ å®Œæˆï¼Œç°åœ¨å¯ä»¥åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œè®­ç»ƒ\"\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {upload|download|sync|all}\"\n",
    "        echo \"  upload/up   - ä¸Šä¼ å®Œæ•´é¡¹ç›®\"\n",
    "        echo \"  download/down - ä¸‹è½½ç»“æœæ–‡ä»¶\"\n",
    "        echo \"  sync        - å¿«é€ŸåŒæ­¥ä»£ç \"\n",
    "        echo \"  all         - ä¸Šä¼ é¡¹ç›®\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "'''\n",
    "    \n",
    "    print(\"ğŸ“ æ–‡ä»¶ä¼ è¾“è„šæœ¬ (transfer.sh):\")\n",
    "    print(script_content)\n",
    "    \n",
    "    print(\"\\nğŸ”§ ä½¿ç”¨æ–¹æ³•:\")\n",
    "    print(\"1. ä¿å­˜ä¸Šè¿°å†…å®¹ä¸º transfer.sh\")\n",
    "    print(\"2. chmod +x transfer.sh\")\n",
    "    print(\"3. ä¿®æ”¹è„šæœ¬ä¸­çš„æœåŠ¡å™¨é…ç½®\")\n",
    "    print(\"4. ./transfer.sh upload  # ä¸Šä¼ é¡¹ç›®\")\n",
    "    print(\"5. ./transfer.sh download  # ä¸‹è½½ç»“æœ\")\n",
    "\n",
    "# ç¤ºä¾‹é…ç½®\n",
    "server_config = {\n",
    "    'user': 'your_username',\n",
    "    'host': 'gpu-server1',\n",
    "    'port': 22\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¼ è¾“ç®¡ç†å™¨\n",
    "transfer_manager = FileTransferManager(server_config)\n",
    "\n",
    "# æ¼”ç¤ºå„ç§ä¼ è¾“å‘½ä»¤\n",
    "print(\"ğŸ“‹ æ–‡ä»¶ä¼ è¾“å‘½ä»¤ç¤ºä¾‹:\\n\")\n",
    "\n",
    "# 1. ä¸Šä¼ é¡¹ç›®\n",
    "cmd = transfer_manager.upload_project(\"./my_ml_project\", \"/home/user/projects\", dry_run=True)\n",
    "print()\n",
    "\n",
    "# 2. ä¸‹è½½ç»“æœ\n",
    "cmds = transfer_manager.download_results(\"/home/user/projects/my_ml_project\", \"./results\")\n",
    "print(\"ğŸ“¥ ä¸‹è½½ç»“æœå‘½ä»¤:\")\n",
    "for i, cmd in enumerate(cmds, 1):\n",
    "    print(f\"{i}. {' '.join(cmd)}\")\n",
    "print()\n",
    "\n",
    "# 3. ä»£ç åŒæ­¥\n",
    "cmd = transfer_manager.sync_code_only(\"./my_ml_project\", \"/home/user/projects/my_ml_project\")\n",
    "print(\"ğŸ”„ ä»£ç åŒæ­¥å‘½ä»¤:\")\n",
    "print(\" \".join(cmd))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "create_transfer_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebc9ad",
   "metadata": {},
   "source": [
    "## 5. æœåŠ¡å™¨ç¯å¢ƒé…ç½®\n",
    "\n",
    "### 5.1 è™šæ‹Ÿç¯å¢ƒç®¡ç†\n",
    "\n",
    "åœ¨æœåŠ¡å™¨ä¸Šç®¡ç†Pythonç¯å¢ƒæ˜¯å…³é”®æŠ€èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å…±äº«æœåŠ¡å™¨ä¸Šï¼š\n",
    "\n",
    "### 5.2 Condaç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862792ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerEnvironmentManager:\n",
    "    \"\"\"æœåŠ¡å™¨ç¯å¢ƒç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conda_envs = []\n",
    "        self.system_info = {}\n",
    "    \n",
    "    def generate_conda_setup_script(self, env_name=\"ml_research\"):\n",
    "        \"\"\"ç”ŸæˆCondaç¯å¢ƒè®¾ç½®è„šæœ¬\"\"\"\n",
    "        \n",
    "        script = f\"\"\"\n",
    "#!/bin/bash\n",
    "# Condaç¯å¢ƒè®¾ç½®è„šæœ¬ - setup_env.sh\n",
    "\n",
    "ENV_NAME=\"{env_name}\"\n",
    "\n",
    "echo \"ğŸ åˆ›å»ºCondaç¯å¢ƒ: $ENV_NAME\"\n",
    "\n",
    "# 1. åˆ›å»ºæ–°ç¯å¢ƒ\n",
    "conda create -n $ENV_NAME python=3.9 -y\n",
    "\n",
    "# 2. æ¿€æ´»ç¯å¢ƒ\n",
    "source activate $ENV_NAME\n",
    "# æˆ–è€…ä½¿ç”¨: conda activate $ENV_NAME\n",
    "\n",
    "# 3. å®‰è£…åŸºç¡€åŒ…\n",
    "echo \"ğŸ“¦ å®‰è£…åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…...\"\n",
    "conda install numpy pandas matplotlib seaborn jupyter -y\n",
    "conda install scikit-learn -y\n",
    "\n",
    "# 4. å®‰è£…æ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "echo \"ğŸ¤– å®‰è£…PyTorch...\"\n",
    "# CPUç‰ˆæœ¬\n",
    "# conda install pytorch torchvision torchaudio cpuonly -c pytorch -y\n",
    "\n",
    "# GPUç‰ˆæœ¬ (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)\n",
    "# CUDA 11.8\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "\n",
    "# CUDA 12.1\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "\n",
    "# 5. å®‰è£…å…¶ä»–å¸¸ç”¨åŒ…\n",
    "echo \"ğŸ”§ å®‰è£…å…¶ä»–å·¥å…·åŒ…...\"\n",
    "pip install tensorboard\n",
    "pip install tqdm\n",
    "pip install wandb  # å®éªŒè·Ÿè¸ª\n",
    "pip install hydra-core  # é…ç½®ç®¡ç†\n",
    "pip install black flake8  # ä»£ç æ ¼å¼åŒ–\n",
    "\n",
    "# 6. éªŒè¯å®‰è£…\n",
    "echo \"âœ… éªŒè¯å®‰è£…...\"\n",
    "python -c \"import torch; print(f'PyTorchç‰ˆæœ¬: {{torch.__version__}}'); print(f'CUDAå¯ç”¨: {{torch.cuda.is_available()}}')\"\n",
    "\n",
    "# 7. ä¿å­˜ç¯å¢ƒé…ç½®\n",
    "conda env export > environment.yml\n",
    "echo \"ğŸ’¾ ç¯å¢ƒé…ç½®å·²ä¿å­˜åˆ° environment.yml\"\n",
    "\n",
    "echo \"ğŸ‰ ç¯å¢ƒè®¾ç½®å®Œæˆ!\"\n",
    "echo \"ğŸ“ ä½¿ç”¨æ–¹æ³•:\"\n",
    "echo \"   conda activate $ENV_NAME\"\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def generate_requirements_script(self):\n",
    "        \"\"\"ç”Ÿæˆrequirements.txtç®¡ç†è„šæœ¬\"\"\"\n",
    "        \n",
    "        script = \"\"\"\n",
    "#!/bin/bash\n",
    "# PythonåŒ…ç®¡ç†è„šæœ¬ - manage_packages.sh\n",
    "\n",
    "# å‡½æ•°ï¼šå¯¼å‡ºå½“å‰ç¯å¢ƒ\n",
    "export_env() {\n",
    "    echo \"ğŸ“‹ å¯¼å‡ºå½“å‰ç¯å¢ƒåˆ° requirements.txt...\"\n",
    "    pip freeze > requirements.txt\n",
    "    echo \"âœ… å¯¼å‡ºå®Œæˆ: requirements.txt\"\n",
    "    \n",
    "    echo \"ğŸ“‹ å¯¼å‡ºCondaç¯å¢ƒ...\"\n",
    "    conda env export > environment.yml\n",
    "    echo \"âœ… å¯¼å‡ºå®Œæˆ: environment.yml\"\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šä»requirements.txtå®‰è£…\n",
    "install_from_requirements() {\n",
    "    if [ -f \"requirements.txt\" ]; then\n",
    "        echo \"ğŸ“¦ ä» requirements.txt å®‰è£…åŒ…...\"\n",
    "        pip install -r requirements.txt\n",
    "        echo \"âœ… å®‰è£…å®Œæˆ!\"\n",
    "    else\n",
    "        echo \"âŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šä»environment.ymlåˆ›å»ºç¯å¢ƒ\n",
    "create_from_yml() {\n",
    "    if [ -f \"environment.yml\" ]; then\n",
    "        echo \"ğŸ ä» environment.yml åˆ›å»ºç¯å¢ƒ...\"\n",
    "        conda env create -f environment.yml\n",
    "        echo \"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ!\"\n",
    "    else\n",
    "        echo \"âŒ environment.yml æ–‡ä»¶ä¸å­˜åœ¨\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šæ›´æ–°ç¯å¢ƒ\n",
    "update_env() {\n",
    "    echo \"ğŸ”„ æ›´æ–°Condaç¯å¢ƒ...\"\n",
    "    conda update --all -y\n",
    "    \n",
    "    echo \"ğŸ”„ æ›´æ–°pipåŒ…...\"\n",
    "    pip list --outdated --format=json | jq -r '.[] | .name' | xargs -I {} pip install --upgrade {}\n",
    "    \n",
    "    echo \"âœ… ç¯å¢ƒæ›´æ–°å®Œæˆ!\"\n",
    "}\n",
    "\n",
    "# å‡½æ•°ï¼šæ¸…ç†ç¯å¢ƒ\n",
    "clean_env() {\n",
    "    echo \"ğŸ§¹ æ¸…ç†Condaç¼“å­˜...\"\n",
    "    conda clean --all -y\n",
    "    \n",
    "    echo \"ğŸ§¹ æ¸…ç†pipç¼“å­˜...\"\n",
    "    pip cache purge\n",
    "    \n",
    "    echo \"âœ… æ¸…ç†å®Œæˆ!\"\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"export\")\n",
    "        export_env\n",
    "        ;;\n",
    "    \"install\")\n",
    "        install_from_requirements\n",
    "        ;;\n",
    "    \"create\")\n",
    "        create_from_yml\n",
    "        ;;\n",
    "    \"update\")\n",
    "        update_env\n",
    "        ;;\n",
    "    \"clean\")\n",
    "        clean_env\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {export|install|create|update|clean}\"\n",
    "        echo \"  export  - å¯¼å‡ºå½“å‰ç¯å¢ƒ\"\n",
    "        echo \"  install - ä»requirements.txtå®‰è£…\"\n",
    "        echo \"  create  - ä»environment.ymlåˆ›å»ºç¯å¢ƒ\"\n",
    "        echo \"  update  - æ›´æ–°æ‰€æœ‰åŒ…\"\n",
    "        echo \"  clean   - æ¸…ç†ç¼“å­˜\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def check_gpu_environment(self):\n",
    "        \"\"\"æ£€æŸ¥GPUç¯å¢ƒé…ç½®\"\"\"\n",
    "        \n",
    "        check_commands = {\n",
    "            \"NVIDIAé©±åŠ¨\": \"nvidia-smi\",\n",
    "            \"CUDAç‰ˆæœ¬\": \"nvcc --version\",\n",
    "            \"PyTorch GPU\": \"python -c 'import torch; print(torch.cuda.is_available())'\",\n",
    "            \"GPUæ•°é‡\": \"python -c 'import torch; print(torch.cuda.device_count())'\",\n",
    "            \"GPUåç§°\": \"python -c 'import torch; print([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])'\"\n",
    "        }\n",
    "        \n",
    "        print(\"ğŸ” GPUç¯å¢ƒæ£€æŸ¥å‘½ä»¤:\")\n",
    "        for desc, cmd in check_commands.items():\n",
    "            print(f\"  {desc}: {cmd}\")\n",
    "        \n",
    "        return check_commands\n",
    "    \n",
    "    def generate_bashrc_config(self):\n",
    "        \"\"\"ç”Ÿæˆ.bashrcé…ç½®\"\"\"\n",
    "        \n",
    "        bashrc_content = \"\"\"\n",
    "# æ·»åŠ åˆ° ~/.bashrc çš„å†…å®¹\n",
    "\n",
    "# Condaé…ç½®\n",
    "export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "# æˆ–è€…å¦‚æœä½¿ç”¨Anaconda\n",
    "# export PATH=\"$HOME/anaconda3/bin:$PATH\"\n",
    "\n",
    "# CUDAé…ç½® (æ ¹æ®å®é™…CUDAå®‰è£…è·¯å¾„ä¿®æ”¹)\n",
    "export CUDA_HOME=/usr/local/cuda\n",
    "export PATH=$CUDA_HOME/bin:$PATH\n",
    "export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n",
    "\n",
    "# Pythoné…ç½®\n",
    "export PYTHONPATH=$HOME/projects:$PYTHONPATH\n",
    "\n",
    "# åˆ«åè®¾ç½®\n",
    "alias ll='ls -alF'\n",
    "alias la='ls -A'\n",
    "alias l='ls -CF'\n",
    "alias grep='grep --color=auto'\n",
    "\n",
    "# GPUç›¸å…³åˆ«å\n",
    "alias gpustat='nvidia-smi'\n",
    "alias gpuwatch='watch -n 1 nvidia-smi'\n",
    "alias gpufree='nvidia-smi --query-gpu=index,name,memory.free --format=csv'\n",
    "\n",
    "# Condaç›¸å…³åˆ«å\n",
    "alias ca='conda activate'\n",
    "alias cda='conda deactivate'\n",
    "alias cenv='conda env list'\n",
    "\n",
    "# é¡¹ç›®ç›¸å…³\n",
    "alias projects='cd $HOME/projects'\n",
    "alias logs='cd $HOME/projects && find . -name \"*.log\" -mtime -1'\n",
    "\n",
    "# æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯\n",
    "echo \"ğŸ–¥ï¸  æœåŠ¡å™¨: $(hostname)\"\n",
    "echo \"ğŸ Python: $(python --version 2>&1 | head -1)\"\n",
    "if command -v nvidia-smi &> /dev/null; then\n",
    "    echo \"ğŸ® GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)\"\n",
    "fi\n",
    "echo \"ğŸ“ å½“å‰ç›®å½•: $(pwd)\"\n",
    "\n",
    "# è‡ªåŠ¨æ¿€æ´»é»˜è®¤ç¯å¢ƒ (å¯é€‰)\n",
    "# conda activate ml_research\n",
    "\"\"\"\n",
    "        \n",
    "        return bashrc_content\n",
    "\n",
    "# åˆ›å»ºç¯å¢ƒç®¡ç†å™¨\n",
    "env_manager = ServerEnvironmentManager()\n",
    "\n",
    "print(\"ğŸ Condaç¯å¢ƒè®¾ç½®è„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "conda_script = env_manager.generate_conda_setup_script(\"ml_research\")\n",
    "print(conda_script)\n",
    "\n",
    "print(\"\\nğŸ“¦ åŒ…ç®¡ç†è„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "packages_script = env_manager.generate_requirements_script()\n",
    "print(packages_script)\n",
    "\n",
    "print(\"\\nğŸ” GPUç¯å¢ƒæ£€æŸ¥:\")\n",
    "print(\"=\"*60)\n",
    "gpu_checks = env_manager.check_gpu_environment()\n",
    "\n",
    "print(\"\\nâš™ï¸ .bashrcé…ç½®:\")\n",
    "print(\"=\"*60)\n",
    "bashrc_config = env_manager.generate_bashrc_config()\n",
    "print(bashrc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2498c0",
   "metadata": {},
   "source": [
    "## 6. ä»»åŠ¡æäº¤å’Œç›‘æ§\n",
    "\n",
    "### 6.1 åå°ä»»åŠ¡ç®¡ç†\n",
    "\n",
    "åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œé•¿æ—¶é—´ä»»åŠ¡æ—¶ï¼Œéœ€è¦ç¡®ä¿ä»»åŠ¡ä¸ä¼šå› ä¸ºSSHè¿æ¥æ–­å¼€è€Œä¸­æ–­ï¼š\n",
    "\n",
    "### 6.2 å¸¸ç”¨ä»»åŠ¡ç®¡ç†å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import signal\n",
    "\n",
    "class TaskManager:\n",
    "    \"\"\"æœåŠ¡å™¨ä»»åŠ¡ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_tasks = {}\n",
    "    \n",
    "    def generate_task_scripts(self):\n",
    "        \"\"\"ç”Ÿæˆå„ç§ä»»åŠ¡ç®¡ç†è„šæœ¬\"\"\"\n",
    "        \n",
    "        scripts = {}\n",
    "        \n",
    "        # 1. Screenä»»åŠ¡è„šæœ¬\n",
    "        scripts['screen_training'] = \"\"\"#!/bin/bash\n",
    "# Screenè®­ç»ƒè„šæœ¬ - train_with_screen.sh\n",
    "\n",
    "PROJECT_NAME=\"mnist_training\"\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "\n",
    "# åˆ›å»ºscreenä¼šè¯å¹¶è¿è¡Œè®­ç»ƒ\n",
    "screen -dmS $PROJECT_NAME bash -c \"\n",
    "    echo 'ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡...'\n",
    "    echo 'ğŸ“… å¼€å§‹æ—¶é—´: $(date)'\n",
    "    \n",
    "    # æ¿€æ´»ç¯å¢ƒ\n",
    "    conda activate ml_research\n",
    "    \n",
    "    # è®¾ç½®GPU\n",
    "    export CUDA_VISIBLE_DEVICES=0\n",
    "    \n",
    "    # è¿è¡Œè®­ç»ƒ\n",
    "    python $SCRIPT_PATH --epochs 100 --batch-size 64 > training.log 2>&1\n",
    "    \n",
    "    echo 'âœ… è®­ç»ƒå®Œæˆ: $(date)'\n",
    "    echo 'æŒ‰ä»»æ„é”®é€€å‡º...'\n",
    "    read\n",
    "\"\n",
    "\n",
    "echo \"âœ… Screenä¼šè¯ '$PROJECT_NAME' å·²å¯åŠ¨\"\n",
    "echo \"ğŸ” æŸ¥çœ‹çŠ¶æ€: screen -list\"\n",
    "echo \"ğŸ”— è¿æ¥ä¼šè¯: screen -r $PROJECT_NAME\"\n",
    "echo \"ğŸ“‹ åˆ†ç¦»ä¼šè¯: Ctrl+A, D\"\n",
    "\"\"\"\n",
    "\n",
    "        # 2. tmuxä»»åŠ¡è„šæœ¬\n",
    "        scripts['tmux_training'] = \"\"\"#!/bin/bash\n",
    "# tmuxè®­ç»ƒè„šæœ¬ - train_with_tmux.sh\n",
    "\n",
    "SESSION_NAME=\"ml_training\"\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "\n",
    "# åˆ›å»ºtmuxä¼šè¯\n",
    "tmux new-session -d -s $SESSION_NAME\n",
    "\n",
    "# åœ¨ä¼šè¯ä¸­è¿è¡Œå‘½ä»¤\n",
    "tmux send-keys -t $SESSION_NAME \"conda activate ml_research\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"export CUDA_VISIBLE_DEVICES=0\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"echo 'ğŸš€ å¼€å§‹è®­ç»ƒ: $(date)'\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"python $SCRIPT_PATH --config config.yaml\" C-m\n",
    "\n",
    "echo \"âœ… tmuxä¼šè¯ '$SESSION_NAME' å·²å¯åŠ¨\"\n",
    "echo \"ğŸ” æŸ¥çœ‹ä¼šè¯: tmux ls\"\n",
    "echo \"ğŸ”— è¿æ¥ä¼šè¯: tmux attach -t $SESSION_NAME\"\n",
    "echo \"ğŸ“‹ åˆ†ç¦»ä¼šè¯: Ctrl+B, D\"\n",
    "\"\"\"\n",
    "\n",
    "        # 3. nohupä»»åŠ¡è„šæœ¬\n",
    "        scripts['nohup_training'] = \"\"\"#!/bin/bash\n",
    "# nohupè®­ç»ƒè„šæœ¬ - train_with_nohup.sh\n",
    "\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "LOG_FILE=\"training_$(date +%Y%m%d_%H%M%S).log\"\n",
    "\n",
    "echo \"ğŸš€ ä½¿ç”¨nohupå¯åŠ¨è®­ç»ƒä»»åŠ¡...\"\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒå¹¶è¿è¡Œ\n",
    "nohup bash -c \"\n",
    "    source activate ml_research\n",
    "    export CUDA_VISIBLE_DEVICES=0\n",
    "    python $SCRIPT_PATH --epochs 100 --batch-size 64\n",
    "\" > $LOG_FILE 2>&1 &\n",
    "\n",
    "PID=$!\n",
    "echo \"âœ… ä»»åŠ¡å·²å¯åŠ¨, PID: $PID\"\n",
    "echo \"ğŸ“„ æ—¥å¿—æ–‡ä»¶: $LOG_FILE\"\n",
    "echo \"ğŸ” ç›‘æ§æ—¥å¿—: tail -f $LOG_FILE\"\n",
    "echo \"â¹ï¸  åœæ­¢ä»»åŠ¡: kill $PID\"\n",
    "\n",
    "# ä¿å­˜PIDåˆ°æ–‡ä»¶\n",
    "echo $PID > training.pid\n",
    "\"\"\"\n",
    "\n",
    "        # 4. ä»»åŠ¡ç›‘æ§è„šæœ¬\n",
    "        scripts['monitor_tasks'] = \"\"\"#!/bin/bash\n",
    "# ä»»åŠ¡ç›‘æ§è„šæœ¬ - monitor.sh\n",
    "\n",
    "# é¢œè‰²å®šä¹‰\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "echo_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }\n",
    "echo_warn() { echo -e \"${YELLOW}[WARN]${NC} $1\"; }\n",
    "echo_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }\n",
    "\n",
    "# æ˜¾ç¤ºç³»ç»Ÿèµ„æº\n",
    "show_resources() {\n",
    "    echo_info \"ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ:\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    # CPUå’Œå†…å­˜\n",
    "    echo \"ğŸ’» CPUå’Œå†…å­˜:\"\n",
    "    top -bn1 | grep \"Cpu(s)\" | sed \"s/.*, *\\\\([0-9.]*\\\\)%* id.*/\\\\1/\" | awk '{print \"CPUä½¿ç”¨ç‡: \" 100-$1\"%\"}'\n",
    "    free -h | awk '/Mem:/ {print \"å†…å­˜ä½¿ç”¨: \" $3 \"/\" $2 \" (\" $3/$2*100 \"%)\"}'\n",
    "    \n",
    "    # GPU\n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"ğŸ® GPUçŠ¶æ€:\"\n",
    "        nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits | \\\\\n",
    "        awk -F, '{printf \"GPU%s: %s, å†…å­˜: %sMB/%sMB (%.1f%%), åˆ©ç”¨ç‡: %s%%\\\\n\", $1, $2, $3, $4, $3/$4*100, $5}'\n",
    "    fi\n",
    "    \n",
    "    # ç£ç›˜\n",
    "    echo \"ğŸ’¾ ç£ç›˜ä½¿ç”¨:\"\n",
    "    df -h | grep -E '^/dev/' | awk '{print $6 \": \" $3 \"/\" $2 \" (\" $5 \")\"}'\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºè®­ç»ƒè¿›ç¨‹\n",
    "show_training_processes() {\n",
    "    echo_info \"Pythonè®­ç»ƒè¿›ç¨‹:\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    ps aux | grep python | grep -v grep | while read line; do\n",
    "        echo \"$line\"\n",
    "    done\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºScreenä¼šè¯\n",
    "show_screen_sessions() {\n",
    "    echo_info \"Screenä¼šè¯:\"\n",
    "    echo \"=========================\"\n",
    "    screen -list 2>/dev/null || echo \"æ²¡æœ‰æ´»è·ƒçš„Screenä¼šè¯\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºtmuxä¼šè¯\n",
    "show_tmux_sessions() {\n",
    "    echo_info \"tmuxä¼šè¯:\"\n",
    "    echo \"=========================\"\n",
    "    tmux ls 2>/dev/null || echo \"æ²¡æœ‰æ´»è·ƒçš„tmuxä¼šè¯\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—\n",
    "show_recent_logs() {\n",
    "    echo_info \"æœ€è¿‘çš„è®­ç»ƒæ—¥å¿— (æœ€å10è¡Œ):\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    find . -name \"*.log\" -mtime -1 -type f | head -5 | while read logfile; do\n",
    "        echo \"ğŸ“„ $logfile:\"\n",
    "        tail -3 \"$logfile\" 2>/dev/null | sed 's/^/  /'\n",
    "        echo \"\"\n",
    "    done\n",
    "}\n",
    "\n",
    "# ä¸»ç›‘æ§å¾ªç¯\n",
    "monitor_loop() {\n",
    "    while true; do\n",
    "        clear\n",
    "        echo \"ğŸ–¥ï¸  æœåŠ¡å™¨ç›‘æ§ - $(date)\"\n",
    "        echo \"==============================================\"\n",
    "        \n",
    "        show_resources\n",
    "        show_training_processes\n",
    "        show_screen_sessions\n",
    "        show_tmux_sessions\n",
    "        show_recent_logs\n",
    "        \n",
    "        echo \"ğŸ”„ æ¯30ç§’è‡ªåŠ¨åˆ·æ–°... (Ctrl+C é€€å‡º)\"\n",
    "        sleep 30\n",
    "    done\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"resources\"|\"res\")\n",
    "        show_resources\n",
    "        ;;\n",
    "    \"processes\"|\"proc\")\n",
    "        show_training_processes\n",
    "        ;;\n",
    "    \"sessions\"|\"sess\")\n",
    "        show_screen_sessions\n",
    "        show_tmux_sessions\n",
    "        ;;\n",
    "    \"logs\")\n",
    "        show_recent_logs\n",
    "        ;;\n",
    "    \"monitor\"|\"\")\n",
    "        monitor_loop\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {resources|processes|sessions|logs|monitor}\"\n",
    "        echo \"  resources  - æ˜¾ç¤ºç³»ç»Ÿèµ„æº\"\n",
    "        echo \"  processes  - æ˜¾ç¤ºè®­ç»ƒè¿›ç¨‹\"\n",
    "        echo \"  sessions   - æ˜¾ç¤ºscreen/tmuxä¼šè¯\"\n",
    "        echo \"  logs       - æ˜¾ç¤ºæœ€è¿‘æ—¥å¿—\"\n",
    "        echo \"  monitor    - è¿ç»­ç›‘æ§ (é»˜è®¤)\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "\n",
    "        return scripts\n",
    "    \n",
    "    def generate_gpu_management_script(self):\n",
    "        \"\"\"ç”ŸæˆGPUç®¡ç†è„šæœ¬\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# GPUç®¡ç†è„šæœ¬ - gpu_manager.sh\n",
    "\n",
    "# é¢œè‰²å®šä¹‰\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "# æ˜¾ç¤ºGPUçŠ¶æ€\n",
    "show_gpu_status() {\n",
    "    echo -e \"${GREEN}ğŸ® GPUçŠ¶æ€æ€»è§ˆ${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    if ! command -v nvidia-smi &> /dev/null; then\n",
    "        echo -e \"${RED}âŒ nvidia-smi å‘½ä»¤ä¸å¯ç”¨${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # åŸºæœ¬GPUä¿¡æ¯\n",
    "    nvidia-smi --query-gpu=index,name,driver_version,memory.total --format=csv\n",
    "    echo \"\"\n",
    "    \n",
    "    # è¯¦ç»†çŠ¶æ€\n",
    "    echo -e \"${BLUE}ğŸ“Š è¯¦ç»†çŠ¶æ€:${NC}\"\n",
    "    nvidia-smi\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºGPUè¿›ç¨‹\n",
    "show_gpu_processes() {\n",
    "    echo -e \"${GREEN}ğŸ” GPUè¿›ç¨‹è¯¦æƒ…${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    nvidia-smi pmon -i 0 -c 1 2>/dev/null || {\n",
    "        echo \"ä½¿ç”¨nvidia-smiæŸ¥çœ‹è¿›ç¨‹:\"\n",
    "        nvidia-smi --query-compute-apps=pid,process_name,gpu_instance_id,used_memory --format=csv\n",
    "    }\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# é€‰æ‹©å¯ç”¨GPU\n",
    "select_gpu() {\n",
    "    echo -e \"${GREEN}ğŸ¯ é€‰æ‹©GPUè®¾å¤‡${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¯ä¸ªGPUçš„å†…å­˜ä½¿ç”¨\n",
    "    nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader,nounits | \\\\\n",
    "    while IFS=, read -r idx name mem_used mem_total; do\n",
    "        usage_percent=$(echo \"scale=1; $mem_used * 100 / $mem_total\" | bc -l 2>/dev/null || echo \"0\")\n",
    "        \n",
    "        if (( $(echo \"$usage_percent < 10\" | bc -l) )); then\n",
    "            status=\"${GREEN}å¯ç”¨${NC}\"\n",
    "        elif (( $(echo \"$usage_percent < 50\" | bc -l) )); then\n",
    "            status=\"${YELLOW}éƒ¨åˆ†å ç”¨${NC}\"\n",
    "        else\n",
    "            status=\"${RED}ç¹å¿™${NC}\"\n",
    "        fi\n",
    "        \n",
    "        echo -e \"GPU$idx: $name | å†…å­˜: ${mem_used}MB/${mem_total}MB (${usage_percent}%) | $status\"\n",
    "    done\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ è®¾ç½®GPUä½¿ç”¨æ–¹æ³•:\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=0    # ä½¿ç”¨GPU 0\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=0,1  # ä½¿ç”¨GPU 0å’Œ1\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=\\\"\\\"   # ä¸ä½¿ç”¨GPU\"\n",
    "}\n",
    "\n",
    "# æ¸…ç†GPUè¿›ç¨‹\n",
    "cleanup_gpu() {\n",
    "    echo -e \"${YELLOW}âš ï¸  æ¸…ç†GPUè¿›ç¨‹${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    echo \"å½“å‰GPUè¿›ç¨‹:\"\n",
    "    nvidia-smi --query-compute-apps=pid,process_name --format=csv\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"è¯·è°¨æ…æ“ä½œ! è¿™å°†å¼ºåˆ¶ç»ˆæ­¢GPUè¿›ç¨‹ã€‚\"\n",
    "    read -p \"ç¡®è®¤æ¸…ç†åƒµæ­»è¿›ç¨‹? (y/N): \" confirm\n",
    "    \n",
    "    if [[ $confirm == [yY] ]]; then\n",
    "        # è·å–GPUè¿›ç¨‹PIDå¹¶è¯¢é—®æ˜¯å¦ç»ˆæ­¢\n",
    "        nvidia-smi --query-compute-apps=pid --format=csv,noheader | while read pid; do\n",
    "            if [[ -n \"$pid\" && \"$pid\" != \"pid\" ]]; then\n",
    "                echo \"ç»ˆæ­¢è¿›ç¨‹ PID: $pid\"\n",
    "                kill -9 $pid 2>/dev/null || echo \"æ— æ³•ç»ˆæ­¢è¿›ç¨‹ $pid\"\n",
    "            fi\n",
    "        done\n",
    "        echo -e \"${GREEN}âœ… GPUæ¸…ç†å®Œæˆ${NC}\"\n",
    "    else\n",
    "        echo \"æ“ä½œå·²å–æ¶ˆ\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# ç›‘æ§GPUä½¿ç”¨\n",
    "monitor_gpu() {\n",
    "    echo -e \"${GREEN}ğŸ“ˆ GPUå®æ—¶ç›‘æ§${NC}\"\n",
    "    echo \"================================\"\n",
    "    echo \"æŒ‰ Ctrl+C é€€å‡ºç›‘æ§\"\n",
    "    echo \"\"\n",
    "    \n",
    "    # ä½¿ç”¨watchå‘½ä»¤å®æ—¶ç›‘æ§\n",
    "    watch -n 2 \"nvidia-smi --query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu --format=csv,noheader | \\\\\n",
    "    awk -F, '{printf \\\"GPU%s: %s\\\\n  æ¸©åº¦: %sÂ°C | åŠŸè€—: %s | å†…å­˜: %sMB/%sMB | åˆ©ç”¨ç‡: %s%%\\\\n\\\\n\\\", \\\\$1, \\\\$2, \\\\$3, \\\\$4, \\\\$5, \\\\$6, \\\\$7}'\"\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"status\"|\"\")\n",
    "        show_gpu_status\n",
    "        ;;\n",
    "    \"processes\"|\"proc\")\n",
    "        show_gpu_processes\n",
    "        ;;\n",
    "    \"select\"|\"sel\")\n",
    "        select_gpu\n",
    "        ;;\n",
    "    \"cleanup\"|\"clean\")\n",
    "        cleanup_gpu\n",
    "        ;;\n",
    "    \"monitor\"|\"mon\")\n",
    "        monitor_gpu\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {status|processes|select|cleanup|monitor}\"\n",
    "        echo \"  status     - æ˜¾ç¤ºGPUçŠ¶æ€ (é»˜è®¤)\"\n",
    "        echo \"  processes  - æ˜¾ç¤ºGPUè¿›ç¨‹\"\n",
    "        echo \"  select     - é€‰æ‹©å¯ç”¨GPU\"\n",
    "        echo \"  cleanup    - æ¸…ç†GPUè¿›ç¨‹\"\n",
    "        echo \"  monitor    - å®æ—¶ç›‘æ§GPU\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# åˆ›å»ºä»»åŠ¡ç®¡ç†å™¨\n",
    "task_manager = TaskManager()\n",
    "\n",
    "print(\"ğŸ› ï¸ ä»»åŠ¡ç®¡ç†è„šæœ¬é›†åˆ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç”Ÿæˆä»»åŠ¡è„šæœ¬\n",
    "task_scripts = task_manager.generate_task_scripts()\n",
    "\n",
    "for script_name, script_content in task_scripts.items():\n",
    "    print(f\"\\nğŸ“„ {script_name}.sh:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(script_content)\n",
    "\n",
    "print(\"\\nğŸ® GPUç®¡ç†è„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "gpu_script = task_manager.generate_gpu_management_script()\n",
    "print(gpu_script)\n",
    "\n",
    "print(\"\\nğŸ’¡ ä½¿ç”¨å»ºè®®:\")\n",
    "print(\"1. ä¿å­˜è¿™äº›è„šæœ¬åˆ°æœåŠ¡å™¨\")\n",
    "print(\"2. chmod +x *.sh  # æ·»åŠ æ‰§è¡Œæƒé™\")\n",
    "print(\"3. æ ¹æ®å®é™…é¡¹ç›®è·¯å¾„ä¿®æ”¹è„šæœ¬\")\n",
    "print(\"4. é€‰æ‹©åˆé€‚çš„ä»»åŠ¡ç®¡ç†å·¥å…· (screen/tmux/nohup)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34d883",
   "metadata": {},
   "source": [
    "## 7. SLURM ä½œä¸šè°ƒåº¦ç³»ç»Ÿ\n",
    "\n",
    "SLURM (Simple Linux Utility for Resource Management) æ˜¯å¾ˆå¤šé«˜æ€§èƒ½è®¡ç®—é›†ç¾¤ä½¿ç”¨çš„ä½œä¸šè°ƒåº¦ç³»ç»Ÿã€‚\n",
    "\n",
    "### 7.1 SLURM åŸºç¡€æ¦‚å¿µ\n",
    "\n",
    "- **èŠ‚ç‚¹ (Node)**: é›†ç¾¤ä¸­çš„è®¡ç®—æœº\n",
    "- **åˆ†åŒº (Partition)**: èŠ‚ç‚¹ç»„ï¼Œç±»ä¼¼é˜Ÿåˆ—\n",
    "- **ä½œä¸š (Job)**: æäº¤çš„è®¡ç®—ä»»åŠ¡\n",
    "- **ä½œä¸šæ­¥ (Job Step)**: ä½œä¸šä¸­çš„å¹¶è¡Œä»»åŠ¡\n",
    "\n",
    "### 7.2 å¸¸ç”¨ SLURM å‘½ä»¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlurmManager:\n",
    "    \"\"\"SLURMä½œä¸šç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.common_partitions = ['gpu', 'cpu', 'highmem', 'debug']\n",
    "        \n",
    "    def generate_slurm_templates(self):\n",
    "        \"\"\"ç”ŸæˆSLURMä½œä¸šè„šæœ¬æ¨¡æ¿\"\"\"\n",
    "        \n",
    "        templates = {}\n",
    "        \n",
    "        # 1. åŸºç¡€GPUè®­ç»ƒè„šæœ¬\n",
    "        templates['gpu_training'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=mnist_training          # ä½œä¸šåç§°\n",
    "#SBATCH --partition=gpu                    # åˆ†åŒºåç§°\n",
    "#SBATCH --nodes=1                          # èŠ‚ç‚¹æ•°\n",
    "#SBATCH --ntasks-per-node=1                # æ¯ä¸ªèŠ‚ç‚¹çš„ä»»åŠ¡æ•°\n",
    "#SBATCH --cpus-per-task=4                  # æ¯ä¸ªä»»åŠ¡çš„CPUæ ¸æ•°\n",
    "#SBATCH --gres=gpu:1                       # GPUèµ„æº (1å—GPU)\n",
    "#SBATCH --mem=16G                          # å†…å­˜éœ€æ±‚\n",
    "#SBATCH --time=24:00:00                    # æœ€å¤§è¿è¡Œæ—¶é—´ (24å°æ—¶)\n",
    "#SBATCH --output=logs/slurm_%j.out         # æ ‡å‡†è¾“å‡ºæ–‡ä»¶\n",
    "#SBATCH --error=logs/slurm_%j.err          # é”™è¯¯è¾“å‡ºæ–‡ä»¶\n",
    "#SBATCH --mail-type=ALL                    # é‚®ä»¶é€šçŸ¥ç±»å‹\n",
    "#SBATCH --mail-user=your_email@university.edu\n",
    "\n",
    "# æ‰“å°ä½œä¸šä¿¡æ¯\n",
    "echo \"ä½œä¸šå¼€å§‹æ—¶é—´: $(date)\"\n",
    "echo \"ä½œä¸šID: $SLURM_JOB_ID\"\n",
    "echo \"èŠ‚ç‚¹åç§°: $SLURM_NODELIST\"\n",
    "echo \"GPUè®¾å¤‡: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "# åˆ›å»ºæ—¥å¿—ç›®å½•\n",
    "mkdir -p logs\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒ\n",
    "source ~/.bashrc\n",
    "conda activate ml_research\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "export PYTHONPATH=$HOME/projects:$PYTHONPATH\n",
    "\n",
    "# è¿è¡Œè®­ç»ƒè„šæœ¬\n",
    "echo \"å¼€å§‹è®­ç»ƒ...\"\n",
    "python train.py \\\\\n",
    "    --epochs 100 \\\\\n",
    "    --batch-size 64 \\\\\n",
    "    --learning-rate 0.001 \\\\\n",
    "    --output-dir ./outputs \\\\\n",
    "    --log-dir ./logs\n",
    "\n",
    "echo \"è®­ç»ƒå®Œæˆæ—¶é—´: $(date)\"\n",
    "echo \"ä½œä¸šç»“æŸ\"\n",
    "\"\"\"\n",
    "\n",
    "        # 2. å¤šGPUè®­ç»ƒè„šæœ¬\n",
    "        templates['multi_gpu_training'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=multi_gpu_training\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --gres=gpu:4                       # 4å—GPU\n",
    "#SBATCH --mem=32G\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --output=logs/multi_gpu_%j.out\n",
    "#SBATCH --error=logs/multi_gpu_%j.err\n",
    "\n",
    "echo \"å¤šGPUè®­ç»ƒä½œä¸šå¼€å§‹: $(date)\"\n",
    "echo \"å¯ç”¨GPU: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒ\n",
    "conda activate ml_research\n",
    "\n",
    "# ä½¿ç”¨PyTorch DistributedDataParallel\n",
    "python -m torch.distributed.launch \\\\\n",
    "    --nproc_per_node=4 \\\\\n",
    "    --use_env \\\\\n",
    "    train_distributed.py \\\\\n",
    "    --epochs 100 \\\\\n",
    "    --batch-size 256 \\\\\n",
    "    --world-size 4\n",
    "\n",
    "echo \"å¤šGPUè®­ç»ƒå®Œæˆ: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        # 3. å‚æ•°æ‰«æè„šæœ¬\n",
    "        templates['hyperparameter_sweep'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=hyperparam_sweep\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --array=1-20                       # ä½œä¸šæ•°ç»„ (20ä¸ªå‚æ•°ç»„åˆ)\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --output=logs/sweep_%A_%a.out      # %Aæ˜¯æ•°ç»„ä½œä¸šID, %aæ˜¯ä»»åŠ¡ID\n",
    "#SBATCH --error=logs/sweep_%A_%a.err\n",
    "\n",
    "# å‚æ•°ç½‘æ ¼\n",
    "learning_rates=(0.001 0.003 0.01 0.03)\n",
    "batch_sizes=(32 64 128 256)\n",
    "optimizers=(\"adam\" \"sgd\" \"adamw\")\n",
    "\n",
    "# è®¡ç®—å½“å‰ä»»åŠ¡çš„å‚æ•°ç»„åˆ\n",
    "lr_idx=$(( ($SLURM_ARRAY_TASK_ID - 1) % 4 ))\n",
    "bs_idx=$(( (($SLURM_ARRAY_TASK_ID - 1) / 4) % 4 ))\n",
    "opt_idx=$(( (($SLURM_ARRAY_TASK_ID - 1) / 16) % 3 ))\n",
    "\n",
    "LR=${learning_rates[$lr_idx]}\n",
    "BS=${batch_sizes[$bs_idx]}\n",
    "OPT=${optimizers[$opt_idx]}\n",
    "\n",
    "echo \"ä»»åŠ¡ $SLURM_ARRAY_TASK_ID: LR=$LR, BS=$BS, OPT=$OPT\"\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒ\n",
    "conda activate ml_research\n",
    "\n",
    "# è¿è¡Œå®éªŒ\n",
    "python train.py \\\\\n",
    "    --learning-rate $LR \\\\\n",
    "    --batch-size $BS \\\\\n",
    "    --optimizer $OPT \\\\\n",
    "    --experiment-name \"sweep_${SLURM_ARRAY_TASK_ID}\" \\\\\n",
    "    --output-dir \"./outputs/sweep_${SLURM_ARRAY_TASK_ID}\"\n",
    "\n",
    "echo \"å®éªŒ $SLURM_ARRAY_TASK_ID å®Œæˆ: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        # 4. CPUå¯†é›†å‹ä»»åŠ¡\n",
    "        templates['cpu_intensive'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=cpu_task\n",
    "#SBATCH --partition=cpu                    # CPUåˆ†åŒº\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=16                 # 16ä¸ªCPUæ ¸\n",
    "#SBATCH --mem=64G                          # 64GBå†…å­˜\n",
    "#SBATCH --time=72:00:00                    # 3å¤©\n",
    "#SBATCH --output=logs/cpu_%j.out\n",
    "#SBATCH --error=logs/cpu_%j.err\n",
    "\n",
    "echo \"CPUå¯†é›†å‹ä»»åŠ¡å¼€å§‹: $(date)\"\n",
    "echo \"å¯ç”¨CPUæ ¸æ•°: $SLURM_CPUS_PER_TASK\"\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒ\n",
    "conda activate ml_research\n",
    "\n",
    "# è®¾ç½®OpenMPçº¿ç¨‹æ•°\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# è¿è¡ŒCPUå¯†é›†å‹ä»»åŠ¡ (å¦‚æ•°æ®é¢„å¤„ç†)\n",
    "python preprocess_data.py \\\\\n",
    "    --num-workers $SLURM_CPUS_PER_TASK \\\\\n",
    "    --input-dir ./raw_data \\\\\n",
    "    --output-dir ./processed_data\n",
    "\n",
    "echo \"CPUä»»åŠ¡å®Œæˆ: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        return templates\n",
    "    \n",
    "    def generate_slurm_commands_reference(self):\n",
    "        \"\"\"ç”ŸæˆSLURMå‘½ä»¤å‚è€ƒ\"\"\"\n",
    "        \n",
    "        commands = {\n",
    "            \"ä½œä¸šæäº¤\": {\n",
    "                \"sbatch script.sh\": \"æäº¤ä½œä¸šè„šæœ¬\",\n",
    "                \"sbatch --dependency=afterok:12345 script.sh\": \"ä¾èµ–ä½œä¸š12345æˆåŠŸåè¿è¡Œ\",\n",
    "                \"sbatch --begin=2024-01-01T10:00:00 script.sh\": \"å®šæ—¶æäº¤ä½œä¸š\"\n",
    "            },\n",
    "            \n",
    "            \"ä½œä¸šæŸ¥è¯¢\": {\n",
    "                \"squeue\": \"æŸ¥çœ‹æ‰€æœ‰ä½œä¸šé˜Ÿåˆ—\",\n",
    "                \"squeue -u $USER\": \"æŸ¥çœ‹å½“å‰ç”¨æˆ·çš„ä½œä¸š\",\n",
    "                \"squeue -j 12345\": \"æŸ¥çœ‹ç‰¹å®šä½œä¸š\",\n",
    "                \"sinfo\": \"æŸ¥çœ‹åˆ†åŒºå’ŒèŠ‚ç‚¹ä¿¡æ¯\",\n",
    "                \"sinfo -p gpu\": \"æŸ¥çœ‹GPUåˆ†åŒºä¿¡æ¯\"\n",
    "            },\n",
    "            \n",
    "            \"ä½œä¸šæ§åˆ¶\": {\n",
    "                \"scancel 12345\": \"å–æ¶ˆä½œä¸š12345\",\n",
    "                \"scancel -u $USER\": \"å–æ¶ˆå½“å‰ç”¨æˆ·æ‰€æœ‰ä½œä¸š\",\n",
    "                \"scontrol hold 12345\": \"æš‚åœä½œä¸š\",\n",
    "                \"scontrol release 12345\": \"é‡Šæ”¾æš‚åœçš„ä½œä¸š\"\n",
    "            },\n",
    "            \n",
    "            \"ä½œä¸šä¿¡æ¯\": {\n",
    "                \"sacct\": \"æŸ¥çœ‹ä½œä¸šå†å²\",\n",
    "                \"sacct -j 12345\": \"æŸ¥çœ‹ç‰¹å®šä½œä¸šè¯¦æƒ…\",\n",
    "                \"sstat 12345\": \"æŸ¥çœ‹è¿è¡Œä¸­ä½œä¸šçŠ¶æ€\",\n",
    "                \"scontrol show job 12345\": \"æ˜¾ç¤ºä½œä¸šè¯¦ç»†ä¿¡æ¯\"\n",
    "            },\n",
    "            \n",
    "            \"èµ„æºæŸ¥è¯¢\": {\n",
    "                \"sinfo -N\": \"æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹\",\n",
    "                \"sinfo -N -p gpu\": \"æŸ¥çœ‹GPUèŠ‚ç‚¹\",\n",
    "                \"squeue -t RUNNING\": \"æŸ¥çœ‹æ­£åœ¨è¿è¡Œçš„ä½œä¸š\",\n",
    "                \"squeue -t PENDING\": \"æŸ¥çœ‹ç­‰å¾…ä¸­çš„ä½œä¸š\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return commands\n",
    "    \n",
    "    def generate_slurm_management_script(self):\n",
    "        \"\"\"ç”ŸæˆSLURMä½œä¸šç®¡ç†è„šæœ¬\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# SLURMä½œä¸šç®¡ç†è„šæœ¬ - slurm_manager.sh\n",
    "\n",
    "# é¢œè‰²å®šä¹‰\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "# æ˜¾ç¤ºæˆ‘çš„ä½œä¸š\n",
    "show_my_jobs() {\n",
    "    echo -e \"${GREEN}ğŸ“‹ æˆ‘çš„ä½œä¸šçŠ¶æ€${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    squeue -u $USER --format=\"%.8i %.12j %.8u %.10T %.10M %.6D %R\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"ä½œä¸šçŠ¶æ€è¯´æ˜:\"\n",
    "    echo \"  PD - PENDING (ç­‰å¾…ä¸­)\"\n",
    "    echo \"  R  - RUNNING (è¿è¡Œä¸­)\"\n",
    "    echo \"  CG - COMPLETING (å®Œæˆä¸­)\"\n",
    "    echo \"  CD - COMPLETED (å·²å®Œæˆ)\"\n",
    "    echo \"  F  - FAILED (å¤±è´¥)\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºåˆ†åŒºä¿¡æ¯\n",
    "show_partitions() {\n",
    "    echo -e \"${GREEN}ğŸ–¥ï¸  åˆ†åŒºå’ŒèŠ‚ç‚¹ä¿¡æ¯${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    sinfo --format=\"%.15P %.5a %.10l %.6D %.6t %.8C %.8G %.15N\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æ˜¾ç¤ºGPUèŠ‚ç‚¹è¯¦æƒ…\n",
    "show_gpu_nodes() {\n",
    "    echo -e \"${GREEN}ğŸ® GPUèŠ‚ç‚¹çŠ¶æ€${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    sinfo -N -p gpu --format=\"%.15N %.10T %.4c %.8m %.25G %.15P\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# æäº¤è®­ç»ƒä½œä¸š\n",
    "submit_training() {\n",
    "    echo -e \"${GREEN}ğŸš€ æäº¤è®­ç»ƒä½œä¸š${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # æ£€æŸ¥å¿…è¦æ–‡ä»¶\n",
    "    if [ ! -f \"train.py\" ]; then\n",
    "        echo -e \"${RED}âŒ æ‰¾ä¸åˆ° train.py æ–‡ä»¶${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # åˆ›å»ºæ—¥å¿—ç›®å½•\n",
    "    mkdir -p logs\n",
    "    \n",
    "    # ç”Ÿæˆä½œä¸šè„šæœ¬\n",
    "    cat > submit_job.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=ml_training\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=logs/train_%j.out\n",
    "#SBATCH --error=logs/train_%j.err\n",
    "\n",
    "echo \"ä½œä¸šå¼€å§‹: $(date)\"\n",
    "echo \"èŠ‚ç‚¹: $SLURM_NODELIST\"\n",
    "echo \"GPU: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "conda activate ml_research\n",
    "python train.py\n",
    "\n",
    "echo \"ä½œä¸šç»“æŸ: $(date)\"\n",
    "EOF\n",
    "    \n",
    "    # æäº¤ä½œä¸š\n",
    "    job_id=$(sbatch submit_job.sh | grep -o '[0-9]\\\\+')\n",
    "    \n",
    "    if [ $? -eq 0 ]; then\n",
    "        echo -e \"${GREEN}âœ… ä½œä¸šå·²æäº¤, ID: $job_id${NC}\"\n",
    "        echo \"ğŸ“„ æŸ¥çœ‹è¾“å‡º: tail -f logs/train_${job_id}.out\"\n",
    "        echo \"âŒ æŸ¥çœ‹é”™è¯¯: tail -f logs/train_${job_id}.err\"\n",
    "        echo \"â¹ï¸  å–æ¶ˆä½œä¸š: scancel $job_id\"\n",
    "    else\n",
    "        echo -e \"${RED}âŒ ä½œä¸šæäº¤å¤±è´¥${NC}\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# ç›‘æ§ä½œä¸š\n",
    "monitor_job() {\n",
    "    if [ $# -eq 0 ]; then\n",
    "        echo \"ç”¨æ³•: $0 monitor <job_id>\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    job_id=$1\n",
    "    echo -e \"${GREEN}ğŸ“Š ç›‘æ§ä½œä¸š $job_id${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # æ£€æŸ¥ä½œä¸šæ˜¯å¦å­˜åœ¨\n",
    "    if ! squeue -j $job_id &>/dev/null; then\n",
    "        echo -e \"${RED}âŒ æ‰¾ä¸åˆ°ä½œä¸š $job_id${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # æ˜¾ç¤ºä½œä¸šè¯¦æƒ…\n",
    "    scontrol show job $job_id | grep -E \"(JobId|JobName|JobState|RunTime|TimeLimit|NodeList)\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo -e \"${BLUE}ğŸ“„ å®æ—¶æ—¥å¿— (Ctrl+C é€€å‡º):${NC}\"\n",
    "    \n",
    "    # æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶\n",
    "    log_file=$(find logs -name \"*${job_id}.out\" 2>/dev/null | head -1)\n",
    "    if [ -n \"$log_file\" ]; then\n",
    "        tail -f \"$log_file\"\n",
    "    else\n",
    "        echo \"æ—¥å¿—æ–‡ä»¶å°šæœªåˆ›å»º...\"\n",
    "        sleep 5\n",
    "        log_file=$(find logs -name \"*${job_id}.out\" 2>/dev/null | head -1)\n",
    "        [ -n \"$log_file\" ] && tail -f \"$log_file\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# æ¸…ç†å®Œæˆçš„ä½œä¸š\n",
    "cleanup_jobs() {\n",
    "    echo -e \"${GREEN}ğŸ§¹ æ¸…ç†å·²å®Œæˆçš„ä½œä¸š${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # æ˜¾ç¤ºå·²å®Œæˆçš„ä½œä¸š\n",
    "    completed_jobs=$(sacct --format=JobID,JobName,State,ExitCode --state=COMPLETED,FAILED --starttime=now-7days --noheader | wc -l)\n",
    "    \n",
    "    echo \"æœ€è¿‘7å¤©å†…å®Œæˆçš„ä½œä¸šæ•°: $completed_jobs\"\n",
    "    \n",
    "    # æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶\n",
    "    echo \"æ¸…ç†7å¤©å‰çš„æ—¥å¿—æ–‡ä»¶...\"\n",
    "    find logs -name \"*.out\" -o -name \"*.err\" -mtime +7 -delete 2>/dev/null\n",
    "    \n",
    "    echo -e \"${GREEN}âœ… æ¸…ç†å®Œæˆ${NC}\"\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"jobs\"|\"\")\n",
    "        show_my_jobs\n",
    "        ;;\n",
    "    \"partitions\"|\"part\")\n",
    "        show_partitions\n",
    "        ;;\n",
    "    \"gpu\")\n",
    "        show_gpu_nodes\n",
    "        ;;\n",
    "    \"submit\")\n",
    "        submit_training\n",
    "        ;;\n",
    "    \"monitor\"|\"mon\")\n",
    "        monitor_job $2\n",
    "        ;;\n",
    "    \"cleanup\")\n",
    "        cleanup_jobs\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {jobs|partitions|gpu|submit|monitor|cleanup}\"\n",
    "        echo \"  jobs       - æ˜¾ç¤ºæˆ‘çš„ä½œä¸š (é»˜è®¤)\"\n",
    "        echo \"  partitions - æ˜¾ç¤ºåˆ†åŒºä¿¡æ¯\"\n",
    "        echo \"  gpu        - æ˜¾ç¤ºGPUèŠ‚ç‚¹\"\n",
    "        echo \"  submit     - æäº¤è®­ç»ƒä½œä¸š\"\n",
    "        echo \"  monitor    - ç›‘æ§ä½œä¸š <job_id>\"\n",
    "        echo \"  cleanup    - æ¸…ç†æ—§ä½œä¸šå’Œæ—¥å¿—\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# åˆ›å»ºSLURMç®¡ç†å™¨\n",
    "slurm_manager = SlurmManager()\n",
    "\n",
    "print(\"ğŸ¯ SLURMä½œä¸šè„šæœ¬æ¨¡æ¿:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç”Ÿæˆæ¨¡æ¿\n",
    "templates = slurm_manager.generate_slurm_templates()\n",
    "for name, template in templates.items():\n",
    "    print(f\"\\nğŸ“„ {name}.slurm:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(template)\n",
    "\n",
    "print(\"\\nğŸ“š SLURMå‘½ä»¤å‚è€ƒ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç”Ÿæˆå‘½ä»¤å‚è€ƒ\n",
    "commands = slurm_manager.generate_slurm_commands_reference()\n",
    "for category, cmd_dict in commands.items():\n",
    "    print(f\"\\nğŸ“‹ {category}:\")\n",
    "    print(\"-\" * 30)\n",
    "    for cmd, desc in cmd_dict.items():\n",
    "        print(f\"  {cmd:<35} # {desc}\")\n",
    "\n",
    "print(\"\\nğŸ› ï¸ SLURMç®¡ç†è„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "management_script = slurm_manager.generate_slurm_management_script()\n",
    "print(management_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb10384",
   "metadata": {},
   "source": [
    "## 8. æœåŠ¡å™¨å·¥ä½œæµæœ€ä½³å®è·µ\n",
    "\n",
    "### 8.1 é¡¹ç›®ç»„ç»‡ç»“æ„\n",
    "\n",
    "åœ¨æœåŠ¡å™¨ä¸Šä¿æŒè‰¯å¥½çš„é¡¹ç›®ç»„ç»‡ç»“æ„éå¸¸é‡è¦ï¼š\n",
    "\n",
    "```\n",
    "~/projects/\n",
    "â”œâ”€â”€ project1/\n",
    "â”‚   â”œâ”€â”€ data/\n",
    "â”‚   â”‚   â”œâ”€â”€ raw/          # åŸå§‹æ•°æ®\n",
    "â”‚   â”‚   â””â”€â”€ processed/    # å¤„ç†åæ•°æ®\n",
    "â”‚   â”œâ”€â”€ src/              # æºä»£ç \n",
    "â”‚   â”œâ”€â”€ configs/          # é…ç½®æ–‡ä»¶\n",
    "â”‚   â”œâ”€â”€ scripts/          # è„šæœ¬æ–‡ä»¶\n",
    "â”‚   â”œâ”€â”€ logs/             # æ—¥å¿—æ–‡ä»¶\n",
    "â”‚   â”œâ”€â”€ checkpoints/      # æ¨¡å‹æ£€æŸ¥ç‚¹\n",
    "â”‚   â”œâ”€â”€ results/          # ç»“æœè¾“å‡º\n",
    "â”‚   â””â”€â”€ environment.yml   # ç¯å¢ƒé…ç½®\n",
    "â””â”€â”€ shared_utils/         # å…±äº«å·¥å…·\n",
    "```\n",
    "\n",
    "### 8.2 æ•°æ®ç®¡ç†ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerBestPractices:\n",
    "    \"\"\"æœåŠ¡å™¨ä½¿ç”¨æœ€ä½³å®è·µæŒ‡å—\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.practices = {}\n",
    "        \n",
    "    def data_management_guide(self):\n",
    "        \"\"\"æ•°æ®ç®¡ç†æŒ‡å—\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# æ•°æ®ç®¡ç†æœ€ä½³å®è·µ\n",
    "\n",
    "## 1. æ•°æ®å­˜å‚¨ç­–ç•¥\n",
    "```bash\n",
    "# åˆ›å»ºè§„èŒƒçš„æ•°æ®ç›®å½•ç»“æ„\n",
    "mkdir -p ~/data/{raw,processed,cache,backup}\n",
    "\n",
    "# ä½¿ç”¨ç¬¦å·é“¾æ¥å…±äº«å¤§å‹æ•°æ®é›†\n",
    "ln -s /shared/datasets/imagenet ~/data/imagenet\n",
    "\n",
    "# å®šæœŸå¤‡ä»½é‡è¦æ•°æ®\n",
    "rsync -av ~/projects/important_results/ ~/backup/$(date +%Y%m%d)/\n",
    "```\n",
    "\n",
    "## 2. æ•°æ®ä¼ è¾“ä¼˜åŒ–\n",
    "```bash\n",
    "# ä½¿ç”¨å‹ç¼©ä¼ è¾“å¤§æ–‡ä»¶\n",
    "tar -czf - large_dataset/ | ssh server 'cd ~/data && tar -xzf -'\n",
    "\n",
    "# æ–­ç‚¹ç»­ä¼ å¤§æ–‡ä»¶\n",
    "rsync -avz --partial --progress large_file.tar.gz server:~/data/\n",
    "\n",
    "# å¹¶è¡Œä¼ è¾“å¤šä¸ªæ–‡ä»¶\n",
    "find . -name \"*.txt\" | parallel -j4 scp {} server:~/data/\n",
    "```\n",
    "\n",
    "## 3. ç£ç›˜ç©ºé—´ç®¡ç†\n",
    "```bash\n",
    "# æ£€æŸ¥ç£ç›˜ä½¿ç”¨\n",
    "df -h\n",
    "du -sh ~/projects/*\n",
    "\n",
    "# æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "find ~/projects -name \"*.tmp\" -delete\n",
    "find ~/projects -name \"__pycache__\" -type d -exec rm -rf {} +\n",
    "\n",
    "# å‹ç¼©æ—§æ—¥å¿—\n",
    "find ~/projects -name \"*.log\" -mtime +30 -exec gzip {} \\\\;\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def performance_optimization_guide(self):\n",
    "        \"\"\"æ€§èƒ½ä¼˜åŒ–æŒ‡å—\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ\n",
    "\n",
    "## 1. CPUä¼˜åŒ–\n",
    "```python\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# è®¾ç½®OpenMPçº¿ç¨‹æ•°\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "# PyTorchæ•°æ®åŠ è½½ä¼˜åŒ–\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,        # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´\n",
    "    pin_memory=True,      # GPUè®­ç»ƒæ—¶å¯ç”¨\n",
    "    persistent_workers=True  # ä¿æŒworkerè¿›ç¨‹\n",
    ")\n",
    "```\n",
    "\n",
    "## 2. å†…å­˜ä¼˜åŒ–\n",
    "```python\n",
    "# æ¢¯åº¦æ£€æŸ¥ç‚¹ (èŠ‚çœå†…å­˜)\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = checkpoint.checkpoint(self.heavy_layer, x)\n",
    "        return x\n",
    "\n",
    "# æ¸…ç†GPUç¼“å­˜\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "with autocast():\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "```\n",
    "\n",
    "## 3. ç½‘ç»œI/Oä¼˜åŒ–\n",
    "```bash\n",
    "# å¯ç”¨SSHè¿æ¥å¤ç”¨\n",
    "echo \"Host *\n",
    "    ControlMaster auto\n",
    "    ControlPath ~/.ssh/sockets/%r@%h-%p\n",
    "    ControlPersist 600\" >> ~/.ssh/config\n",
    "\n",
    "mkdir -p ~/.ssh/sockets\n",
    "\n",
    "# ä½¿ç”¨rsyncå¢é‡åŒæ­¥\n",
    "rsync -avz --delete --exclude='*.pyc' local/ server:remote/\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def security_best_practices(self):\n",
    "        \"\"\"å®‰å…¨æœ€ä½³å®è·µ\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# å®‰å…¨æœ€ä½³å®è·µ\n",
    "\n",
    "## 1. SSHå®‰å…¨é…ç½®\n",
    "```bash\n",
    "# ç”Ÿæˆå¼ºå¯†é’¥\n",
    "ssh-keygen -t ed25519 -a 100 -f ~/.ssh/server_key\n",
    "\n",
    "# é…ç½®SSHå®¢æˆ·ç«¯\n",
    "cat >> ~/.ssh/config << EOF\n",
    "Host secure-server\n",
    "    HostName server.university.edu\n",
    "    User your_username\n",
    "    IdentityFile ~/.ssh/server_key\n",
    "    PasswordAuthentication no\n",
    "    PubkeyAuthentication yes\n",
    "    ServerAliveInterval 60\n",
    "EOF\n",
    "\n",
    "# è®¾ç½®æ­£ç¡®çš„æƒé™\n",
    "chmod 700 ~/.ssh\n",
    "chmod 600 ~/.ssh/*\n",
    "chmod 644 ~/.ssh/*.pub\n",
    "```\n",
    "\n",
    "## 2. æ•æ„Ÿä¿¡æ¯ç®¡ç†\n",
    "```bash\n",
    "# ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "echo \"export API_KEY='your_secret_key'\" >> ~/.bashrc_private\n",
    "echo \"source ~/.bashrc_private\" >> ~/.bashrc\n",
    "\n",
    "# åœ¨ä»£ç ä¸­ä½¿ç”¨\n",
    "import os\n",
    "api_key = os.environ.get('API_KEY')\n",
    "```\n",
    "\n",
    "## 3. æ–‡ä»¶æƒé™ç®¡ç†\n",
    "```bash\n",
    "# è®¾ç½®é»˜è®¤æƒé™\n",
    "umask 022\n",
    "\n",
    "# ä¿æŠ¤æ•æ„Ÿæ–‡ä»¶\n",
    "chmod 600 config_with_secrets.yaml\n",
    "chmod 700 private_scripts/\n",
    "\n",
    "# å…±äº«é¡¹ç›®ç›®å½•\n",
    "chmod 755 ~/projects/shared_project/\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def troubleshooting_guide(self):\n",
    "        \"\"\"æ•…éšœæ’é™¤æŒ‡å—\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# æ•…éšœæ’é™¤æŒ‡å—\n",
    "\n",
    "## 1. è¿æ¥é—®é¢˜\n",
    "### SSHè¿æ¥è¶…æ—¶\n",
    "```bash\n",
    "# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§\n",
    "ping server.university.edu\n",
    "\n",
    "# ä½¿ç”¨è¯¦ç»†æ¨¡å¼è¯Šæ–­\n",
    "ssh -v username@server\n",
    "\n",
    "# æ£€æŸ¥SSHæœåŠ¡çŠ¶æ€\n",
    "ssh username@server 'sudo systemctl status sshd'\n",
    "```\n",
    "\n",
    "### è¿æ¥é¢‘ç¹æ–­å¼€\n",
    "```bash\n",
    "# å®¢æˆ·ç«¯é…ç½®ä¿æŒè¿æ¥\n",
    "echo \"ServerAliveInterval 60\n",
    "ServerAliveCountMax 3\" >> ~/.ssh/config\n",
    "\n",
    "# æœåŠ¡å™¨ç«¯é…ç½® (éœ€è¦ç®¡ç†å‘˜æƒé™)\n",
    "# åœ¨ /etc/ssh/sshd_config ä¸­æ·»åŠ :\n",
    "# ClientAliveInterval 60\n",
    "# ClientAliveCountMax 3\n",
    "```\n",
    "\n",
    "## 2. ç¯å¢ƒé—®é¢˜\n",
    "### Condaç¯å¢ƒé—®é¢˜\n",
    "```bash\n",
    "# é‡æ–°åˆå§‹åŒ–Conda\n",
    "conda init bash\n",
    "source ~/.bashrc\n",
    "\n",
    "# æ¸…ç†æŸåçš„ç¯å¢ƒ\n",
    "conda remove --name broken_env --all\n",
    "conda clean --all\n",
    "\n",
    "# é‡å»ºç¯å¢ƒ\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "### PythonåŒ…å†²çª\n",
    "```bash\n",
    "# æ£€æŸ¥åŒ…ä¾èµ–\n",
    "pip check\n",
    "\n",
    "# åˆ›å»ºæ–°çš„æ¸…æ´ç¯å¢ƒ\n",
    "conda create -n fresh_env python=3.9\n",
    "conda activate fresh_env\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## 3. èµ„æºé—®é¢˜\n",
    "### GPUå†…å­˜ä¸è¶³\n",
    "```python\n",
    "# æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨\n",
    "import torch\n",
    "print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n",
    "print(f\"å·²ç”¨å†…å­˜: {torch.cuda.memory_allocated(0)/1e9:.1f}GB\")\n",
    "\n",
    "# æ¸…ç†GPUç¼“å­˜\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# å‡å°‘æ‰¹æ¬¡å¤§å°\n",
    "batch_size = 32  # ä»64å‡å°‘åˆ°32\n",
    "```\n",
    "\n",
    "### ç£ç›˜ç©ºé—´ä¸è¶³\n",
    "```bash\n",
    "# æŸ¥æ‰¾å¤§æ–‡ä»¶\n",
    "find ~ -size +1G -type f -exec ls -lh {} \\\\; | sort -k5 -hr\n",
    "\n",
    "# æ¸…ç†ç¼“å­˜\n",
    "rm -rf ~/.cache/pip\n",
    "conda clean --all\n",
    "\n",
    "# å‹ç¼©æ—¥å¿—æ–‡ä»¶\n",
    "find ~/projects -name \"*.log\" -exec gzip {} \\\\;\n",
    "```\n",
    "\n",
    "## 4. æ€§èƒ½é—®é¢˜\n",
    "### è®­ç»ƒé€Ÿåº¦æ…¢\n",
    "```python\n",
    "# æ£€æŸ¥æ•°æ®åŠ è½½ç“¶é¢ˆ\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for batch in train_loader:\n",
    "    data_time = time.time() - start_time\n",
    "    print(f\"æ•°æ®åŠ è½½æ—¶é—´: {data_time:.3f}s\")\n",
    "    break\n",
    "\n",
    "# å¢åŠ æ•°æ®åŠ è½½workers\n",
    "train_loader = DataLoader(..., num_workers=8)\n",
    "\n",
    "# ä½¿ç”¨æ··åˆç²¾åº¦\n",
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    output = model(input)\n",
    "```\n",
    "\n",
    "### å†…å­˜æ³„æ¼\n",
    "```python\n",
    "# ç›‘æ§å†…å­˜ä½¿ç”¨\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "# è®­ç»ƒä»£ç ...\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"å½“å‰å†…å­˜: {current/1e6:.1f}MB, å³°å€¼: {peak/1e6:.1f}MB\")\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def monitoring_scripts(self):\n",
    "        \"\"\"ç”Ÿæˆç›‘æ§è„šæœ¬\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# ç³»ç»Ÿç›‘æ§è„šæœ¬ - system_monitor.sh\n",
    "\n",
    "# åˆ›å»ºç›‘æ§æŠ¥å‘Š\n",
    "create_report() {\n",
    "    local report_file=\"monitor_report_$(date +%Y%m%d_%H%M%S).txt\"\n",
    "    \n",
    "    echo \"=== ç³»ç»Ÿç›‘æ§æŠ¥å‘Š ===\" > $report_file\n",
    "    echo \"ç”Ÿæˆæ—¶é—´: $(date)\" >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== ç³»ç»Ÿä¿¡æ¯ ===\" >> $report_file\n",
    "    uname -a >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== CPUä½¿ç”¨ç‡ ===\" >> $report_file\n",
    "    top -bn1 | head -20 >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== å†…å­˜ä½¿ç”¨ ===\" >> $report_file\n",
    "    free -h >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== ç£ç›˜ä½¿ç”¨ ===\" >> $report_file\n",
    "    df -h >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"=== GPUçŠ¶æ€ ===\" >> $report_file\n",
    "        nvidia-smi >> $report_file\n",
    "        echo \"\" >> $report_file\n",
    "    fi\n",
    "    \n",
    "    echo \"=== ç½‘ç»œè¿æ¥ ===\" >> $report_file\n",
    "    ss -tuln >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== æœ€è¿‘çš„ç³»ç»Ÿæ—¥å¿— ===\" >> $report_file\n",
    "    journalctl --since \"1 hour ago\" --no-pager | tail -50 >> $report_file\n",
    "    \n",
    "    echo \"ç›‘æ§æŠ¥å‘Šå·²ä¿å­˜åˆ°: $report_file\"\n",
    "}\n",
    "\n",
    "# å®æ—¶ç›‘æ§\n",
    "real_time_monitor() {\n",
    "    echo \"å¼€å§‹å®æ—¶ç›‘æ§ (Ctrl+C é€€å‡º)...\"\n",
    "    \n",
    "    while true; do\n",
    "        clear\n",
    "        echo \"=== å®æ—¶ç³»ç»Ÿç›‘æ§ - $(date) ===\"\n",
    "        echo \"\"\n",
    "        \n",
    "        echo \"CPUå’Œå†…å­˜:\"\n",
    "        top -bn1 | head -5 | tail -2\n",
    "        echo \"\"\n",
    "        \n",
    "        echo \"ç£ç›˜ä½¿ç”¨:\"\n",
    "        df -h | grep -E '^/dev/'\n",
    "        echo \"\"\n",
    "        \n",
    "        if command -v nvidia-smi &> /dev/null; then\n",
    "            echo \"GPUçŠ¶æ€:\"\n",
    "            nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits\n",
    "            echo \"\"\n",
    "        fi\n",
    "        \n",
    "        echo \"ç½‘ç»œæµé‡:\"\n",
    "        cat /proc/net/dev | grep -E '(eth|wlan)' | head -2\n",
    "        echo \"\"\n",
    "        \n",
    "        sleep 5\n",
    "    done\n",
    "}\n",
    "\n",
    "# æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶å†µ\n",
    "health_check() {\n",
    "    echo \"=== æœåŠ¡å™¨å¥åº·æ£€æŸ¥ ===\"\n",
    "    \n",
    "    # CPUæ¸©åº¦æ£€æŸ¥\n",
    "    if command -v sensors &> /dev/null; then\n",
    "        echo \"CPUæ¸©åº¦:\"\n",
    "        sensors | grep -E 'Core|temp'\n",
    "        echo \"\"\n",
    "    fi\n",
    "    \n",
    "    # è´Ÿè½½æ£€æŸ¥\n",
    "    load=$(uptime | awk -F'load average:' '{print $2}' | cut -d, -f1 | xargs)\n",
    "    cores=$(nproc)\n",
    "    echo \"ç³»ç»Ÿè´Ÿè½½: $load / $cores æ ¸\"\n",
    "    \n",
    "    if (( $(echo \"$load > $cores\" | bc -l) )); then\n",
    "        echo \"âš ï¸  è­¦å‘Š: ç³»ç»Ÿè´Ÿè½½è¿‡é«˜!\"\n",
    "    else\n",
    "        echo \"âœ… ç³»ç»Ÿè´Ÿè½½æ­£å¸¸\"\n",
    "    fi\n",
    "    echo \"\"\n",
    "    \n",
    "    # å†…å­˜æ£€æŸ¥\n",
    "    mem_usage=$(free | awk '/Mem:/ {printf \"%.1f\", $3/$2 * 100.0}')\n",
    "    echo \"å†…å­˜ä½¿ç”¨ç‡: ${mem_usage}%\"\n",
    "    \n",
    "    if (( $(echo \"$mem_usage > 90\" | bc -l) )); then\n",
    "        echo \"âš ï¸  è­¦å‘Š: å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜!\"\n",
    "    else\n",
    "        echo \"âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸\"\n",
    "    fi\n",
    "    echo \"\"\n",
    "    \n",
    "    # ç£ç›˜æ£€æŸ¥\n",
    "    echo \"ç£ç›˜ä½¿ç”¨ç‡:\"\n",
    "    df -h | awk 'NR>1 && $5+0 > 90 {print \"âš ï¸  \" $0 \" - ç£ç›˜ç©ºé—´ä¸è¶³!\"}'\n",
    "    df -h | awk 'NR>1 && $5+0 <= 90 {print \"âœ… \" $0}'\n",
    "    echo \"\"\n",
    "    \n",
    "    # GPUæ£€æŸ¥\n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"GPUçŠ¶æ€æ£€æŸ¥:\"\n",
    "        nvidia-smi --query-gpu=temperature.gpu,power.draw --format=csv,noheader,nounits | \\\\\n",
    "        awk -F, '{temp=$1; power=$2; if(temp>80) print \"âš ï¸  GPUæ¸©åº¦è¿‡é«˜: \" temp \"Â°C\"; else print \"âœ… GPUæ¸©åº¦æ­£å¸¸: \" temp \"Â°C\"}'\n",
    "        echo \"\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"report\")\n",
    "        create_report\n",
    "        ;;\n",
    "    \"monitor\")\n",
    "        real_time_monitor\n",
    "        ;;\n",
    "    \"health\")\n",
    "        health_check\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {report|monitor|health}\"\n",
    "        echo \"  report  - ç”Ÿæˆç›‘æ§æŠ¥å‘Š\"\n",
    "        echo \"  monitor - å®æ—¶ç›‘æ§\"\n",
    "        echo \"  health  - å¥åº·æ£€æŸ¥\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# åˆ›å»ºæœ€ä½³å®è·µæŒ‡å—\n",
    "practices = ServerBestPractices()\n",
    "\n",
    "print(\"ğŸ“Š æ•°æ®ç®¡ç†æŒ‡å—:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.data_management_guide())\n",
    "\n",
    "print(\"\\nâš¡ æ€§èƒ½ä¼˜åŒ–æŒ‡å—:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.performance_optimization_guide())\n",
    "\n",
    "print(\"\\nğŸ”’ å®‰å…¨æœ€ä½³å®è·µ:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.security_best_practices())\n",
    "\n",
    "print(\"\\nğŸ”§ æ•…éšœæ’é™¤æŒ‡å—:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.troubleshooting_guide())\n",
    "\n",
    "print(\"\\nğŸ“ˆ ç³»ç»Ÿç›‘æ§è„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.monitoring_scripts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d175f",
   "metadata": {},
   "source": [
    "## 9. å®Œæ•´å·¥ä½œæµç¤ºä¾‹\n",
    "\n",
    "### 9.1 å…¸å‹çš„æœºå™¨å­¦ä¹ é¡¹ç›®å·¥ä½œæµ\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä¸€ä¸ªä»é¡¹ç›®å¼€å§‹åˆ°ç»“æŸçš„å®Œæ•´æœåŠ¡å™¨å·¥ä½œæµç¤ºä¾‹ï¼š\n",
    "\n",
    "#### é˜¶æ®µ1ï¼šé¡¹ç›®åˆå§‹åŒ–\n",
    "1. åœ¨æœ¬åœ°å¼€å‘å’Œæµ‹è¯•ä»£ç \n",
    "2. å‡†å¤‡é¡¹ç›®ç»“æ„å’Œé…ç½®æ–‡ä»¶\n",
    "3. åˆ›å»ºrequirements.txtå’Œenvironment.yml\n",
    "\n",
    "#### é˜¶æ®µ2ï¼šæœåŠ¡å™¨ç¯å¢ƒæ­å»º\n",
    "1. è¿æ¥æœåŠ¡å™¨å¹¶é…ç½®SSH\n",
    "2. åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„\n",
    "3. è®¾ç½®Condaç¯å¢ƒ\n",
    "4. ä¸Šä¼ åˆå§‹ä»£ç \n",
    "\n",
    "#### é˜¶æ®µ3ï¼šæ•°æ®å‡†å¤‡\n",
    "1. ä¸Šä¼ æˆ–é“¾æ¥æ•°æ®é›†\n",
    "2. è¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬\n",
    "3. éªŒè¯æ•°æ®å®Œæ•´æ€§\n",
    "\n",
    "#### é˜¶æ®µ4ï¼šæ¨¡å‹è®­ç»ƒ\n",
    "1. æäº¤è®­ç»ƒä»»åŠ¡ï¼ˆSLURMæˆ–åå°è¿è¡Œï¼‰\n",
    "2. ç›‘æ§è®­ç»ƒè¿›åº¦\n",
    "3. è°ƒæ•´è¶…å‚æ•°\n",
    "\n",
    "#### é˜¶æ®µ5ï¼šç»“æœåˆ†æ\n",
    "1. ä¸‹è½½è®­ç»ƒç»“æœ\n",
    "2. åˆ†ææ¨¡å‹æ€§èƒ½\n",
    "3. ç”ŸæˆæŠ¥å‘Šå’Œå¯è§†åŒ–\n",
    "\n",
    "### 9.2 å·¥ä½œæµè‡ªåŠ¨åŒ–è„šæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteWorkflow:\n",
    "    \"\"\"å®Œæ•´çš„æœåŠ¡å™¨å·¥ä½œæµç®¡ç†\"\"\"\n",
    "    \n",
    "    def __init__(self, project_name, server_config):\n",
    "        self.project_name = project_name\n",
    "        self.server_config = server_config\n",
    "        \n",
    "    def generate_workflow_script(self):\n",
    "        \"\"\"ç”Ÿæˆå®Œæ•´å·¥ä½œæµè„šæœ¬\"\"\"\n",
    "        \n",
    "        script = f\"\"\"#!/bin/bash\n",
    "# å®Œæ•´æœºå™¨å­¦ä¹ é¡¹ç›®å·¥ä½œæµ - ml_workflow.sh\n",
    "\n",
    "PROJECT_NAME=\"{self.project_name}\"\n",
    "SERVER_USER=\"{self.server_config.get('user', 'username')}\"\n",
    "SERVER_HOST=\"{self.server_config.get('host', 'server')}\"\n",
    "REMOTE_BASE=\"/home/$SERVER_USER/projects\"\n",
    "LOCAL_PROJECT=\"./$PROJECT_NAME\"\n",
    "\n",
    "# é¢œè‰²å®šä¹‰\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "log_info() {{ echo -e \"${{GREEN}}[INFO]${{NC}} $1\"; }}\n",
    "log_warn() {{ echo -e \"${{YELLOW}}[WARN]${{NC}} $1\"; }}\n",
    "log_error() {{ echo -e \"${{RED}}[ERROR]${{NC}} $1\"; }}\n",
    "\n",
    "# é˜¶æ®µ1: é¡¹ç›®åˆå§‹åŒ–\n",
    "init_project() {{\n",
    "    log_info \"ğŸš€ åˆå§‹åŒ–é¡¹ç›®: $PROJECT_NAME\"\n",
    "    \n",
    "    # åˆ›å»ºæœ¬åœ°é¡¹ç›®ç»“æ„\n",
    "    mkdir -p $LOCAL_PROJECT/{{data,src,configs,scripts,logs,results}}\n",
    "    \n",
    "    # åˆ›å»ºé…ç½®æ–‡ä»¶\n",
    "    cat > $LOCAL_PROJECT/requirements.txt << 'EOF'\n",
    "torch>=1.9.0\n",
    "torchvision\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "scikit-learn\n",
    "tensorboard\n",
    "tqdm\n",
    "pyyaml\n",
    "EOF\n",
    "\n",
    "    cat > $LOCAL_PROJECT/environment.yml << 'EOF'\n",
    "name: {self.project_name}\n",
    "channels:\n",
    "  - pytorch\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pytorch\n",
    "  - torchvision\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - scikit-learn\n",
    "  - jupyter\n",
    "  - pip\n",
    "  - pip:\n",
    "    - tensorboard\n",
    "    - tqdm\n",
    "    - pyyaml\n",
    "EOF\n",
    "\n",
    "    # åˆ›å»ºREADME\n",
    "    cat > $LOCAL_PROJECT/README.md << 'EOF'\n",
    "# {self.project_name}\n",
    "\n",
    "## é¡¹ç›®æè¿°\n",
    "æœºå™¨å­¦ä¹ é¡¹ç›®æ¨¡æ¿\n",
    "\n",
    "## ç¯å¢ƒè®¾ç½®\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate {self.project_name}\n",
    "```\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "1. æ•°æ®é¢„å¤„ç†: `python src/preprocess.py`\n",
    "2. æ¨¡å‹è®­ç»ƒ: `python src/train.py`\n",
    "3. ç»“æœè¯„ä¼°: `python src/evaluate.py`\n",
    "EOF\n",
    "\n",
    "    log_info \"âœ… é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ\"\n",
    "}}\n",
    "\n",
    "# é˜¶æ®µ2: æœåŠ¡å™¨ç¯å¢ƒæ­å»º\n",
    "setup_server() {{\n",
    "    log_info \"ğŸ–¥ï¸  è®¾ç½®æœåŠ¡å™¨ç¯å¢ƒ\"\n",
    "    \n",
    "    # åˆ›å»ºè¿œç¨‹ç›®å½•\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"mkdir -p $REMOTE_BASE/$PROJECT_NAME/{{data,src,configs,scripts,logs,results,checkpoints}}\"\n",
    "    \n",
    "    # ä¸Šä¼ é¡¹ç›®æ–‡ä»¶\n",
    "    rsync -avz --progress \\\\\n",
    "        --exclude='*.pyc' \\\\\n",
    "        --exclude='__pycache__/' \\\\\n",
    "        --exclude='.git/' \\\\\n",
    "        --exclude='data/raw/' \\\\\n",
    "        $LOCAL_PROJECT/ \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/\n",
    "    \n",
    "    # åœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºç¯å¢ƒ\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        conda env create -f environment.yml && \\\\\n",
    "        echo 'conda activate $PROJECT_NAME' >> ~/.bashrc\"\n",
    "    \n",
    "    log_info \"âœ… æœåŠ¡å™¨ç¯å¢ƒè®¾ç½®å®Œæˆ\"\n",
    "}}\n",
    "\n",
    "# é˜¶æ®µ3: æ•°æ®å‡†å¤‡\n",
    "prepare_data() {{\n",
    "    log_info \"ğŸ“Š å‡†å¤‡æ•°æ®\"\n",
    "    \n",
    "    # ä¸Šä¼ æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n",
    "    if [ -d \"$LOCAL_PROJECT/data/raw\" ]; then\n",
    "        log_info \"ä¸Šä¼ åŸå§‹æ•°æ®...\"\n",
    "        rsync -avz --progress \\\\\n",
    "            $LOCAL_PROJECT/data/raw/ \\\\\n",
    "            $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/data/raw/\n",
    "    fi\n",
    "    \n",
    "    # åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œæ•°æ®é¢„å¤„ç†\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        conda activate $PROJECT_NAME && \\\\\n",
    "        python -c 'print(\\\\\\\"æ•°æ®é¢„å¤„ç†å¼€å§‹\\\\\\\")' && \\\\\n",
    "        echo 'æ•°æ®é¢„å¤„ç†å®Œæˆ'\"\n",
    "    \n",
    "    log_info \"âœ… æ•°æ®å‡†å¤‡å®Œæˆ\"\n",
    "}}\n",
    "\n",
    "# é˜¶æ®µ4: æäº¤è®­ç»ƒä»»åŠ¡\n",
    "submit_training() {{\n",
    "    log_info \"ğŸ¤– æäº¤è®­ç»ƒä»»åŠ¡\"\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒè„šæœ¬\n",
    "    cat > train_job.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name={self.project_name}_train\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=logs/train_%j.out\n",
    "#SBATCH --error=logs/train_%j.err\n",
    "\n",
    "echo \"è®­ç»ƒå¼€å§‹: $(date)\"\n",
    "conda activate {self.project_name}\n",
    "python src/train.py --config configs/default.yaml\n",
    "echo \"è®­ç»ƒç»“æŸ: $(date)\"\n",
    "EOF\n",
    "\n",
    "    # ä¸Šä¼ å¹¶æäº¤ä½œä¸š\n",
    "    scp train_job.sh $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/\n",
    "    \n",
    "    job_id=$(ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && sbatch train_job.sh\" | grep -o '[0-9]\\\\+')\n",
    "    \n",
    "    if [ -n \"$job_id\" ]; then\n",
    "        log_info \"âœ… è®­ç»ƒä»»åŠ¡å·²æäº¤, ä½œä¸šID: $job_id\"\n",
    "        echo $job_id > .job_id\n",
    "    else\n",
    "        log_error \"âŒ è®­ç»ƒä»»åŠ¡æäº¤å¤±è´¥\"\n",
    "        return 1\n",
    "    fi\n",
    "}}\n",
    "\n",
    "# é˜¶æ®µ5: ç›‘æ§è®­ç»ƒ\n",
    "monitor_training() {{\n",
    "    if [ ! -f \".job_id\" ]; then\n",
    "        log_error \"âŒ æ²¡æœ‰æ‰¾åˆ°ä½œä¸šIDæ–‡ä»¶\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    job_id=$(cat .job_id)\n",
    "    log_info \"ğŸ“Š ç›‘æ§è®­ç»ƒä»»åŠ¡: $job_id\"\n",
    "    \n",
    "    # æ£€æŸ¥ä½œä¸šçŠ¶æ€\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"squeue -j $job_id\"\n",
    "    \n",
    "    # å®æ—¶æŸ¥çœ‹æ—¥å¿—\n",
    "    log_info \"ğŸ“„ å®æ—¶æ—¥å¿— (Ctrl+C é€€å‡º):\"\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"tail -f $REMOTE_BASE/$PROJECT_NAME/logs/train_${{job_id}}.out\"\n",
    "}}\n",
    "\n",
    "# é˜¶æ®µ6: ä¸‹è½½ç»“æœ\n",
    "download_results() {{\n",
    "    log_info \"ğŸ“¥ ä¸‹è½½è®­ç»ƒç»“æœ\"\n",
    "    \n",
    "    # åˆ›å»ºæœ¬åœ°ç»“æœç›®å½•\n",
    "    mkdir -p $LOCAL_PROJECT/results/$(date +%Y%m%d_%H%M%S)\n",
    "    \n",
    "    # ä¸‹è½½ç»“æœæ–‡ä»¶\n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/checkpoints/ \\\\\n",
    "        $LOCAL_PROJECT/results/checkpoints/\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/logs/ \\\\\n",
    "        $LOCAL_PROJECT/results/logs/\n",
    "    \n",
    "    # ä¸‹è½½å¯è§†åŒ–ç»“æœ\n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/results/ \\\\\n",
    "        $LOCAL_PROJECT/results/\n",
    "    \n",
    "    log_info \"âœ… ç»“æœä¸‹è½½å®Œæˆ\"\n",
    "}}\n",
    "\n",
    "# æ¸…ç†å‡½æ•°\n",
    "cleanup() {{\n",
    "    log_info \"ğŸ§¹ æ¸…ç†æœåŠ¡å™¨ä¸´æ—¶æ–‡ä»¶\"\n",
    "    \n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        find . -name '*.tmp' -delete && \\\\\n",
    "        find . -name '__pycache__' -type d -exec rm -rf {{}} + 2>/dev/null || true\"\n",
    "    \n",
    "    log_info \"âœ… æ¸…ç†å®Œæˆ\"\n",
    "}}\n",
    "\n",
    "# å®Œæ•´å·¥ä½œæµ\n",
    "run_complete_workflow() {{\n",
    "    log_info \"ğŸ¯ å¼€å§‹å®Œæ•´å·¥ä½œæµ\"\n",
    "    \n",
    "    init_project\n",
    "    setup_server\n",
    "    prepare_data\n",
    "    submit_training\n",
    "    \n",
    "    log_info \"ğŸ‰ å·¥ä½œæµå¯åŠ¨å®Œæˆï¼\"\n",
    "    log_info \"ğŸ“‹ åç»­æ“ä½œ:\"\n",
    "    log_info \"  - ç›‘æ§è®­ç»ƒ: $0 monitor\"\n",
    "    log_info \"  - ä¸‹è½½ç»“æœ: $0 download\"\n",
    "    log_info \"  - æ¸…ç†æ–‡ä»¶: $0 cleanup\"\n",
    "}}\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "case \"$1\" in\n",
    "    \"init\")\n",
    "        init_project\n",
    "        ;;\n",
    "    \"setup\")\n",
    "        setup_server\n",
    "        ;;\n",
    "    \"data\")\n",
    "        prepare_data\n",
    "        ;;\n",
    "    \"train\")\n",
    "        submit_training\n",
    "        ;;\n",
    "    \"monitor\")\n",
    "        monitor_training\n",
    "        ;;\n",
    "    \"download\")\n",
    "        download_results\n",
    "        ;;\n",
    "    \"cleanup\")\n",
    "        cleanup\n",
    "        ;;\n",
    "    \"all\"|\"\")\n",
    "        run_complete_workflow\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ç”¨æ³•: $0 {{init|setup|data|train|monitor|download|cleanup|all}}\"\n",
    "        echo \"  init     - åˆå§‹åŒ–é¡¹ç›®\"\n",
    "        echo \"  setup    - è®¾ç½®æœåŠ¡å™¨ç¯å¢ƒ\"\n",
    "        echo \"  data     - å‡†å¤‡æ•°æ®\"\n",
    "        echo \"  train    - æäº¤è®­ç»ƒä»»åŠ¡\"\n",
    "        echo \"  monitor  - ç›‘æ§è®­ç»ƒ\"\n",
    "        echo \"  download - ä¸‹è½½ç»“æœ\"\n",
    "        echo \"  cleanup  - æ¸…ç†ä¸´æ—¶æ–‡ä»¶\"\n",
    "        echo \"  all      - è¿è¡Œå®Œæ•´å·¥ä½œæµ (é»˜è®¤)\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def generate_project_template(self):\n",
    "        \"\"\"ç”Ÿæˆé¡¹ç›®æ¨¡æ¿æ–‡ä»¶\"\"\"\n",
    "        \n",
    "        templates = {}\n",
    "        \n",
    "        # è®­ç»ƒè„šæœ¬æ¨¡æ¿\n",
    "        templates['train.py'] = \"\"\"#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "æœºå™¨å­¦ä¹ è®­ç»ƒè„šæœ¬æ¨¡æ¿\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config(config_path):\n",
    "    \\\"\\\"\\\"åŠ è½½é…ç½®æ–‡ä»¶\\\"\\\"\\\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def setup_logging(log_dir):\n",
    "    \\\"\\\"\\\"è®¾ç½®æ—¥å¿—\\\"\\\"\\\"\n",
    "    log_dir = Path(log_dir)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n",
    "\n",
    "def train_model(config):\n",
    "    \\\"\\\"\\\"è®­ç»ƒæ¨¡å‹\\\"\\\"\\\"\n",
    "    print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ: {{config['model']['name']}}\")\n",
    "    \n",
    "    # è®¾ç½®è®¾å¤‡\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ä½¿ç”¨è®¾å¤‡: {{device}}\")\n",
    "    \n",
    "    # è¿™é‡Œæ·»åŠ ä½ çš„è®­ç»ƒä»£ç \n",
    "    # model = YourModel()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=config['training']['lr'])\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # è®­ç»ƒå¾ªç¯\n",
    "    for epoch in range(config['training']['epochs']):\n",
    "        print(f\"Epoch {{epoch+1}}/{{config['training']['epochs']}}\")\n",
    "        \n",
    "        # è®­ç»ƒä»£ç ...\n",
    "        \n",
    "        # ä¿å­˜æ£€æŸ¥ç‚¹\n",
    "        if (epoch + 1) % config['training']['save_frequency'] == 0:\n",
    "            checkpoint_path = Path(config['paths']['checkpoints']) / f\"model_epoch_{{epoch+1}}.pth\"\n",
    "            # torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: {{checkpoint_path}}\")\n",
    "    \n",
    "    print(\"ğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='è®­ç»ƒè„šæœ¬')\n",
    "    parser.add_argument('--config', type=str, default='configs/default.yaml',\n",
    "                       help='é…ç½®æ–‡ä»¶è·¯å¾„')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # åŠ è½½é…ç½®\n",
    "    config = load_config(args.config)\n",
    "    \n",
    "    # è®¾ç½®æ—¥å¿—\n",
    "    writer = setup_logging(config['paths']['logs'])\n",
    "    \n",
    "    # å¼€å§‹è®­ç»ƒ\n",
    "    train_model(config)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "        # é…ç½®æ–‡ä»¶æ¨¡æ¿\n",
    "        templates['default.yaml'] = f\"\"\"\n",
    "# é»˜è®¤é…ç½®æ–‡ä»¶\n",
    "project:\n",
    "  name: \"{self.project_name}\"\n",
    "  description: \"æœºå™¨å­¦ä¹ é¡¹ç›®\"\n",
    "\n",
    "model:\n",
    "  name: \"SimpleCNN\"\n",
    "  num_classes: 10\n",
    "  dropout: 0.5\n",
    "\n",
    "training:\n",
    "  epochs: 100\n",
    "  batch_size: 64\n",
    "  learning_rate: 0.001\n",
    "  optimizer: \"adam\"\n",
    "  scheduler: \"step\"\n",
    "  save_frequency: 10\n",
    "\n",
    "data:\n",
    "  dataset: \"MNIST\"\n",
    "  train_split: 0.8\n",
    "  val_split: 0.1\n",
    "  test_split: 0.1\n",
    "\n",
    "paths:\n",
    "  data: \"./data\"\n",
    "  checkpoints: \"./checkpoints\"\n",
    "  logs: \"./logs\"\n",
    "  results: \"./results\"\n",
    "\n",
    "hardware:\n",
    "  device: \"auto\"  # auto, cpu, cuda\n",
    "  num_workers: 4\n",
    "  pin_memory: true\n",
    "\"\"\"\n",
    "        \n",
    "        return templates\n",
    "\n",
    "# åˆ›å»ºå®Œæ•´å·¥ä½œæµç®¡ç†å™¨\n",
    "server_config = {\n",
    "    'user': 'your_username',\n",
    "    'host': 'gpu-server',\n",
    "    'port': 22\n",
    "}\n",
    "\n",
    "workflow = CompleteWorkflow(\"my_ml_project\", server_config)\n",
    "\n",
    "print(\"ğŸ”„ å®Œæ•´å·¥ä½œæµè„šæœ¬:\")\n",
    "print(\"=\"*60)\n",
    "workflow_script = workflow.generate_workflow_script()\n",
    "print(workflow_script)\n",
    "\n",
    "print(\"\\nğŸ“‹ é¡¹ç›®æ¨¡æ¿æ–‡ä»¶:\")\n",
    "print(\"=\"*60)\n",
    "templates = workflow.generate_project_template()\n",
    "\n",
    "for filename, content in templates.items():\n",
    "    print(f\"\\nğŸ“„ {filename}:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(content)\n",
    "\n",
    "print(\"\\nğŸ¯ ä½¿ç”¨æŒ‡å—:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. ä¿å­˜å·¥ä½œæµè„šæœ¬ä¸º ml_workflow.sh\n",
    "2. ä¿®æ”¹è„šæœ¬ä¸­çš„æœåŠ¡å™¨é…ç½®\n",
    "3. chmod +x ml_workflow.sh\n",
    "4. è¿è¡Œå®Œæ•´å·¥ä½œæµ: ./ml_workflow.sh all\n",
    "\n",
    "å„é˜¶æ®µå¯ä»¥å•ç‹¬è¿è¡Œ:\n",
    "- åˆå§‹åŒ–é¡¹ç›®: ./ml_workflow.sh init\n",
    "- è®¾ç½®æœåŠ¡å™¨: ./ml_workflow.sh setup  \n",
    "- å‡†å¤‡æ•°æ®: ./ml_workflow.sh data\n",
    "- æäº¤è®­ç»ƒ: ./ml_workflow.sh train\n",
    "- ç›‘æ§è®­ç»ƒ: ./ml_workflow.sh monitor\n",
    "- ä¸‹è½½ç»“æœ: ./ml_workflow.sh download\n",
    "- æ¸…ç†æ–‡ä»¶: ./ml_workflow.sh cleanup\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe14d9",
   "metadata": {},
   "source": [
    "## 10. æ€»ç»“ä¸è¿›é˜¶å­¦ä¹ \n",
    "\n",
    "### 10.1 æ ¸å¿ƒè¦ç‚¹å›é¡¾\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬å­¦ä¹ äº†æœåŠ¡å™¨ä½¿ç”¨çš„å…¨æ–¹ä½æŠ€èƒ½ï¼š\n",
    "\n",
    "âœ… **SSHè¿æ¥ç®¡ç†**ï¼šé…ç½®æ–‡ä»¶ã€å¯†é’¥è®¤è¯ã€è¿æ¥ä¿æŒ\n",
    "âœ… **æ–‡ä»¶ä¼ è¾“ä¼˜åŒ–**ï¼šscpã€rsyncã€å¢é‡åŒæ­¥ã€æ’é™¤æ¨¡å¼\n",
    "âœ… **ç¯å¢ƒé…ç½®**ï¼šCondaç¯å¢ƒç®¡ç†ã€åŒ…ä¾èµ–ã€GPUé…ç½®\n",
    "âœ… **ä»»åŠ¡ç®¡ç†**ï¼šscreenã€tmuxã€nohupã€åå°è¿è¡Œ\n",
    "âœ… **SLURMç³»ç»Ÿ**ï¼šä½œä¸šæäº¤ã€èµ„æºç”³è¯·ã€é˜Ÿåˆ—ç®¡ç†\n",
    "âœ… **ç›‘æ§å’Œè°ƒè¯•**ï¼šèµ„æºç›‘æ§ã€æ—¥å¿—ç®¡ç†ã€æ•…éšœæ’é™¤\n",
    "âœ… **å®Œæ•´å·¥ä½œæµ**ï¼šé¡¹ç›®è‡ªåŠ¨åŒ–ã€è„šæœ¬ç®¡ç†ã€æœ€ä½³å®è·µ\n",
    "\n",
    "### 10.2 æœåŠ¡å™¨ä½¿ç”¨æŠ€èƒ½å¯¹æ¯”\n",
    "\n",
    "| æŠ€èƒ½ç­‰çº§ | åŸºç¡€æŠ€èƒ½ | è¿›é˜¶æŠ€èƒ½ | ä¸“å®¶æŠ€èƒ½ |\n",
    "|----------|----------|----------|----------|\n",
    "| **è¿æ¥** | SSHåŸºæœ¬è¿æ¥ | é…ç½®æ–‡ä»¶ã€å¯†é’¥ç®¡ç† | è·³æ¿æœºã€ç«¯å£è½¬å‘ |\n",
    "| **æ–‡ä»¶** | scpåŸºæœ¬ä¼ è¾“ | rsyncå¢é‡åŒæ­¥ | å¹¶è¡Œä¼ è¾“ã€å‹ç¼©ä¼˜åŒ– |\n",
    "| **ç¯å¢ƒ** | åŸºæœ¬åŒ…å®‰è£… | è™šæ‹Ÿç¯å¢ƒç®¡ç† | å®¹å™¨åŒ–ã€ç¯å¢ƒéš”ç¦» |\n",
    "| **ä»»åŠ¡** | å‘½ä»¤è¡Œè¿è¡Œ | åå°ä»»åŠ¡ç®¡ç† | ä½œä¸šè°ƒåº¦ã€èµ„æºä¼˜åŒ– |\n",
    "| **ç›‘æ§** | åŸºæœ¬çŠ¶æ€æŸ¥çœ‹ | å®æ—¶ç›‘æ§è„šæœ¬ | è‡ªåŠ¨åŒ–å‘Šè­¦ã€æ€§èƒ½åˆ†æ |\n",
    "\n",
    "### 10.3 è¿›é˜¶å­¦ä¹ æ–¹å‘\n",
    "\n",
    "1. **å®¹å™¨æŠ€æœ¯**ï¼š\n",
    "   - Docker å®¹å™¨åŒ–éƒ¨ç½²\n",
    "   - Singularity é›†ç¾¤å®¹å™¨\n",
    "   - Kubernetes ç¼–æ’\n",
    "\n",
    "2. **è‡ªåŠ¨åŒ–å·¥å…·**ï¼š\n",
    "   - Ansible é…ç½®ç®¡ç†\n",
    "   - Jenkins CI/CD\n",
    "   - GitHub Actions\n",
    "\n",
    "3. **ç›‘æ§ç³»ç»Ÿ**ï¼š\n",
    "   - Prometheus + Grafana\n",
    "   - ELK Stack (æ—¥å¿—åˆ†æ)\n",
    "   - è‡ªå®šä¹‰ç›‘æ§å‘Šè­¦\n",
    "\n",
    "4. **é«˜çº§ç½‘ç»œ**ï¼š\n",
    "   - VPN å’Œéš§é“æŠ€æœ¯\n",
    "   - è´Ÿè½½å‡è¡¡\n",
    "   - åˆ†å¸ƒå¼å­˜å‚¨\n",
    "\n",
    "### 10.4 æ¨èèµ„æº\n",
    "\n",
    "- **å®˜æ–¹æ–‡æ¡£**ï¼š\n",
    "  - [SSH å®˜æ–¹æ‰‹å†Œ](https://man.openbsd.org/ssh)\n",
    "  - [SLURM æ–‡æ¡£](https://slurm.schedmd.com/documentation.html)\n",
    "  - [GNU Screen ç”¨æˆ·æ‰‹å†Œ](https://www.gnu.org/software/screen/manual/)\n",
    "\n",
    "- **å®ç”¨å·¥å…·**ï¼š\n",
    "  - [tmux é€ŸæŸ¥è¡¨](https://tmuxcheatsheet.com/)\n",
    "  - [rsync è¯¦ç»†æ•™ç¨‹](https://rsync.samba.org/)\n",
    "  - [htop ç³»ç»Ÿç›‘æ§](https://htop.dev/)\n",
    "\n",
    "- **æœ€ä½³å®è·µ**ï¼š\n",
    "  - [é«˜æ€§èƒ½è®¡ç®—æœ€ä½³å®è·µ](https://hpc-wiki.info/)\n",
    "  - [Linux æœåŠ¡å™¨ç®¡ç†æŒ‡å—](https://linuxhandbook.com/)\n",
    "  - [Shell è„šæœ¬ç¼–ç¨‹æŒ‡å—](https://tldp.org/LDP/Bash-Beginners-Guide/html/)\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†æœåŠ¡å™¨å·¥ä½œæµæ•™ç¨‹ï¼ğŸ‰\n",
    "\n",
    "ç°åœ¨ä½ å·²ç»å…·å¤‡äº†åœ¨æœåŠ¡å™¨ä¸Šé«˜æ•ˆè¿›è¡Œæœºå™¨å­¦ä¹ ç ”ç©¶çš„æŠ€èƒ½ã€‚è®°ä½ï¼š\n",
    "- ğŸ”§ **è‡ªåŠ¨åŒ–ä¸€åˆ‡**ï¼šèƒ½è„šæœ¬åŒ–çš„å°±ä¸è¦æ‰‹åŠ¨æ“ä½œ\n",
    "- ğŸ“Š **ç›‘æ§ä¸ºç‹**ï¼šæ—¶åˆ»äº†è§£ç³»ç»Ÿå’Œä»»åŠ¡çŠ¶æ€  \n",
    "- ğŸ”’ **å®‰å…¨ç¬¬ä¸€**ï¼šä¿æŠ¤å¥½ä½ çš„æœåŠ¡å™¨è®¿é—®å‡­è¯\n",
    "- ğŸ“ **æ–‡æ¡£è®°å½•**ï¼šè®°å½•ä½ çš„é…ç½®å’Œå·¥ä½œæµç¨‹\n",
    "- ğŸ¤ **å›¢é˜Ÿåä½œ**ï¼šä¸å›¢é˜Ÿæˆå‘˜åˆ†äº«æœ€ä½³å®è·µ\n",
    "\n",
    "ç¥ä½ åœ¨æœåŠ¡å™¨ä¸Šçš„æœºå™¨å­¦ä¹ ç ”ç©¶å–å¾—æˆåŠŸï¼ğŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
