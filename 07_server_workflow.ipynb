{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85849f6",
   "metadata": {},
   "source": [
    "# 服务器使用和工作流\n",
    "\n",
    "本教程介绍如何在服务器上运行机器学习代码，包括私有集群和使用SLURM的公共集群。\n",
    "\n",
    "## 内容概览\n",
    "1. 服务器连接和基本操作\n",
    "2. 文件传输（上传/下载）\n",
    "3. 环境配置和包管理\n",
    "4. 任务提交和监控\n",
    "5. SLURM作业调度系统\n",
    "6. 最佳实践和常见问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2536c03",
   "metadata": {},
   "source": [
    "## 1. 服务器连接\n",
    "\n",
    "### SSH连接\n",
    "```bash\n",
    "# 基本连接\n",
    "ssh username@server_address\n",
    "\n",
    "# 指定端口\n",
    "ssh -p 2222 username@server_address\n",
    "\n",
    "# 使用密钥连接\n",
    "ssh -i ~/.ssh/private_key username@server_address\n",
    "\n",
    "# 保持连接活跃\n",
    "ssh -o ServerAliveInterval=60 username@server_address\n",
    "```\n",
    "\n",
    "### 配置SSH免密登录\n",
    "```bash\n",
    "# 1. 生成SSH密钥对\n",
    "ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n",
    "\n",
    "# 2. 复制公钥到服务器\n",
    "ssh-copy-id username@server_address\n",
    "\n",
    "# 3. 或手动添加\n",
    "cat ~/.ssh/id_rsa.pub | ssh username@server_address \"mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56d8a7",
   "metadata": {},
   "source": [
    "## 2. 文件传输\n",
    "\n",
    "### SCP命令\n",
    "```bash\n",
    "# 上传文件\n",
    "scp local_file.py username@server:/remote/path/\n",
    "\n",
    "# 上传文件夹\n",
    "scp -r local_folder/ username@server:/remote/path/\n",
    "\n",
    "# 下载文件\n",
    "scp username@server:/remote/file.py ./local_path/\n",
    "\n",
    "# 下载文件夹\n",
    "scp -r username@server:/remote/folder/ ./local_path/\n",
    "```\n",
    "\n",
    "### Rsync同步\n",
    "```bash\n",
    "# 增量同步（推荐）\n",
    "rsync -avz --progress local_folder/ username@server:/remote/path/\n",
    "\n",
    "# 排除特定文件\n",
    "rsync -avz --exclude='*.log' --exclude='__pycache__' local_folder/ username@server:/remote/path/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 服务器环境检查脚本\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def check_server_environment():\n",
    "    \"\"\"检查服务器环境信息\"\"\"\n",
    "    print(\"=== 服务器环境信息 ===\")\n",
    "    \n",
    "    # 系统信息\n",
    "    print(f\"操作系统: {os.uname().sysname} {os.uname().release}\")\n",
    "    print(f\"主机名: {os.uname().nodename}\")\n",
    "    print(f\"Python版本: {sys.version}\")\n",
    "    \n",
    "    # 硬件信息\n",
    "    print(f\"CPU核心数: {psutil.cpu_count()}\")\n",
    "    print(f\"内存总量: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "    print(f\"可用内存: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "    \n",
    "    # GPU信息\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.used', '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"GPU信息:\")\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                print(f\"  {line}\")\n",
    "        else:\n",
    "            print(\"未检测到GPU或nvidia-smi不可用\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi命令未找到\")\n",
    "    \n",
    "    # 磁盘使用情况\n",
    "    disk_usage = psutil.disk_usage('/')\n",
    "    print(f\"磁盘使用: {disk_usage.used / (1024**3):.1f} GB / {disk_usage.total / (1024**3):.1f} GB\")\n",
    "    \n",
    "    # 环境变量\n",
    "    important_vars = ['CUDA_VISIBLE_DEVICES', 'PATH', 'PYTHONPATH']\n",
    "    print(\"\\n重要环境变量:\")\n",
    "    for var in important_vars:\n",
    "        value = os.environ.get(var, '未设置')\n",
    "        print(f\"  {var}: {value[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
    "\n",
    "# 运行检查\n",
    "check_server_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50618a",
   "metadata": {},
   "source": [
    "## 3. SSH连接管理和配置\n",
    "\n",
    "### 3.1 SSH配置文件\n",
    "\n",
    "创建 `~/.ssh/config` 文件来简化连接管理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "def create_ssh_config():\n",
    "    \"\"\"创建SSH配置文件示例\"\"\"\n",
    "    \n",
    "    ssh_config_content = \"\"\"\n",
    "# ~/.ssh/config 示例文件\n",
    "\n",
    "# 私有集群服务器\n",
    "Host gpu-server1\n",
    "    HostName 192.168.1.100\n",
    "    User your_username\n",
    "    Port 22\n",
    "    IdentityFile ~/.ssh/id_rsa\n",
    "    ServerAliveInterval 60\n",
    "    ServerAliveCountMax 3\n",
    "    \n",
    "Host gpu-server2\n",
    "    HostName gpu2.university.edu\n",
    "    User research_account\n",
    "    Port 2222\n",
    "    IdentityFile ~/.ssh/gpu_server_key\n",
    "    ServerAliveInterval 60\n",
    "    \n",
    "# 公共集群（SLURM）\n",
    "Host hpc-cluster\n",
    "    HostName login.hpc.university.edu\n",
    "    User student_id\n",
    "    Port 22\n",
    "    IdentityFile ~/.ssh/hpc_key\n",
    "    ServerAliveInterval 120\n",
    "    \n",
    "# 跳板机配置\n",
    "Host internal-server\n",
    "    HostName 10.0.0.50\n",
    "    User admin\n",
    "    ProxyJump gateway-server\n",
    "    \n",
    "Host gateway-server\n",
    "    HostName gateway.company.com\n",
    "    User gateway_user\n",
    "    Port 2222\n",
    "\n",
    "# 通用设置\n",
    "Host *\n",
    "    UseKeychain yes\n",
    "    AddKeysToAgent yes\n",
    "    Compression yes\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"SSH配置文件示例：\")\n",
    "    print(ssh_config_content)\n",
    "    \n",
    "    print(\"\\n🔧 使用方法：\")\n",
    "    print(\"1. 复制上述内容到 ~/.ssh/config\")\n",
    "    print(\"2. 修改相应的主机名、用户名和密钥路径\")\n",
    "    print(\"3. 然后就可以直接使用: ssh gpu-server1\")\n",
    "\n",
    "def test_ssh_connection(host_alias):\n",
    "    \"\"\"测试SSH连接\"\"\"\n",
    "    try:\n",
    "        print(f\"🔄 测试连接到 {host_alias}...\")\n",
    "        \n",
    "        # 测试连接（不执行命令，只测试连通性）\n",
    "        result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=10', '-o', 'BatchMode=yes', \n",
    "             host_alias, 'echo \"Connection successful\"'],\n",
    "            capture_output=True, text=True, timeout=15\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"✅ 成功连接到 {host_alias}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ 连接失败: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"⏱️ 连接超时: {host_alias}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 连接错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def generate_ssh_key():\n",
    "    \"\"\"生成SSH密钥对\"\"\"\n",
    "    print(\"🔑 SSH密钥生成指南：\")\n",
    "    \n",
    "    commands = [\n",
    "        \"# 1. 生成RSA密钥对（推荐4096位）\",\n",
    "        \"ssh-keygen -t rsa -b 4096 -C 'your_email@example.com'\",\n",
    "        \"\",\n",
    "        \"# 2. 生成ED25519密钥对（更安全，推荐）\",\n",
    "        \"ssh-keygen -t ed25519 -C 'your_email@example.com'\",\n",
    "        \"\",\n",
    "        \"# 3. 为特定服务器生成专用密钥\",\n",
    "        \"ssh-keygen -t rsa -b 4096 -f ~/.ssh/gpu_server_key -C 'gpu_server_access'\",\n",
    "        \"\",\n",
    "        \"# 4. 复制公钥到服务器\",\n",
    "        \"ssh-copy-id -i ~/.ssh/id_rsa.pub username@server_address\",\n",
    "        \"\",\n",
    "        \"# 5. 手动复制公钥（如果ssh-copy-id不可用）\",\n",
    "        \"cat ~/.ssh/id_rsa.pub | ssh username@server 'mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys'\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        print(cmd)\n",
    "\n",
    "# 运行示例\n",
    "create_ssh_config()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "generate_ssh_key()\n",
    "\n",
    "# 注意：实际测试连接需要真实的服务器配置\n",
    "# test_ssh_connection(\"gpu-server1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d307",
   "metadata": {},
   "source": [
    "## 4. 高效文件传输\n",
    "\n",
    "### 4.1 文件传输工具对比\n",
    "\n",
    "| 工具 | 特点 | 适用场景 | 命令示例 |\n",
    "|------|------|----------|----------|\n",
    "| `scp` | 简单直接 | 小文件，一次性传输 | `scp file.py user@server:/path/` |\n",
    "| `rsync` | 增量同步，断点续传 | 大文件，频繁同步 | `rsync -avz --progress local/ user@server:/path/` |\n",
    "| `sftp` | 交互式文件管理 | 文件浏览和管理 | `sftp user@server` |\n",
    "| `git` | 版本控制 | 代码同步 | `git push/pull` |\n",
    "\n",
    "### 4.2 文件传输最佳实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "class FileTransferManager:\n",
    "    \"\"\"文件传输管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, server_config):\n",
    "        self.server_config = server_config\n",
    "        \n",
    "    def generate_rsync_command(self, local_path, remote_path, \n",
    "                              exclude_patterns=None, dry_run=False):\n",
    "        \"\"\"生成rsync命令\"\"\"\n",
    "        if exclude_patterns is None:\n",
    "            exclude_patterns = [\n",
    "                '*.pyc', '__pycache__/', '*.log', '.git/', \n",
    "                '.vscode/', '.idea/', '*.DS_Store', '*.tmp'\n",
    "            ]\n",
    "        \n",
    "        # 基础命令\n",
    "        cmd = ['rsync', '-avz', '--progress']\n",
    "        \n",
    "        # 添加排除模式\n",
    "        for pattern in exclude_patterns:\n",
    "            cmd.extend(['--exclude', pattern])\n",
    "        \n",
    "        # 干运行模式\n",
    "        if dry_run:\n",
    "            cmd.append('--dry-run')\n",
    "        \n",
    "        # 添加路径\n",
    "        cmd.append(local_path)\n",
    "        cmd.append(f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}\")\n",
    "        \n",
    "        return cmd\n",
    "    \n",
    "    def upload_project(self, project_path, remote_base_path, dry_run=True):\n",
    "        \"\"\"上传项目到服务器\"\"\"\n",
    "        print(f\"📤 准备上传项目: {project_path}\")\n",
    "        print(f\"🎯 目标路径: {remote_base_path}\")\n",
    "        \n",
    "        # 生成命令\n",
    "        cmd = self.generate_rsync_command(\n",
    "            f\"{project_path}/\", remote_base_path, dry_run=dry_run\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n🔧 执行命令:\")\n",
    "        print(\" \".join(cmd))\n",
    "        \n",
    "        if dry_run:\n",
    "            print(\"\\n⚠️  这是干运行模式，实际不会传输文件\")\n",
    "            print(\"   移除 dry_run=True 参数来执行实际传输\")\n",
    "        \n",
    "        return cmd\n",
    "    \n",
    "    def download_results(self, remote_path, local_path, patterns=None):\n",
    "        \"\"\"下载结果文件\"\"\"\n",
    "        if patterns is None:\n",
    "            patterns = ['*.pth', '*.pkl', '*.json', '*.png', '*.jpg', '*.log']\n",
    "        \n",
    "        print(f\"📥 下载结果文件...\")\n",
    "        \n",
    "        commands = []\n",
    "        for pattern in patterns:\n",
    "            cmd = [\n",
    "                'rsync', '-avz', '--progress',\n",
    "                f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}/{pattern}\",\n",
    "                local_path\n",
    "            ]\n",
    "            commands.append(cmd)\n",
    "        \n",
    "        return commands\n",
    "    \n",
    "    def sync_code_only(self, local_path, remote_path, dry_run=True):\n",
    "        \"\"\"只同步代码文件\"\"\"\n",
    "        code_patterns = ['*.py', '*.ipynb', '*.yml', '*.yaml', '*.json', '*.txt', '*.md']\n",
    "        \n",
    "        cmd = ['rsync', '-avz', '--progress']\n",
    "        \n",
    "        # 只包含代码文件\n",
    "        for pattern in code_patterns:\n",
    "            cmd.extend(['--include', pattern])\n",
    "        \n",
    "        cmd.extend(['--include', '*/'])  # 包含目录\n",
    "        cmd.append('--exclude=*')  # 排除其他所有文件\n",
    "        \n",
    "        if dry_run:\n",
    "            cmd.append('--dry-run')\n",
    "            \n",
    "        cmd.append(f\"{local_path}/\")\n",
    "        cmd.append(f\"{self.server_config['user']}@{self.server_config['host']}:{remote_path}\")\n",
    "        \n",
    "        return cmd\n",
    "\n",
    "def create_transfer_script():\n",
    "    \"\"\"创建文件传输脚本\"\"\"\n",
    "    \n",
    "    script_content = '''#!/bin/bash\n",
    "# 文件传输脚本 - transfer.sh\n",
    "\n",
    "# 配置\n",
    "SERVER_USER=\"your_username\"\n",
    "SERVER_HOST=\"gpu-server1\"\n",
    "LOCAL_PROJECT_PATH=\"./my_ml_project\"\n",
    "REMOTE_BASE_PATH=\"/home/$SERVER_USER/projects\"\n",
    "\n",
    "# 颜色输出\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "NC='\\\\033[0m' # No Color\n",
    "\n",
    "echo_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }\n",
    "echo_warn() { echo -e \"${YELLOW}[WARN]${NC} $1\"; }\n",
    "echo_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }\n",
    "\n",
    "# 函数：上传项目\n",
    "upload_project() {\n",
    "    echo_info \"开始上传项目...\"\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        --exclude='*.pyc' \\\\\n",
    "        --exclude='__pycache__/' \\\\\n",
    "        --exclude='*.log' \\\\\n",
    "        --exclude='.git/' \\\\\n",
    "        --exclude='*.DS_Store' \\\\\n",
    "        --exclude='data/raw/' \\\\\n",
    "        --exclude='checkpoints/' \\\\\n",
    "        \"$LOCAL_PROJECT_PATH/\" \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)/\"\n",
    "    \n",
    "    if [ $? -eq 0 ]; then\n",
    "        echo_info \"项目上传完成!\"\n",
    "    else\n",
    "        echo_error \"项目上传失败!\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 函数：下载结果\n",
    "download_results() {\n",
    "    echo_info \"下载结果文件...\"\n",
    "    \n",
    "    local remote_project=\"$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)\"\n",
    "    local local_results=\"./results/$(date +%Y%m%d_%H%M%S)\"\n",
    "    \n",
    "    mkdir -p \"$local_results\"\n",
    "    \n",
    "    # 下载模型文件\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/checkpoints/\" \\\\\n",
    "        \"$local_results/checkpoints/\" 2>/dev/null || echo_warn \"没有找到checkpoints目录\"\n",
    "    \n",
    "    # 下载日志文件\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/logs/\" \\\\\n",
    "        \"$local_results/logs/\" 2>/dev/null || echo_warn \"没有找到logs目录\"\n",
    "    \n",
    "    # 下载结果图像\n",
    "    rsync -avz --progress \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$remote_project/*.png\" \\\\\n",
    "        \"$local_results/\" 2>/dev/null || echo_warn \"没有找到PNG文件\"\n",
    "        \n",
    "    echo_info \"结果已下载到: $local_results\"\n",
    "}\n",
    "\n",
    "# 函数：快速同步代码\n",
    "sync_code() {\n",
    "    echo_info \"快速同步代码文件...\"\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        --include='*.py' \\\\\n",
    "        --include='*.ipynb' \\\\\n",
    "        --include='*.yml' \\\\\n",
    "        --include='*.yaml' \\\\\n",
    "        --include='*.json' \\\\\n",
    "        --include='*.txt' \\\\\n",
    "        --include='*.md' \\\\\n",
    "        --include='*/' \\\\\n",
    "        --exclude='*' \\\\\n",
    "        \"$LOCAL_PROJECT_PATH/\" \\\\\n",
    "        \"$SERVER_USER@$SERVER_HOST:$REMOTE_BASE_PATH/$(basename $LOCAL_PROJECT_PATH)/\"\n",
    "    \n",
    "    echo_info \"代码同步完成!\"\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"upload\"|\"up\")\n",
    "        upload_project\n",
    "        ;;\n",
    "    \"download\"|\"down\")\n",
    "        download_results\n",
    "        ;;\n",
    "    \"sync\")\n",
    "        sync_code\n",
    "        ;;\n",
    "    \"all\")\n",
    "        upload_project\n",
    "        echo_info \"项目上传完成，现在可以在服务器上运行训练\"\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {upload|download|sync|all}\"\n",
    "        echo \"  upload/up   - 上传完整项目\"\n",
    "        echo \"  download/down - 下载结果文件\"\n",
    "        echo \"  sync        - 快速同步代码\"\n",
    "        echo \"  all         - 上传项目\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "'''\n",
    "    \n",
    "    print(\"📝 文件传输脚本 (transfer.sh):\")\n",
    "    print(script_content)\n",
    "    \n",
    "    print(\"\\n🔧 使用方法:\")\n",
    "    print(\"1. 保存上述内容为 transfer.sh\")\n",
    "    print(\"2. chmod +x transfer.sh\")\n",
    "    print(\"3. 修改脚本中的服务器配置\")\n",
    "    print(\"4. ./transfer.sh upload  # 上传项目\")\n",
    "    print(\"5. ./transfer.sh download  # 下载结果\")\n",
    "\n",
    "# 示例配置\n",
    "server_config = {\n",
    "    'user': 'your_username',\n",
    "    'host': 'gpu-server1',\n",
    "    'port': 22\n",
    "}\n",
    "\n",
    "# 创建传输管理器\n",
    "transfer_manager = FileTransferManager(server_config)\n",
    "\n",
    "# 演示各种传输命令\n",
    "print(\"📋 文件传输命令示例:\\n\")\n",
    "\n",
    "# 1. 上传项目\n",
    "cmd = transfer_manager.upload_project(\"./my_ml_project\", \"/home/user/projects\", dry_run=True)\n",
    "print()\n",
    "\n",
    "# 2. 下载结果\n",
    "cmds = transfer_manager.download_results(\"/home/user/projects/my_ml_project\", \"./results\")\n",
    "print(\"📥 下载结果命令:\")\n",
    "for i, cmd in enumerate(cmds, 1):\n",
    "    print(f\"{i}. {' '.join(cmd)}\")\n",
    "print()\n",
    "\n",
    "# 3. 代码同步\n",
    "cmd = transfer_manager.sync_code_only(\"./my_ml_project\", \"/home/user/projects/my_ml_project\")\n",
    "print(\"🔄 代码同步命令:\")\n",
    "print(\" \".join(cmd))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "create_transfer_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebc9ad",
   "metadata": {},
   "source": [
    "## 5. 服务器环境配置\n",
    "\n",
    "### 5.1 虚拟环境管理\n",
    "\n",
    "在服务器上管理Python环境是关键技能，特别是在共享服务器上：\n",
    "\n",
    "### 5.2 Conda环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862792ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerEnvironmentManager:\n",
    "    \"\"\"服务器环境管理器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conda_envs = []\n",
    "        self.system_info = {}\n",
    "    \n",
    "    def generate_conda_setup_script(self, env_name=\"ml_research\"):\n",
    "        \"\"\"生成Conda环境设置脚本\"\"\"\n",
    "        \n",
    "        script = f\"\"\"\n",
    "#!/bin/bash\n",
    "# Conda环境设置脚本 - setup_env.sh\n",
    "\n",
    "ENV_NAME=\"{env_name}\"\n",
    "\n",
    "echo \"🐍 创建Conda环境: $ENV_NAME\"\n",
    "\n",
    "# 1. 创建新环境\n",
    "conda create -n $ENV_NAME python=3.9 -y\n",
    "\n",
    "# 2. 激活环境\n",
    "source activate $ENV_NAME\n",
    "# 或者使用: conda activate $ENV_NAME\n",
    "\n",
    "# 3. 安装基础包\n",
    "echo \"📦 安装基础科学计算包...\"\n",
    "conda install numpy pandas matplotlib seaborn jupyter -y\n",
    "conda install scikit-learn -y\n",
    "\n",
    "# 4. 安装深度学习框架\n",
    "echo \"🤖 安装PyTorch...\"\n",
    "# CPU版本\n",
    "# conda install pytorch torchvision torchaudio cpuonly -c pytorch -y\n",
    "\n",
    "# GPU版本 (根据CUDA版本选择)\n",
    "# CUDA 11.8\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "\n",
    "# CUDA 12.1\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "\n",
    "# 5. 安装其他常用包\n",
    "echo \"🔧 安装其他工具包...\"\n",
    "pip install tensorboard\n",
    "pip install tqdm\n",
    "pip install wandb  # 实验跟踪\n",
    "pip install hydra-core  # 配置管理\n",
    "pip install black flake8  # 代码格式化\n",
    "\n",
    "# 6. 验证安装\n",
    "echo \"✅ 验证安装...\"\n",
    "python -c \"import torch; print(f'PyTorch版本: {{torch.__version__}}'); print(f'CUDA可用: {{torch.cuda.is_available()}}')\"\n",
    "\n",
    "# 7. 保存环境配置\n",
    "conda env export > environment.yml\n",
    "echo \"💾 环境配置已保存到 environment.yml\"\n",
    "\n",
    "echo \"🎉 环境设置完成!\"\n",
    "echo \"📝 使用方法:\"\n",
    "echo \"   conda activate $ENV_NAME\"\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def generate_requirements_script(self):\n",
    "        \"\"\"生成requirements.txt管理脚本\"\"\"\n",
    "        \n",
    "        script = \"\"\"\n",
    "#!/bin/bash\n",
    "# Python包管理脚本 - manage_packages.sh\n",
    "\n",
    "# 函数：导出当前环境\n",
    "export_env() {\n",
    "    echo \"📋 导出当前环境到 requirements.txt...\"\n",
    "    pip freeze > requirements.txt\n",
    "    echo \"✅ 导出完成: requirements.txt\"\n",
    "    \n",
    "    echo \"📋 导出Conda环境...\"\n",
    "    conda env export > environment.yml\n",
    "    echo \"✅ 导出完成: environment.yml\"\n",
    "}\n",
    "\n",
    "# 函数：从requirements.txt安装\n",
    "install_from_requirements() {\n",
    "    if [ -f \"requirements.txt\" ]; then\n",
    "        echo \"📦 从 requirements.txt 安装包...\"\n",
    "        pip install -r requirements.txt\n",
    "        echo \"✅ 安装完成!\"\n",
    "    else\n",
    "        echo \"❌ requirements.txt 文件不存在\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 函数：从environment.yml创建环境\n",
    "create_from_yml() {\n",
    "    if [ -f \"environment.yml\" ]; then\n",
    "        echo \"🐍 从 environment.yml 创建环境...\"\n",
    "        conda env create -f environment.yml\n",
    "        echo \"✅ 环境创建完成!\"\n",
    "    else\n",
    "        echo \"❌ environment.yml 文件不存在\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 函数：更新环境\n",
    "update_env() {\n",
    "    echo \"🔄 更新Conda环境...\"\n",
    "    conda update --all -y\n",
    "    \n",
    "    echo \"🔄 更新pip包...\"\n",
    "    pip list --outdated --format=json | jq -r '.[] | .name' | xargs -I {} pip install --upgrade {}\n",
    "    \n",
    "    echo \"✅ 环境更新完成!\"\n",
    "}\n",
    "\n",
    "# 函数：清理环境\n",
    "clean_env() {\n",
    "    echo \"🧹 清理Conda缓存...\"\n",
    "    conda clean --all -y\n",
    "    \n",
    "    echo \"🧹 清理pip缓存...\"\n",
    "    pip cache purge\n",
    "    \n",
    "    echo \"✅ 清理完成!\"\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"export\")\n",
    "        export_env\n",
    "        ;;\n",
    "    \"install\")\n",
    "        install_from_requirements\n",
    "        ;;\n",
    "    \"create\")\n",
    "        create_from_yml\n",
    "        ;;\n",
    "    \"update\")\n",
    "        update_env\n",
    "        ;;\n",
    "    \"clean\")\n",
    "        clean_env\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {export|install|create|update|clean}\"\n",
    "        echo \"  export  - 导出当前环境\"\n",
    "        echo \"  install - 从requirements.txt安装\"\n",
    "        echo \"  create  - 从environment.yml创建环境\"\n",
    "        echo \"  update  - 更新所有包\"\n",
    "        echo \"  clean   - 清理缓存\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def check_gpu_environment(self):\n",
    "        \"\"\"检查GPU环境配置\"\"\"\n",
    "        \n",
    "        check_commands = {\n",
    "            \"NVIDIA驱动\": \"nvidia-smi\",\n",
    "            \"CUDA版本\": \"nvcc --version\",\n",
    "            \"PyTorch GPU\": \"python -c 'import torch; print(torch.cuda.is_available())'\",\n",
    "            \"GPU数量\": \"python -c 'import torch; print(torch.cuda.device_count())'\",\n",
    "            \"GPU名称\": \"python -c 'import torch; print([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])'\"\n",
    "        }\n",
    "        \n",
    "        print(\"🔍 GPU环境检查命令:\")\n",
    "        for desc, cmd in check_commands.items():\n",
    "            print(f\"  {desc}: {cmd}\")\n",
    "        \n",
    "        return check_commands\n",
    "    \n",
    "    def generate_bashrc_config(self):\n",
    "        \"\"\"生成.bashrc配置\"\"\"\n",
    "        \n",
    "        bashrc_content = \"\"\"\n",
    "# 添加到 ~/.bashrc 的内容\n",
    "\n",
    "# Conda配置\n",
    "export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "# 或者如果使用Anaconda\n",
    "# export PATH=\"$HOME/anaconda3/bin:$PATH\"\n",
    "\n",
    "# CUDA配置 (根据实际CUDA安装路径修改)\n",
    "export CUDA_HOME=/usr/local/cuda\n",
    "export PATH=$CUDA_HOME/bin:$PATH\n",
    "export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n",
    "\n",
    "# Python配置\n",
    "export PYTHONPATH=$HOME/projects:$PYTHONPATH\n",
    "\n",
    "# 别名设置\n",
    "alias ll='ls -alF'\n",
    "alias la='ls -A'\n",
    "alias l='ls -CF'\n",
    "alias grep='grep --color=auto'\n",
    "\n",
    "# GPU相关别名\n",
    "alias gpustat='nvidia-smi'\n",
    "alias gpuwatch='watch -n 1 nvidia-smi'\n",
    "alias gpufree='nvidia-smi --query-gpu=index,name,memory.free --format=csv'\n",
    "\n",
    "# Conda相关别名\n",
    "alias ca='conda activate'\n",
    "alias cda='conda deactivate'\n",
    "alias cenv='conda env list'\n",
    "\n",
    "# 项目相关\n",
    "alias projects='cd $HOME/projects'\n",
    "alias logs='cd $HOME/projects && find . -name \"*.log\" -mtime -1'\n",
    "\n",
    "# 显示系统信息\n",
    "echo \"🖥️  服务器: $(hostname)\"\n",
    "echo \"🐍 Python: $(python --version 2>&1 | head -1)\"\n",
    "if command -v nvidia-smi &> /dev/null; then\n",
    "    echo \"🎮 GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)\"\n",
    "fi\n",
    "echo \"📁 当前目录: $(pwd)\"\n",
    "\n",
    "# 自动激活默认环境 (可选)\n",
    "# conda activate ml_research\n",
    "\"\"\"\n",
    "        \n",
    "        return bashrc_content\n",
    "\n",
    "# 创建环境管理器\n",
    "env_manager = ServerEnvironmentManager()\n",
    "\n",
    "print(\"🐍 Conda环境设置脚本:\")\n",
    "print(\"=\"*60)\n",
    "conda_script = env_manager.generate_conda_setup_script(\"ml_research\")\n",
    "print(conda_script)\n",
    "\n",
    "print(\"\\n📦 包管理脚本:\")\n",
    "print(\"=\"*60)\n",
    "packages_script = env_manager.generate_requirements_script()\n",
    "print(packages_script)\n",
    "\n",
    "print(\"\\n🔍 GPU环境检查:\")\n",
    "print(\"=\"*60)\n",
    "gpu_checks = env_manager.check_gpu_environment()\n",
    "\n",
    "print(\"\\n⚙️ .bashrc配置:\")\n",
    "print(\"=\"*60)\n",
    "bashrc_config = env_manager.generate_bashrc_config()\n",
    "print(bashrc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2498c0",
   "metadata": {},
   "source": [
    "## 6. 任务提交和监控\n",
    "\n",
    "### 6.1 后台任务管理\n",
    "\n",
    "在服务器上运行长时间任务时，需要确保任务不会因为SSH连接断开而中断：\n",
    "\n",
    "### 6.2 常用任务管理工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import signal\n",
    "\n",
    "class TaskManager:\n",
    "    \"\"\"服务器任务管理器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_tasks = {}\n",
    "    \n",
    "    def generate_task_scripts(self):\n",
    "        \"\"\"生成各种任务管理脚本\"\"\"\n",
    "        \n",
    "        scripts = {}\n",
    "        \n",
    "        # 1. Screen任务脚本\n",
    "        scripts['screen_training'] = \"\"\"#!/bin/bash\n",
    "# Screen训练脚本 - train_with_screen.sh\n",
    "\n",
    "PROJECT_NAME=\"mnist_training\"\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "\n",
    "# 创建screen会话并运行训练\n",
    "screen -dmS $PROJECT_NAME bash -c \"\n",
    "    echo '🚀 开始训练任务...'\n",
    "    echo '📅 开始时间: $(date)'\n",
    "    \n",
    "    # 激活环境\n",
    "    conda activate ml_research\n",
    "    \n",
    "    # 设置GPU\n",
    "    export CUDA_VISIBLE_DEVICES=0\n",
    "    \n",
    "    # 运行训练\n",
    "    python $SCRIPT_PATH --epochs 100 --batch-size 64 > training.log 2>&1\n",
    "    \n",
    "    echo '✅ 训练完成: $(date)'\n",
    "    echo '按任意键退出...'\n",
    "    read\n",
    "\"\n",
    "\n",
    "echo \"✅ Screen会话 '$PROJECT_NAME' 已启动\"\n",
    "echo \"🔍 查看状态: screen -list\"\n",
    "echo \"🔗 连接会话: screen -r $PROJECT_NAME\"\n",
    "echo \"📋 分离会话: Ctrl+A, D\"\n",
    "\"\"\"\n",
    "\n",
    "        # 2. tmux任务脚本\n",
    "        scripts['tmux_training'] = \"\"\"#!/bin/bash\n",
    "# tmux训练脚本 - train_with_tmux.sh\n",
    "\n",
    "SESSION_NAME=\"ml_training\"\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "\n",
    "# 创建tmux会话\n",
    "tmux new-session -d -s $SESSION_NAME\n",
    "\n",
    "# 在会话中运行命令\n",
    "tmux send-keys -t $SESSION_NAME \"conda activate ml_research\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"export CUDA_VISIBLE_DEVICES=0\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"echo '🚀 开始训练: $(date)'\" C-m\n",
    "tmux send-keys -t $SESSION_NAME \"python $SCRIPT_PATH --config config.yaml\" C-m\n",
    "\n",
    "echo \"✅ tmux会话 '$SESSION_NAME' 已启动\"\n",
    "echo \"🔍 查看会话: tmux ls\"\n",
    "echo \"🔗 连接会话: tmux attach -t $SESSION_NAME\"\n",
    "echo \"📋 分离会话: Ctrl+B, D\"\n",
    "\"\"\"\n",
    "\n",
    "        # 3. nohup任务脚本\n",
    "        scripts['nohup_training'] = \"\"\"#!/bin/bash\n",
    "# nohup训练脚本 - train_with_nohup.sh\n",
    "\n",
    "SCRIPT_PATH=\"train.py\"\n",
    "LOG_FILE=\"training_$(date +%Y%m%d_%H%M%S).log\"\n",
    "\n",
    "echo \"🚀 使用nohup启动训练任务...\"\n",
    "\n",
    "# 激活环境并运行\n",
    "nohup bash -c \"\n",
    "    source activate ml_research\n",
    "    export CUDA_VISIBLE_DEVICES=0\n",
    "    python $SCRIPT_PATH --epochs 100 --batch-size 64\n",
    "\" > $LOG_FILE 2>&1 &\n",
    "\n",
    "PID=$!\n",
    "echo \"✅ 任务已启动, PID: $PID\"\n",
    "echo \"📄 日志文件: $LOG_FILE\"\n",
    "echo \"🔍 监控日志: tail -f $LOG_FILE\"\n",
    "echo \"⏹️  停止任务: kill $PID\"\n",
    "\n",
    "# 保存PID到文件\n",
    "echo $PID > training.pid\n",
    "\"\"\"\n",
    "\n",
    "        # 4. 任务监控脚本\n",
    "        scripts['monitor_tasks'] = \"\"\"#!/bin/bash\n",
    "# 任务监控脚本 - monitor.sh\n",
    "\n",
    "# 颜色定义\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "echo_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }\n",
    "echo_warn() { echo -e \"${YELLOW}[WARN]${NC} $1\"; }\n",
    "echo_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }\n",
    "\n",
    "# 显示系统资源\n",
    "show_resources() {\n",
    "    echo_info \"系统资源使用情况:\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    # CPU和内存\n",
    "    echo \"💻 CPU和内存:\"\n",
    "    top -bn1 | grep \"Cpu(s)\" | sed \"s/.*, *\\\\([0-9.]*\\\\)%* id.*/\\\\1/\" | awk '{print \"CPU使用率: \" 100-$1\"%\"}'\n",
    "    free -h | awk '/Mem:/ {print \"内存使用: \" $3 \"/\" $2 \" (\" $3/$2*100 \"%)\"}'\n",
    "    \n",
    "    # GPU\n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"🎮 GPU状态:\"\n",
    "        nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits | \\\\\n",
    "        awk -F, '{printf \"GPU%s: %s, 内存: %sMB/%sMB (%.1f%%), 利用率: %s%%\\\\n\", $1, $2, $3, $4, $3/$4*100, $5}'\n",
    "    fi\n",
    "    \n",
    "    # 磁盘\n",
    "    echo \"💾 磁盘使用:\"\n",
    "    df -h | grep -E '^/dev/' | awk '{print $6 \": \" $3 \"/\" $2 \" (\" $5 \")\"}'\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示训练进程\n",
    "show_training_processes() {\n",
    "    echo_info \"Python训练进程:\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    ps aux | grep python | grep -v grep | while read line; do\n",
    "        echo \"$line\"\n",
    "    done\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示Screen会话\n",
    "show_screen_sessions() {\n",
    "    echo_info \"Screen会话:\"\n",
    "    echo \"=========================\"\n",
    "    screen -list 2>/dev/null || echo \"没有活跃的Screen会话\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示tmux会话\n",
    "show_tmux_sessions() {\n",
    "    echo_info \"tmux会话:\"\n",
    "    echo \"=========================\"\n",
    "    tmux ls 2>/dev/null || echo \"没有活跃的tmux会话\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示最近的日志\n",
    "show_recent_logs() {\n",
    "    echo_info \"最近的训练日志 (最后10行):\"\n",
    "    echo \"=========================\"\n",
    "    \n",
    "    find . -name \"*.log\" -mtime -1 -type f | head -5 | while read logfile; do\n",
    "        echo \"📄 $logfile:\"\n",
    "        tail -3 \"$logfile\" 2>/dev/null | sed 's/^/  /'\n",
    "        echo \"\"\n",
    "    done\n",
    "}\n",
    "\n",
    "# 主监控循环\n",
    "monitor_loop() {\n",
    "    while true; do\n",
    "        clear\n",
    "        echo \"🖥️  服务器监控 - $(date)\"\n",
    "        echo \"==============================================\"\n",
    "        \n",
    "        show_resources\n",
    "        show_training_processes\n",
    "        show_screen_sessions\n",
    "        show_tmux_sessions\n",
    "        show_recent_logs\n",
    "        \n",
    "        echo \"🔄 每30秒自动刷新... (Ctrl+C 退出)\"\n",
    "        sleep 30\n",
    "    done\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"resources\"|\"res\")\n",
    "        show_resources\n",
    "        ;;\n",
    "    \"processes\"|\"proc\")\n",
    "        show_training_processes\n",
    "        ;;\n",
    "    \"sessions\"|\"sess\")\n",
    "        show_screen_sessions\n",
    "        show_tmux_sessions\n",
    "        ;;\n",
    "    \"logs\")\n",
    "        show_recent_logs\n",
    "        ;;\n",
    "    \"monitor\"|\"\")\n",
    "        monitor_loop\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {resources|processes|sessions|logs|monitor}\"\n",
    "        echo \"  resources  - 显示系统资源\"\n",
    "        echo \"  processes  - 显示训练进程\"\n",
    "        echo \"  sessions   - 显示screen/tmux会话\"\n",
    "        echo \"  logs       - 显示最近日志\"\n",
    "        echo \"  monitor    - 连续监控 (默认)\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "\n",
    "        return scripts\n",
    "    \n",
    "    def generate_gpu_management_script(self):\n",
    "        \"\"\"生成GPU管理脚本\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# GPU管理脚本 - gpu_manager.sh\n",
    "\n",
    "# 颜色定义\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "# 显示GPU状态\n",
    "show_gpu_status() {\n",
    "    echo -e \"${GREEN}🎮 GPU状态总览${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    if ! command -v nvidia-smi &> /dev/null; then\n",
    "        echo -e \"${RED}❌ nvidia-smi 命令不可用${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # 基本GPU信息\n",
    "    nvidia-smi --query-gpu=index,name,driver_version,memory.total --format=csv\n",
    "    echo \"\"\n",
    "    \n",
    "    # 详细状态\n",
    "    echo -e \"${BLUE}📊 详细状态:${NC}\"\n",
    "    nvidia-smi\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示GPU进程\n",
    "show_gpu_processes() {\n",
    "    echo -e \"${GREEN}🔍 GPU进程详情${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    nvidia-smi pmon -i 0 -c 1 2>/dev/null || {\n",
    "        echo \"使用nvidia-smi查看进程:\"\n",
    "        nvidia-smi --query-compute-apps=pid,process_name,gpu_instance_id,used_memory --format=csv\n",
    "    }\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 选择可用GPU\n",
    "select_gpu() {\n",
    "    echo -e \"${GREEN}🎯 选择GPU设备${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # 显示每个GPU的内存使用\n",
    "    nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader,nounits | \\\\\n",
    "    while IFS=, read -r idx name mem_used mem_total; do\n",
    "        usage_percent=$(echo \"scale=1; $mem_used * 100 / $mem_total\" | bc -l 2>/dev/null || echo \"0\")\n",
    "        \n",
    "        if (( $(echo \"$usage_percent < 10\" | bc -l) )); then\n",
    "            status=\"${GREEN}可用${NC}\"\n",
    "        elif (( $(echo \"$usage_percent < 50\" | bc -l) )); then\n",
    "            status=\"${YELLOW}部分占用${NC}\"\n",
    "        else\n",
    "            status=\"${RED}繁忙${NC}\"\n",
    "        fi\n",
    "        \n",
    "        echo -e \"GPU$idx: $name | 内存: ${mem_used}MB/${mem_total}MB (${usage_percent}%) | $status\"\n",
    "    done\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"💡 设置GPU使用方法:\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=0    # 使用GPU 0\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=0,1  # 使用GPU 0和1\"\n",
    "    echo \"export CUDA_VISIBLE_DEVICES=\\\"\\\"   # 不使用GPU\"\n",
    "}\n",
    "\n",
    "# 清理GPU进程\n",
    "cleanup_gpu() {\n",
    "    echo -e \"${YELLOW}⚠️  清理GPU进程${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    echo \"当前GPU进程:\"\n",
    "    nvidia-smi --query-compute-apps=pid,process_name --format=csv\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"请谨慎操作! 这将强制终止GPU进程。\"\n",
    "    read -p \"确认清理僵死进程? (y/N): \" confirm\n",
    "    \n",
    "    if [[ $confirm == [yY] ]]; then\n",
    "        # 获取GPU进程PID并询问是否终止\n",
    "        nvidia-smi --query-compute-apps=pid --format=csv,noheader | while read pid; do\n",
    "            if [[ -n \"$pid\" && \"$pid\" != \"pid\" ]]; then\n",
    "                echo \"终止进程 PID: $pid\"\n",
    "                kill -9 $pid 2>/dev/null || echo \"无法终止进程 $pid\"\n",
    "            fi\n",
    "        done\n",
    "        echo -e \"${GREEN}✅ GPU清理完成${NC}\"\n",
    "    else\n",
    "        echo \"操作已取消\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 监控GPU使用\n",
    "monitor_gpu() {\n",
    "    echo -e \"${GREEN}📈 GPU实时监控${NC}\"\n",
    "    echo \"================================\"\n",
    "    echo \"按 Ctrl+C 退出监控\"\n",
    "    echo \"\"\n",
    "    \n",
    "    # 使用watch命令实时监控\n",
    "    watch -n 2 \"nvidia-smi --query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu --format=csv,noheader | \\\\\n",
    "    awk -F, '{printf \\\"GPU%s: %s\\\\n  温度: %s°C | 功耗: %s | 内存: %sMB/%sMB | 利用率: %s%%\\\\n\\\\n\\\", \\\\$1, \\\\$2, \\\\$3, \\\\$4, \\\\$5, \\\\$6, \\\\$7}'\"\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"status\"|\"\")\n",
    "        show_gpu_status\n",
    "        ;;\n",
    "    \"processes\"|\"proc\")\n",
    "        show_gpu_processes\n",
    "        ;;\n",
    "    \"select\"|\"sel\")\n",
    "        select_gpu\n",
    "        ;;\n",
    "    \"cleanup\"|\"clean\")\n",
    "        cleanup_gpu\n",
    "        ;;\n",
    "    \"monitor\"|\"mon\")\n",
    "        monitor_gpu\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {status|processes|select|cleanup|monitor}\"\n",
    "        echo \"  status     - 显示GPU状态 (默认)\"\n",
    "        echo \"  processes  - 显示GPU进程\"\n",
    "        echo \"  select     - 选择可用GPU\"\n",
    "        echo \"  cleanup    - 清理GPU进程\"\n",
    "        echo \"  monitor    - 实时监控GPU\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# 创建任务管理器\n",
    "task_manager = TaskManager()\n",
    "\n",
    "print(\"🛠️ 任务管理脚本集合:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 生成任务脚本\n",
    "task_scripts = task_manager.generate_task_scripts()\n",
    "\n",
    "for script_name, script_content in task_scripts.items():\n",
    "    print(f\"\\n📄 {script_name}.sh:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(script_content)\n",
    "\n",
    "print(\"\\n🎮 GPU管理脚本:\")\n",
    "print(\"=\"*60)\n",
    "gpu_script = task_manager.generate_gpu_management_script()\n",
    "print(gpu_script)\n",
    "\n",
    "print(\"\\n💡 使用建议:\")\n",
    "print(\"1. 保存这些脚本到服务器\")\n",
    "print(\"2. chmod +x *.sh  # 添加执行权限\")\n",
    "print(\"3. 根据实际项目路径修改脚本\")\n",
    "print(\"4. 选择合适的任务管理工具 (screen/tmux/nohup)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34d883",
   "metadata": {},
   "source": [
    "## 7. SLURM 作业调度系统\n",
    "\n",
    "SLURM (Simple Linux Utility for Resource Management) 是很多高性能计算集群使用的作业调度系统。\n",
    "\n",
    "### 7.1 SLURM 基础概念\n",
    "\n",
    "- **节点 (Node)**: 集群中的计算机\n",
    "- **分区 (Partition)**: 节点组，类似队列\n",
    "- **作业 (Job)**: 提交的计算任务\n",
    "- **作业步 (Job Step)**: 作业中的并行任务\n",
    "\n",
    "### 7.2 常用 SLURM 命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlurmManager:\n",
    "    \"\"\"SLURM作业管理器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.common_partitions = ['gpu', 'cpu', 'highmem', 'debug']\n",
    "        \n",
    "    def generate_slurm_templates(self):\n",
    "        \"\"\"生成SLURM作业脚本模板\"\"\"\n",
    "        \n",
    "        templates = {}\n",
    "        \n",
    "        # 1. 基础GPU训练脚本\n",
    "        templates['gpu_training'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=mnist_training          # 作业名称\n",
    "#SBATCH --partition=gpu                    # 分区名称\n",
    "#SBATCH --nodes=1                          # 节点数\n",
    "#SBATCH --ntasks-per-node=1                # 每个节点的任务数\n",
    "#SBATCH --cpus-per-task=4                  # 每个任务的CPU核数\n",
    "#SBATCH --gres=gpu:1                       # GPU资源 (1块GPU)\n",
    "#SBATCH --mem=16G                          # 内存需求\n",
    "#SBATCH --time=24:00:00                    # 最大运行时间 (24小时)\n",
    "#SBATCH --output=logs/slurm_%j.out         # 标准输出文件\n",
    "#SBATCH --error=logs/slurm_%j.err          # 错误输出文件\n",
    "#SBATCH --mail-type=ALL                    # 邮件通知类型\n",
    "#SBATCH --mail-user=your_email@university.edu\n",
    "\n",
    "# 打印作业信息\n",
    "echo \"作业开始时间: $(date)\"\n",
    "echo \"作业ID: $SLURM_JOB_ID\"\n",
    "echo \"节点名称: $SLURM_NODELIST\"\n",
    "echo \"GPU设备: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "# 创建日志目录\n",
    "mkdir -p logs\n",
    "\n",
    "# 激活环境\n",
    "source ~/.bashrc\n",
    "conda activate ml_research\n",
    "\n",
    "# 设置环境变量\n",
    "export PYTHONPATH=$HOME/projects:$PYTHONPATH\n",
    "\n",
    "# 运行训练脚本\n",
    "echo \"开始训练...\"\n",
    "python train.py \\\\\n",
    "    --epochs 100 \\\\\n",
    "    --batch-size 64 \\\\\n",
    "    --learning-rate 0.001 \\\\\n",
    "    --output-dir ./outputs \\\\\n",
    "    --log-dir ./logs\n",
    "\n",
    "echo \"训练完成时间: $(date)\"\n",
    "echo \"作业结束\"\n",
    "\"\"\"\n",
    "\n",
    "        # 2. 多GPU训练脚本\n",
    "        templates['multi_gpu_training'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=multi_gpu_training\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --gres=gpu:4                       # 4块GPU\n",
    "#SBATCH --mem=32G\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --output=logs/multi_gpu_%j.out\n",
    "#SBATCH --error=logs/multi_gpu_%j.err\n",
    "\n",
    "echo \"多GPU训练作业开始: $(date)\"\n",
    "echo \"可用GPU: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "# 激活环境\n",
    "conda activate ml_research\n",
    "\n",
    "# 使用PyTorch DistributedDataParallel\n",
    "python -m torch.distributed.launch \\\\\n",
    "    --nproc_per_node=4 \\\\\n",
    "    --use_env \\\\\n",
    "    train_distributed.py \\\\\n",
    "    --epochs 100 \\\\\n",
    "    --batch-size 256 \\\\\n",
    "    --world-size 4\n",
    "\n",
    "echo \"多GPU训练完成: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        # 3. 参数扫描脚本\n",
    "        templates['hyperparameter_sweep'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=hyperparam_sweep\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --array=1-20                       # 作业数组 (20个参数组合)\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --output=logs/sweep_%A_%a.out      # %A是数组作业ID, %a是任务ID\n",
    "#SBATCH --error=logs/sweep_%A_%a.err\n",
    "\n",
    "# 参数网格\n",
    "learning_rates=(0.001 0.003 0.01 0.03)\n",
    "batch_sizes=(32 64 128 256)\n",
    "optimizers=(\"adam\" \"sgd\" \"adamw\")\n",
    "\n",
    "# 计算当前任务的参数组合\n",
    "lr_idx=$(( ($SLURM_ARRAY_TASK_ID - 1) % 4 ))\n",
    "bs_idx=$(( (($SLURM_ARRAY_TASK_ID - 1) / 4) % 4 ))\n",
    "opt_idx=$(( (($SLURM_ARRAY_TASK_ID - 1) / 16) % 3 ))\n",
    "\n",
    "LR=${learning_rates[$lr_idx]}\n",
    "BS=${batch_sizes[$bs_idx]}\n",
    "OPT=${optimizers[$opt_idx]}\n",
    "\n",
    "echo \"任务 $SLURM_ARRAY_TASK_ID: LR=$LR, BS=$BS, OPT=$OPT\"\n",
    "\n",
    "# 激活环境\n",
    "conda activate ml_research\n",
    "\n",
    "# 运行实验\n",
    "python train.py \\\\\n",
    "    --learning-rate $LR \\\\\n",
    "    --batch-size $BS \\\\\n",
    "    --optimizer $OPT \\\\\n",
    "    --experiment-name \"sweep_${SLURM_ARRAY_TASK_ID}\" \\\\\n",
    "    --output-dir \"./outputs/sweep_${SLURM_ARRAY_TASK_ID}\"\n",
    "\n",
    "echo \"实验 $SLURM_ARRAY_TASK_ID 完成: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        # 4. CPU密集型任务\n",
    "        templates['cpu_intensive'] = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=cpu_task\n",
    "#SBATCH --partition=cpu                    # CPU分区\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=16                 # 16个CPU核\n",
    "#SBATCH --mem=64G                          # 64GB内存\n",
    "#SBATCH --time=72:00:00                    # 3天\n",
    "#SBATCH --output=logs/cpu_%j.out\n",
    "#SBATCH --error=logs/cpu_%j.err\n",
    "\n",
    "echo \"CPU密集型任务开始: $(date)\"\n",
    "echo \"可用CPU核数: $SLURM_CPUS_PER_TASK\"\n",
    "\n",
    "# 激活环境\n",
    "conda activate ml_research\n",
    "\n",
    "# 设置OpenMP线程数\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# 运行CPU密集型任务 (如数据预处理)\n",
    "python preprocess_data.py \\\\\n",
    "    --num-workers $SLURM_CPUS_PER_TASK \\\\\n",
    "    --input-dir ./raw_data \\\\\n",
    "    --output-dir ./processed_data\n",
    "\n",
    "echo \"CPU任务完成: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "        return templates\n",
    "    \n",
    "    def generate_slurm_commands_reference(self):\n",
    "        \"\"\"生成SLURM命令参考\"\"\"\n",
    "        \n",
    "        commands = {\n",
    "            \"作业提交\": {\n",
    "                \"sbatch script.sh\": \"提交作业脚本\",\n",
    "                \"sbatch --dependency=afterok:12345 script.sh\": \"依赖作业12345成功后运行\",\n",
    "                \"sbatch --begin=2024-01-01T10:00:00 script.sh\": \"定时提交作业\"\n",
    "            },\n",
    "            \n",
    "            \"作业查询\": {\n",
    "                \"squeue\": \"查看所有作业队列\",\n",
    "                \"squeue -u $USER\": \"查看当前用户的作业\",\n",
    "                \"squeue -j 12345\": \"查看特定作业\",\n",
    "                \"sinfo\": \"查看分区和节点信息\",\n",
    "                \"sinfo -p gpu\": \"查看GPU分区信息\"\n",
    "            },\n",
    "            \n",
    "            \"作业控制\": {\n",
    "                \"scancel 12345\": \"取消作业12345\",\n",
    "                \"scancel -u $USER\": \"取消当前用户所有作业\",\n",
    "                \"scontrol hold 12345\": \"暂停作业\",\n",
    "                \"scontrol release 12345\": \"释放暂停的作业\"\n",
    "            },\n",
    "            \n",
    "            \"作业信息\": {\n",
    "                \"sacct\": \"查看作业历史\",\n",
    "                \"sacct -j 12345\": \"查看特定作业详情\",\n",
    "                \"sstat 12345\": \"查看运行中作业状态\",\n",
    "                \"scontrol show job 12345\": \"显示作业详细信息\"\n",
    "            },\n",
    "            \n",
    "            \"资源查询\": {\n",
    "                \"sinfo -N\": \"查看所有节点\",\n",
    "                \"sinfo -N -p gpu\": \"查看GPU节点\",\n",
    "                \"squeue -t RUNNING\": \"查看正在运行的作业\",\n",
    "                \"squeue -t PENDING\": \"查看等待中的作业\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return commands\n",
    "    \n",
    "    def generate_slurm_management_script(self):\n",
    "        \"\"\"生成SLURM作业管理脚本\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# SLURM作业管理脚本 - slurm_manager.sh\n",
    "\n",
    "# 颜色定义\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "# 显示我的作业\n",
    "show_my_jobs() {\n",
    "    echo -e \"${GREEN}📋 我的作业状态${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    squeue -u $USER --format=\"%.8i %.12j %.8u %.10T %.10M %.6D %R\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"作业状态说明:\"\n",
    "    echo \"  PD - PENDING (等待中)\"\n",
    "    echo \"  R  - RUNNING (运行中)\"\n",
    "    echo \"  CG - COMPLETING (完成中)\"\n",
    "    echo \"  CD - COMPLETED (已完成)\"\n",
    "    echo \"  F  - FAILED (失败)\"\n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示分区信息\n",
    "show_partitions() {\n",
    "    echo -e \"${GREEN}🖥️  分区和节点信息${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    sinfo --format=\"%.15P %.5a %.10l %.6D %.6t %.8C %.8G %.15N\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 显示GPU节点详情\n",
    "show_gpu_nodes() {\n",
    "    echo -e \"${GREEN}🎮 GPU节点状态${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    sinfo -N -p gpu --format=\"%.15N %.10T %.4c %.8m %.25G %.15P\" | \\\\\n",
    "    awk 'NR==1{print $0; print \"================================\"} NR>1{print $0}'\n",
    "    \n",
    "    echo \"\"\n",
    "}\n",
    "\n",
    "# 提交训练作业\n",
    "submit_training() {\n",
    "    echo -e \"${GREEN}🚀 提交训练作业${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # 检查必要文件\n",
    "    if [ ! -f \"train.py\" ]; then\n",
    "        echo -e \"${RED}❌ 找不到 train.py 文件${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # 创建日志目录\n",
    "    mkdir -p logs\n",
    "    \n",
    "    # 生成作业脚本\n",
    "    cat > submit_job.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=ml_training\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=logs/train_%j.out\n",
    "#SBATCH --error=logs/train_%j.err\n",
    "\n",
    "echo \"作业开始: $(date)\"\n",
    "echo \"节点: $SLURM_NODELIST\"\n",
    "echo \"GPU: $CUDA_VISIBLE_DEVICES\"\n",
    "\n",
    "conda activate ml_research\n",
    "python train.py\n",
    "\n",
    "echo \"作业结束: $(date)\"\n",
    "EOF\n",
    "    \n",
    "    # 提交作业\n",
    "    job_id=$(sbatch submit_job.sh | grep -o '[0-9]\\\\+')\n",
    "    \n",
    "    if [ $? -eq 0 ]; then\n",
    "        echo -e \"${GREEN}✅ 作业已提交, ID: $job_id${NC}\"\n",
    "        echo \"📄 查看输出: tail -f logs/train_${job_id}.out\"\n",
    "        echo \"❌ 查看错误: tail -f logs/train_${job_id}.err\"\n",
    "        echo \"⏹️  取消作业: scancel $job_id\"\n",
    "    else\n",
    "        echo -e \"${RED}❌ 作业提交失败${NC}\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 监控作业\n",
    "monitor_job() {\n",
    "    if [ $# -eq 0 ]; then\n",
    "        echo \"用法: $0 monitor <job_id>\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    job_id=$1\n",
    "    echo -e \"${GREEN}📊 监控作业 $job_id${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # 检查作业是否存在\n",
    "    if ! squeue -j $job_id &>/dev/null; then\n",
    "        echo -e \"${RED}❌ 找不到作业 $job_id${NC}\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    # 显示作业详情\n",
    "    scontrol show job $job_id | grep -E \"(JobId|JobName|JobState|RunTime|TimeLimit|NodeList)\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo -e \"${BLUE}📄 实时日志 (Ctrl+C 退出):${NC}\"\n",
    "    \n",
    "    # 查找日志文件\n",
    "    log_file=$(find logs -name \"*${job_id}.out\" 2>/dev/null | head -1)\n",
    "    if [ -n \"$log_file\" ]; then\n",
    "        tail -f \"$log_file\"\n",
    "    else\n",
    "        echo \"日志文件尚未创建...\"\n",
    "        sleep 5\n",
    "        log_file=$(find logs -name \"*${job_id}.out\" 2>/dev/null | head -1)\n",
    "        [ -n \"$log_file\" ] && tail -f \"$log_file\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 清理完成的作业\n",
    "cleanup_jobs() {\n",
    "    echo -e \"${GREEN}🧹 清理已完成的作业${NC}\"\n",
    "    echo \"================================\"\n",
    "    \n",
    "    # 显示已完成的作业\n",
    "    completed_jobs=$(sacct --format=JobID,JobName,State,ExitCode --state=COMPLETED,FAILED --starttime=now-7days --noheader | wc -l)\n",
    "    \n",
    "    echo \"最近7天内完成的作业数: $completed_jobs\"\n",
    "    \n",
    "    # 清理旧的日志文件\n",
    "    echo \"清理7天前的日志文件...\"\n",
    "    find logs -name \"*.out\" -o -name \"*.err\" -mtime +7 -delete 2>/dev/null\n",
    "    \n",
    "    echo -e \"${GREEN}✅ 清理完成${NC}\"\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"jobs\"|\"\")\n",
    "        show_my_jobs\n",
    "        ;;\n",
    "    \"partitions\"|\"part\")\n",
    "        show_partitions\n",
    "        ;;\n",
    "    \"gpu\")\n",
    "        show_gpu_nodes\n",
    "        ;;\n",
    "    \"submit\")\n",
    "        submit_training\n",
    "        ;;\n",
    "    \"monitor\"|\"mon\")\n",
    "        monitor_job $2\n",
    "        ;;\n",
    "    \"cleanup\")\n",
    "        cleanup_jobs\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {jobs|partitions|gpu|submit|monitor|cleanup}\"\n",
    "        echo \"  jobs       - 显示我的作业 (默认)\"\n",
    "        echo \"  partitions - 显示分区信息\"\n",
    "        echo \"  gpu        - 显示GPU节点\"\n",
    "        echo \"  submit     - 提交训练作业\"\n",
    "        echo \"  monitor    - 监控作业 <job_id>\"\n",
    "        echo \"  cleanup    - 清理旧作业和日志\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# 创建SLURM管理器\n",
    "slurm_manager = SlurmManager()\n",
    "\n",
    "print(\"🎯 SLURM作业脚本模板:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 生成模板\n",
    "templates = slurm_manager.generate_slurm_templates()\n",
    "for name, template in templates.items():\n",
    "    print(f\"\\n📄 {name}.slurm:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(template)\n",
    "\n",
    "print(\"\\n📚 SLURM命令参考:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 生成命令参考\n",
    "commands = slurm_manager.generate_slurm_commands_reference()\n",
    "for category, cmd_dict in commands.items():\n",
    "    print(f\"\\n📋 {category}:\")\n",
    "    print(\"-\" * 30)\n",
    "    for cmd, desc in cmd_dict.items():\n",
    "        print(f\"  {cmd:<35} # {desc}\")\n",
    "\n",
    "print(\"\\n🛠️ SLURM管理脚本:\")\n",
    "print(\"=\"*60)\n",
    "management_script = slurm_manager.generate_slurm_management_script()\n",
    "print(management_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb10384",
   "metadata": {},
   "source": [
    "## 8. 服务器工作流最佳实践\n",
    "\n",
    "### 8.1 项目组织结构\n",
    "\n",
    "在服务器上保持良好的项目组织结构非常重要：\n",
    "\n",
    "```\n",
    "~/projects/\n",
    "├── project1/\n",
    "│   ├── data/\n",
    "│   │   ├── raw/          # 原始数据\n",
    "│   │   └── processed/    # 处理后数据\n",
    "│   ├── src/              # 源代码\n",
    "│   ├── configs/          # 配置文件\n",
    "│   ├── scripts/          # 脚本文件\n",
    "│   ├── logs/             # 日志文件\n",
    "│   ├── checkpoints/      # 模型检查点\n",
    "│   ├── results/          # 结果输出\n",
    "│   └── environment.yml   # 环境配置\n",
    "└── shared_utils/         # 共享工具\n",
    "```\n",
    "\n",
    "### 8.2 数据管理策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerBestPractices:\n",
    "    \"\"\"服务器使用最佳实践指南\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.practices = {}\n",
    "        \n",
    "    def data_management_guide(self):\n",
    "        \"\"\"数据管理指南\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# 数据管理最佳实践\n",
    "\n",
    "## 1. 数据存储策略\n",
    "```bash\n",
    "# 创建规范的数据目录结构\n",
    "mkdir -p ~/data/{raw,processed,cache,backup}\n",
    "\n",
    "# 使用符号链接共享大型数据集\n",
    "ln -s /shared/datasets/imagenet ~/data/imagenet\n",
    "\n",
    "# 定期备份重要数据\n",
    "rsync -av ~/projects/important_results/ ~/backup/$(date +%Y%m%d)/\n",
    "```\n",
    "\n",
    "## 2. 数据传输优化\n",
    "```bash\n",
    "# 使用压缩传输大文件\n",
    "tar -czf - large_dataset/ | ssh server 'cd ~/data && tar -xzf -'\n",
    "\n",
    "# 断点续传大文件\n",
    "rsync -avz --partial --progress large_file.tar.gz server:~/data/\n",
    "\n",
    "# 并行传输多个文件\n",
    "find . -name \"*.txt\" | parallel -j4 scp {} server:~/data/\n",
    "```\n",
    "\n",
    "## 3. 磁盘空间管理\n",
    "```bash\n",
    "# 检查磁盘使用\n",
    "df -h\n",
    "du -sh ~/projects/*\n",
    "\n",
    "# 清理临时文件\n",
    "find ~/projects -name \"*.tmp\" -delete\n",
    "find ~/projects -name \"__pycache__\" -type d -exec rm -rf {} +\n",
    "\n",
    "# 压缩旧日志\n",
    "find ~/projects -name \"*.log\" -mtime +30 -exec gzip {} \\\\;\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def performance_optimization_guide(self):\n",
    "        \"\"\"性能优化指南\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# 性能优化最佳实践\n",
    "\n",
    "## 1. CPU优化\n",
    "```python\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置OpenMP线程数\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "# PyTorch数据加载优化\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,        # 根据CPU核心数调整\n",
    "    pin_memory=True,      # GPU训练时启用\n",
    "    persistent_workers=True  # 保持worker进程\n",
    ")\n",
    "```\n",
    "\n",
    "## 2. 内存优化\n",
    "```python\n",
    "# 梯度检查点 (节省内存)\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = checkpoint.checkpoint(self.heavy_layer, x)\n",
    "        return x\n",
    "\n",
    "# 清理GPU缓存\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 混合精度训练\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "with autocast():\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "```\n",
    "\n",
    "## 3. 网络I/O优化\n",
    "```bash\n",
    "# 启用SSH连接复用\n",
    "echo \"Host *\n",
    "    ControlMaster auto\n",
    "    ControlPath ~/.ssh/sockets/%r@%h-%p\n",
    "    ControlPersist 600\" >> ~/.ssh/config\n",
    "\n",
    "mkdir -p ~/.ssh/sockets\n",
    "\n",
    "# 使用rsync增量同步\n",
    "rsync -avz --delete --exclude='*.pyc' local/ server:remote/\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def security_best_practices(self):\n",
    "        \"\"\"安全最佳实践\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# 安全最佳实践\n",
    "\n",
    "## 1. SSH安全配置\n",
    "```bash\n",
    "# 生成强密钥\n",
    "ssh-keygen -t ed25519 -a 100 -f ~/.ssh/server_key\n",
    "\n",
    "# 配置SSH客户端\n",
    "cat >> ~/.ssh/config << EOF\n",
    "Host secure-server\n",
    "    HostName server.university.edu\n",
    "    User your_username\n",
    "    IdentityFile ~/.ssh/server_key\n",
    "    PasswordAuthentication no\n",
    "    PubkeyAuthentication yes\n",
    "    ServerAliveInterval 60\n",
    "EOF\n",
    "\n",
    "# 设置正确的权限\n",
    "chmod 700 ~/.ssh\n",
    "chmod 600 ~/.ssh/*\n",
    "chmod 644 ~/.ssh/*.pub\n",
    "```\n",
    "\n",
    "## 2. 敏感信息管理\n",
    "```bash\n",
    "# 使用环境变量存储敏感信息\n",
    "echo \"export API_KEY='your_secret_key'\" >> ~/.bashrc_private\n",
    "echo \"source ~/.bashrc_private\" >> ~/.bashrc\n",
    "\n",
    "# 在代码中使用\n",
    "import os\n",
    "api_key = os.environ.get('API_KEY')\n",
    "```\n",
    "\n",
    "## 3. 文件权限管理\n",
    "```bash\n",
    "# 设置默认权限\n",
    "umask 022\n",
    "\n",
    "# 保护敏感文件\n",
    "chmod 600 config_with_secrets.yaml\n",
    "chmod 700 private_scripts/\n",
    "\n",
    "# 共享项目目录\n",
    "chmod 755 ~/projects/shared_project/\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def troubleshooting_guide(self):\n",
    "        \"\"\"故障排除指南\"\"\"\n",
    "        \n",
    "        guide = \"\"\"\n",
    "# 故障排除指南\n",
    "\n",
    "## 1. 连接问题\n",
    "### SSH连接超时\n",
    "```bash\n",
    "# 检查网络连通性\n",
    "ping server.university.edu\n",
    "\n",
    "# 使用详细模式诊断\n",
    "ssh -v username@server\n",
    "\n",
    "# 检查SSH服务状态\n",
    "ssh username@server 'sudo systemctl status sshd'\n",
    "```\n",
    "\n",
    "### 连接频繁断开\n",
    "```bash\n",
    "# 客户端配置保持连接\n",
    "echo \"ServerAliveInterval 60\n",
    "ServerAliveCountMax 3\" >> ~/.ssh/config\n",
    "\n",
    "# 服务器端配置 (需要管理员权限)\n",
    "# 在 /etc/ssh/sshd_config 中添加:\n",
    "# ClientAliveInterval 60\n",
    "# ClientAliveCountMax 3\n",
    "```\n",
    "\n",
    "## 2. 环境问题\n",
    "### Conda环境问题\n",
    "```bash\n",
    "# 重新初始化Conda\n",
    "conda init bash\n",
    "source ~/.bashrc\n",
    "\n",
    "# 清理损坏的环境\n",
    "conda remove --name broken_env --all\n",
    "conda clean --all\n",
    "\n",
    "# 重建环境\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "### Python包冲突\n",
    "```bash\n",
    "# 检查包依赖\n",
    "pip check\n",
    "\n",
    "# 创建新的清洁环境\n",
    "conda create -n fresh_env python=3.9\n",
    "conda activate fresh_env\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## 3. 资源问题\n",
    "### GPU内存不足\n",
    "```python\n",
    "# 检查GPU内存使用\n",
    "import torch\n",
    "print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n",
    "print(f\"已用内存: {torch.cuda.memory_allocated(0)/1e9:.1f}GB\")\n",
    "\n",
    "# 清理GPU缓存\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 减少批次大小\n",
    "batch_size = 32  # 从64减少到32\n",
    "```\n",
    "\n",
    "### 磁盘空间不足\n",
    "```bash\n",
    "# 查找大文件\n",
    "find ~ -size +1G -type f -exec ls -lh {} \\\\; | sort -k5 -hr\n",
    "\n",
    "# 清理缓存\n",
    "rm -rf ~/.cache/pip\n",
    "conda clean --all\n",
    "\n",
    "# 压缩日志文件\n",
    "find ~/projects -name \"*.log\" -exec gzip {} \\\\;\n",
    "```\n",
    "\n",
    "## 4. 性能问题\n",
    "### 训练速度慢\n",
    "```python\n",
    "# 检查数据加载瓶颈\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for batch in train_loader:\n",
    "    data_time = time.time() - start_time\n",
    "    print(f\"数据加载时间: {data_time:.3f}s\")\n",
    "    break\n",
    "\n",
    "# 增加数据加载workers\n",
    "train_loader = DataLoader(..., num_workers=8)\n",
    "\n",
    "# 使用混合精度\n",
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    output = model(input)\n",
    "```\n",
    "\n",
    "### 内存泄漏\n",
    "```python\n",
    "# 监控内存使用\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "# 训练代码...\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"当前内存: {current/1e6:.1f}MB, 峰值: {peak/1e6:.1f}MB\")\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        return guide\n",
    "    \n",
    "    def monitoring_scripts(self):\n",
    "        \"\"\"生成监控脚本\"\"\"\n",
    "        \n",
    "        script = \"\"\"#!/bin/bash\n",
    "# 系统监控脚本 - system_monitor.sh\n",
    "\n",
    "# 创建监控报告\n",
    "create_report() {\n",
    "    local report_file=\"monitor_report_$(date +%Y%m%d_%H%M%S).txt\"\n",
    "    \n",
    "    echo \"=== 系统监控报告 ===\" > $report_file\n",
    "    echo \"生成时间: $(date)\" >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== 系统信息 ===\" >> $report_file\n",
    "    uname -a >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== CPU使用率 ===\" >> $report_file\n",
    "    top -bn1 | head -20 >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== 内存使用 ===\" >> $report_file\n",
    "    free -h >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== 磁盘使用 ===\" >> $report_file\n",
    "    df -h >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"=== GPU状态 ===\" >> $report_file\n",
    "        nvidia-smi >> $report_file\n",
    "        echo \"\" >> $report_file\n",
    "    fi\n",
    "    \n",
    "    echo \"=== 网络连接 ===\" >> $report_file\n",
    "    ss -tuln >> $report_file\n",
    "    echo \"\" >> $report_file\n",
    "    \n",
    "    echo \"=== 最近的系统日志 ===\" >> $report_file\n",
    "    journalctl --since \"1 hour ago\" --no-pager | tail -50 >> $report_file\n",
    "    \n",
    "    echo \"监控报告已保存到: $report_file\"\n",
    "}\n",
    "\n",
    "# 实时监控\n",
    "real_time_monitor() {\n",
    "    echo \"开始实时监控 (Ctrl+C 退出)...\"\n",
    "    \n",
    "    while true; do\n",
    "        clear\n",
    "        echo \"=== 实时系统监控 - $(date) ===\"\n",
    "        echo \"\"\n",
    "        \n",
    "        echo \"CPU和内存:\"\n",
    "        top -bn1 | head -5 | tail -2\n",
    "        echo \"\"\n",
    "        \n",
    "        echo \"磁盘使用:\"\n",
    "        df -h | grep -E '^/dev/'\n",
    "        echo \"\"\n",
    "        \n",
    "        if command -v nvidia-smi &> /dev/null; then\n",
    "            echo \"GPU状态:\"\n",
    "            nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits\n",
    "            echo \"\"\n",
    "        fi\n",
    "        \n",
    "        echo \"网络流量:\"\n",
    "        cat /proc/net/dev | grep -E '(eth|wlan)' | head -2\n",
    "        echo \"\"\n",
    "        \n",
    "        sleep 5\n",
    "    done\n",
    "}\n",
    "\n",
    "# 检查服务器健康状况\n",
    "health_check() {\n",
    "    echo \"=== 服务器健康检查 ===\"\n",
    "    \n",
    "    # CPU温度检查\n",
    "    if command -v sensors &> /dev/null; then\n",
    "        echo \"CPU温度:\"\n",
    "        sensors | grep -E 'Core|temp'\n",
    "        echo \"\"\n",
    "    fi\n",
    "    \n",
    "    # 负载检查\n",
    "    load=$(uptime | awk -F'load average:' '{print $2}' | cut -d, -f1 | xargs)\n",
    "    cores=$(nproc)\n",
    "    echo \"系统负载: $load / $cores 核\"\n",
    "    \n",
    "    if (( $(echo \"$load > $cores\" | bc -l) )); then\n",
    "        echo \"⚠️  警告: 系统负载过高!\"\n",
    "    else\n",
    "        echo \"✅ 系统负载正常\"\n",
    "    fi\n",
    "    echo \"\"\n",
    "    \n",
    "    # 内存检查\n",
    "    mem_usage=$(free | awk '/Mem:/ {printf \"%.1f\", $3/$2 * 100.0}')\n",
    "    echo \"内存使用率: ${mem_usage}%\"\n",
    "    \n",
    "    if (( $(echo \"$mem_usage > 90\" | bc -l) )); then\n",
    "        echo \"⚠️  警告: 内存使用率过高!\"\n",
    "    else\n",
    "        echo \"✅ 内存使用正常\"\n",
    "    fi\n",
    "    echo \"\"\n",
    "    \n",
    "    # 磁盘检查\n",
    "    echo \"磁盘使用率:\"\n",
    "    df -h | awk 'NR>1 && $5+0 > 90 {print \"⚠️  \" $0 \" - 磁盘空间不足!\"}'\n",
    "    df -h | awk 'NR>1 && $5+0 <= 90 {print \"✅ \" $0}'\n",
    "    echo \"\"\n",
    "    \n",
    "    # GPU检查\n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"GPU状态检查:\"\n",
    "        nvidia-smi --query-gpu=temperature.gpu,power.draw --format=csv,noheader,nounits | \\\\\n",
    "        awk -F, '{temp=$1; power=$2; if(temp>80) print \"⚠️  GPU温度过高: \" temp \"°C\"; else print \"✅ GPU温度正常: \" temp \"°C\"}'\n",
    "        echo \"\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"report\")\n",
    "        create_report\n",
    "        ;;\n",
    "    \"monitor\")\n",
    "        real_time_monitor\n",
    "        ;;\n",
    "    \"health\")\n",
    "        health_check\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {report|monitor|health}\"\n",
    "        echo \"  report  - 生成监控报告\"\n",
    "        echo \"  monitor - 实时监控\"\n",
    "        echo \"  health  - 健康检查\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "\n",
    "# 创建最佳实践指南\n",
    "practices = ServerBestPractices()\n",
    "\n",
    "print(\"📊 数据管理指南:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.data_management_guide())\n",
    "\n",
    "print(\"\\n⚡ 性能优化指南:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.performance_optimization_guide())\n",
    "\n",
    "print(\"\\n🔒 安全最佳实践:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.security_best_practices())\n",
    "\n",
    "print(\"\\n🔧 故障排除指南:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.troubleshooting_guide())\n",
    "\n",
    "print(\"\\n📈 系统监控脚本:\")\n",
    "print(\"=\"*60)\n",
    "print(practices.monitoring_scripts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d175f",
   "metadata": {},
   "source": [
    "## 9. 完整工作流示例\n",
    "\n",
    "### 9.1 典型的机器学习项目工作流\n",
    "\n",
    "以下是一个从项目开始到结束的完整服务器工作流示例：\n",
    "\n",
    "#### 阶段1：项目初始化\n",
    "1. 在本地开发和测试代码\n",
    "2. 准备项目结构和配置文件\n",
    "3. 创建requirements.txt和environment.yml\n",
    "\n",
    "#### 阶段2：服务器环境搭建\n",
    "1. 连接服务器并配置SSH\n",
    "2. 创建项目目录结构\n",
    "3. 设置Conda环境\n",
    "4. 上传初始代码\n",
    "\n",
    "#### 阶段3：数据准备\n",
    "1. 上传或链接数据集\n",
    "2. 运行数据预处理脚本\n",
    "3. 验证数据完整性\n",
    "\n",
    "#### 阶段4：模型训练\n",
    "1. 提交训练任务（SLURM或后台运行）\n",
    "2. 监控训练进度\n",
    "3. 调整超参数\n",
    "\n",
    "#### 阶段5：结果分析\n",
    "1. 下载训练结果\n",
    "2. 分析模型性能\n",
    "3. 生成报告和可视化\n",
    "\n",
    "### 9.2 工作流自动化脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteWorkflow:\n",
    "    \"\"\"完整的服务器工作流管理\"\"\"\n",
    "    \n",
    "    def __init__(self, project_name, server_config):\n",
    "        self.project_name = project_name\n",
    "        self.server_config = server_config\n",
    "        \n",
    "    def generate_workflow_script(self):\n",
    "        \"\"\"生成完整工作流脚本\"\"\"\n",
    "        \n",
    "        script = f\"\"\"#!/bin/bash\n",
    "# 完整机器学习项目工作流 - ml_workflow.sh\n",
    "\n",
    "PROJECT_NAME=\"{self.project_name}\"\n",
    "SERVER_USER=\"{self.server_config.get('user', 'username')}\"\n",
    "SERVER_HOST=\"{self.server_config.get('host', 'server')}\"\n",
    "REMOTE_BASE=\"/home/$SERVER_USER/projects\"\n",
    "LOCAL_PROJECT=\"./$PROJECT_NAME\"\n",
    "\n",
    "# 颜色定义\n",
    "RED='\\\\033[0;31m'\n",
    "GREEN='\\\\033[0;32m'\n",
    "YELLOW='\\\\033[1;33m'\n",
    "BLUE='\\\\033[0;34m'\n",
    "NC='\\\\033[0m'\n",
    "\n",
    "log_info() {{ echo -e \"${{GREEN}}[INFO]${{NC}} $1\"; }}\n",
    "log_warn() {{ echo -e \"${{YELLOW}}[WARN]${{NC}} $1\"; }}\n",
    "log_error() {{ echo -e \"${{RED}}[ERROR]${{NC}} $1\"; }}\n",
    "\n",
    "# 阶段1: 项目初始化\n",
    "init_project() {{\n",
    "    log_info \"🚀 初始化项目: $PROJECT_NAME\"\n",
    "    \n",
    "    # 创建本地项目结构\n",
    "    mkdir -p $LOCAL_PROJECT/{{data,src,configs,scripts,logs,results}}\n",
    "    \n",
    "    # 创建配置文件\n",
    "    cat > $LOCAL_PROJECT/requirements.txt << 'EOF'\n",
    "torch>=1.9.0\n",
    "torchvision\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "scikit-learn\n",
    "tensorboard\n",
    "tqdm\n",
    "pyyaml\n",
    "EOF\n",
    "\n",
    "    cat > $LOCAL_PROJECT/environment.yml << 'EOF'\n",
    "name: {self.project_name}\n",
    "channels:\n",
    "  - pytorch\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pytorch\n",
    "  - torchvision\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - scikit-learn\n",
    "  - jupyter\n",
    "  - pip\n",
    "  - pip:\n",
    "    - tensorboard\n",
    "    - tqdm\n",
    "    - pyyaml\n",
    "EOF\n",
    "\n",
    "    # 创建README\n",
    "    cat > $LOCAL_PROJECT/README.md << 'EOF'\n",
    "# {self.project_name}\n",
    "\n",
    "## 项目描述\n",
    "机器学习项目模板\n",
    "\n",
    "## 环境设置\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate {self.project_name}\n",
    "```\n",
    "\n",
    "## 使用方法\n",
    "1. 数据预处理: `python src/preprocess.py`\n",
    "2. 模型训练: `python src/train.py`\n",
    "3. 结果评估: `python src/evaluate.py`\n",
    "EOF\n",
    "\n",
    "    log_info \"✅ 项目结构创建完成\"\n",
    "}}\n",
    "\n",
    "# 阶段2: 服务器环境搭建\n",
    "setup_server() {{\n",
    "    log_info \"🖥️  设置服务器环境\"\n",
    "    \n",
    "    # 创建远程目录\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"mkdir -p $REMOTE_BASE/$PROJECT_NAME/{{data,src,configs,scripts,logs,results,checkpoints}}\"\n",
    "    \n",
    "    # 上传项目文件\n",
    "    rsync -avz --progress \\\\\n",
    "        --exclude='*.pyc' \\\\\n",
    "        --exclude='__pycache__/' \\\\\n",
    "        --exclude='.git/' \\\\\n",
    "        --exclude='data/raw/' \\\\\n",
    "        $LOCAL_PROJECT/ \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/\n",
    "    \n",
    "    # 在服务器上创建环境\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        conda env create -f environment.yml && \\\\\n",
    "        echo 'conda activate $PROJECT_NAME' >> ~/.bashrc\"\n",
    "    \n",
    "    log_info \"✅ 服务器环境设置完成\"\n",
    "}}\n",
    "\n",
    "# 阶段3: 数据准备\n",
    "prepare_data() {{\n",
    "    log_info \"📊 准备数据\"\n",
    "    \n",
    "    # 上传数据（如果有的话）\n",
    "    if [ -d \"$LOCAL_PROJECT/data/raw\" ]; then\n",
    "        log_info \"上传原始数据...\"\n",
    "        rsync -avz --progress \\\\\n",
    "            $LOCAL_PROJECT/data/raw/ \\\\\n",
    "            $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/data/raw/\n",
    "    fi\n",
    "    \n",
    "    # 在服务器上运行数据预处理\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        conda activate $PROJECT_NAME && \\\\\n",
    "        python -c 'print(\\\\\\\"数据预处理开始\\\\\\\")' && \\\\\n",
    "        echo '数据预处理完成'\"\n",
    "    \n",
    "    log_info \"✅ 数据准备完成\"\n",
    "}}\n",
    "\n",
    "# 阶段4: 提交训练任务\n",
    "submit_training() {{\n",
    "    log_info \"🤖 提交训练任务\"\n",
    "    \n",
    "    # 创建训练脚本\n",
    "    cat > train_job.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name={self.project_name}_train\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16G\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=logs/train_%j.out\n",
    "#SBATCH --error=logs/train_%j.err\n",
    "\n",
    "echo \"训练开始: $(date)\"\n",
    "conda activate {self.project_name}\n",
    "python src/train.py --config configs/default.yaml\n",
    "echo \"训练结束: $(date)\"\n",
    "EOF\n",
    "\n",
    "    # 上传并提交作业\n",
    "    scp train_job.sh $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/\n",
    "    \n",
    "    job_id=$(ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && sbatch train_job.sh\" | grep -o '[0-9]\\\\+')\n",
    "    \n",
    "    if [ -n \"$job_id\" ]; then\n",
    "        log_info \"✅ 训练任务已提交, 作业ID: $job_id\"\n",
    "        echo $job_id > .job_id\n",
    "    else\n",
    "        log_error \"❌ 训练任务提交失败\"\n",
    "        return 1\n",
    "    fi\n",
    "}}\n",
    "\n",
    "# 阶段5: 监控训练\n",
    "monitor_training() {{\n",
    "    if [ ! -f \".job_id\" ]; then\n",
    "        log_error \"❌ 没有找到作业ID文件\"\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    job_id=$(cat .job_id)\n",
    "    log_info \"📊 监控训练任务: $job_id\"\n",
    "    \n",
    "    # 检查作业状态\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"squeue -j $job_id\"\n",
    "    \n",
    "    # 实时查看日志\n",
    "    log_info \"📄 实时日志 (Ctrl+C 退出):\"\n",
    "    ssh $SERVER_USER@$SERVER_HOST \"tail -f $REMOTE_BASE/$PROJECT_NAME/logs/train_${{job_id}}.out\"\n",
    "}}\n",
    "\n",
    "# 阶段6: 下载结果\n",
    "download_results() {{\n",
    "    log_info \"📥 下载训练结果\"\n",
    "    \n",
    "    # 创建本地结果目录\n",
    "    mkdir -p $LOCAL_PROJECT/results/$(date +%Y%m%d_%H%M%S)\n",
    "    \n",
    "    # 下载结果文件\n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/checkpoints/ \\\\\n",
    "        $LOCAL_PROJECT/results/checkpoints/\n",
    "    \n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/logs/ \\\\\n",
    "        $LOCAL_PROJECT/results/logs/\n",
    "    \n",
    "    # 下载可视化结果\n",
    "    rsync -avz --progress \\\\\n",
    "        $SERVER_USER@$SERVER_HOST:$REMOTE_BASE/$PROJECT_NAME/results/ \\\\\n",
    "        $LOCAL_PROJECT/results/\n",
    "    \n",
    "    log_info \"✅ 结果下载完成\"\n",
    "}}\n",
    "\n",
    "# 清理函数\n",
    "cleanup() {{\n",
    "    log_info \"🧹 清理服务器临时文件\"\n",
    "    \n",
    "    ssh $SERVER_USER@$SERVER_HOST \"cd $REMOTE_BASE/$PROJECT_NAME && \\\\\n",
    "        find . -name '*.tmp' -delete && \\\\\n",
    "        find . -name '__pycache__' -type d -exec rm -rf {{}} + 2>/dev/null || true\"\n",
    "    \n",
    "    log_info \"✅ 清理完成\"\n",
    "}}\n",
    "\n",
    "# 完整工作流\n",
    "run_complete_workflow() {{\n",
    "    log_info \"🎯 开始完整工作流\"\n",
    "    \n",
    "    init_project\n",
    "    setup_server\n",
    "    prepare_data\n",
    "    submit_training\n",
    "    \n",
    "    log_info \"🎉 工作流启动完成！\"\n",
    "    log_info \"📋 后续操作:\"\n",
    "    log_info \"  - 监控训练: $0 monitor\"\n",
    "    log_info \"  - 下载结果: $0 download\"\n",
    "    log_info \"  - 清理文件: $0 cleanup\"\n",
    "}}\n",
    "\n",
    "# 主程序\n",
    "case \"$1\" in\n",
    "    \"init\")\n",
    "        init_project\n",
    "        ;;\n",
    "    \"setup\")\n",
    "        setup_server\n",
    "        ;;\n",
    "    \"data\")\n",
    "        prepare_data\n",
    "        ;;\n",
    "    \"train\")\n",
    "        submit_training\n",
    "        ;;\n",
    "    \"monitor\")\n",
    "        monitor_training\n",
    "        ;;\n",
    "    \"download\")\n",
    "        download_results\n",
    "        ;;\n",
    "    \"cleanup\")\n",
    "        cleanup\n",
    "        ;;\n",
    "    \"all\"|\"\")\n",
    "        run_complete_workflow\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"用法: $0 {{init|setup|data|train|monitor|download|cleanup|all}}\"\n",
    "        echo \"  init     - 初始化项目\"\n",
    "        echo \"  setup    - 设置服务器环境\"\n",
    "        echo \"  data     - 准备数据\"\n",
    "        echo \"  train    - 提交训练任务\"\n",
    "        echo \"  monitor  - 监控训练\"\n",
    "        echo \"  download - 下载结果\"\n",
    "        echo \"  cleanup  - 清理临时文件\"\n",
    "        echo \"  all      - 运行完整工作流 (默认)\"\n",
    "        exit 1\n",
    "        ;;\n",
    "esac\n",
    "\"\"\"\n",
    "        \n",
    "        return script\n",
    "    \n",
    "    def generate_project_template(self):\n",
    "        \"\"\"生成项目模板文件\"\"\"\n",
    "        \n",
    "        templates = {}\n",
    "        \n",
    "        # 训练脚本模板\n",
    "        templates['train.py'] = \"\"\"#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "机器学习训练脚本模板\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config(config_path):\n",
    "    \\\"\\\"\\\"加载配置文件\\\"\\\"\\\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def setup_logging(log_dir):\n",
    "    \\\"\\\"\\\"设置日志\\\"\\\"\\\"\n",
    "    log_dir = Path(log_dir)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n",
    "\n",
    "def train_model(config):\n",
    "    \\\"\\\"\\\"训练模型\\\"\\\"\\\"\n",
    "    print(f\"🚀 开始训练: {{config['model']['name']}}\")\n",
    "    \n",
    "    # 设置设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {{device}}\")\n",
    "    \n",
    "    # 这里添加你的训练代码\n",
    "    # model = YourModel()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=config['training']['lr'])\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(config['training']['epochs']):\n",
    "        print(f\"Epoch {{epoch+1}}/{{config['training']['epochs']}}\")\n",
    "        \n",
    "        # 训练代码...\n",
    "        \n",
    "        # 保存检查点\n",
    "        if (epoch + 1) % config['training']['save_frequency'] == 0:\n",
    "            checkpoint_path = Path(config['paths']['checkpoints']) / f\"model_epoch_{{epoch+1}}.pth\"\n",
    "            # torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"✅ 检查点已保存: {{checkpoint_path}}\")\n",
    "    \n",
    "    print(\"🎉 训练完成!\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='训练脚本')\n",
    "    parser.add_argument('--config', type=str, default='configs/default.yaml',\n",
    "                       help='配置文件路径')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # 加载配置\n",
    "    config = load_config(args.config)\n",
    "    \n",
    "    # 设置日志\n",
    "    writer = setup_logging(config['paths']['logs'])\n",
    "    \n",
    "    # 开始训练\n",
    "    train_model(config)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "        # 配置文件模板\n",
    "        templates['default.yaml'] = f\"\"\"\n",
    "# 默认配置文件\n",
    "project:\n",
    "  name: \"{self.project_name}\"\n",
    "  description: \"机器学习项目\"\n",
    "\n",
    "model:\n",
    "  name: \"SimpleCNN\"\n",
    "  num_classes: 10\n",
    "  dropout: 0.5\n",
    "\n",
    "training:\n",
    "  epochs: 100\n",
    "  batch_size: 64\n",
    "  learning_rate: 0.001\n",
    "  optimizer: \"adam\"\n",
    "  scheduler: \"step\"\n",
    "  save_frequency: 10\n",
    "\n",
    "data:\n",
    "  dataset: \"MNIST\"\n",
    "  train_split: 0.8\n",
    "  val_split: 0.1\n",
    "  test_split: 0.1\n",
    "\n",
    "paths:\n",
    "  data: \"./data\"\n",
    "  checkpoints: \"./checkpoints\"\n",
    "  logs: \"./logs\"\n",
    "  results: \"./results\"\n",
    "\n",
    "hardware:\n",
    "  device: \"auto\"  # auto, cpu, cuda\n",
    "  num_workers: 4\n",
    "  pin_memory: true\n",
    "\"\"\"\n",
    "        \n",
    "        return templates\n",
    "\n",
    "# 创建完整工作流管理器\n",
    "server_config = {\n",
    "    'user': 'your_username',\n",
    "    'host': 'gpu-server',\n",
    "    'port': 22\n",
    "}\n",
    "\n",
    "workflow = CompleteWorkflow(\"my_ml_project\", server_config)\n",
    "\n",
    "print(\"🔄 完整工作流脚本:\")\n",
    "print(\"=\"*60)\n",
    "workflow_script = workflow.generate_workflow_script()\n",
    "print(workflow_script)\n",
    "\n",
    "print(\"\\n📋 项目模板文件:\")\n",
    "print(\"=\"*60)\n",
    "templates = workflow.generate_project_template()\n",
    "\n",
    "for filename, content in templates.items():\n",
    "    print(f\"\\n📄 {filename}:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(content)\n",
    "\n",
    "print(\"\\n🎯 使用指南:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. 保存工作流脚本为 ml_workflow.sh\n",
    "2. 修改脚本中的服务器配置\n",
    "3. chmod +x ml_workflow.sh\n",
    "4. 运行完整工作流: ./ml_workflow.sh all\n",
    "\n",
    "各阶段可以单独运行:\n",
    "- 初始化项目: ./ml_workflow.sh init\n",
    "- 设置服务器: ./ml_workflow.sh setup  \n",
    "- 准备数据: ./ml_workflow.sh data\n",
    "- 提交训练: ./ml_workflow.sh train\n",
    "- 监控训练: ./ml_workflow.sh monitor\n",
    "- 下载结果: ./ml_workflow.sh download\n",
    "- 清理文件: ./ml_workflow.sh cleanup\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe14d9",
   "metadata": {},
   "source": [
    "## 10. 总结与进阶学习\n",
    "\n",
    "### 10.1 核心要点回顾\n",
    "\n",
    "通过本教程，我们学习了服务器使用的全方位技能：\n",
    "\n",
    "✅ **SSH连接管理**：配置文件、密钥认证、连接保持\n",
    "✅ **文件传输优化**：scp、rsync、增量同步、排除模式\n",
    "✅ **环境配置**：Conda环境管理、包依赖、GPU配置\n",
    "✅ **任务管理**：screen、tmux、nohup、后台运行\n",
    "✅ **SLURM系统**：作业提交、资源申请、队列管理\n",
    "✅ **监控和调试**：资源监控、日志管理、故障排除\n",
    "✅ **完整工作流**：项目自动化、脚本管理、最佳实践\n",
    "\n",
    "### 10.2 服务器使用技能对比\n",
    "\n",
    "| 技能等级 | 基础技能 | 进阶技能 | 专家技能 |\n",
    "|----------|----------|----------|----------|\n",
    "| **连接** | SSH基本连接 | 配置文件、密钥管理 | 跳板机、端口转发 |\n",
    "| **文件** | scp基本传输 | rsync增量同步 | 并行传输、压缩优化 |\n",
    "| **环境** | 基本包安装 | 虚拟环境管理 | 容器化、环境隔离 |\n",
    "| **任务** | 命令行运行 | 后台任务管理 | 作业调度、资源优化 |\n",
    "| **监控** | 基本状态查看 | 实时监控脚本 | 自动化告警、性能分析 |\n",
    "\n",
    "### 10.3 进阶学习方向\n",
    "\n",
    "1. **容器技术**：\n",
    "   - Docker 容器化部署\n",
    "   - Singularity 集群容器\n",
    "   - Kubernetes 编排\n",
    "\n",
    "2. **自动化工具**：\n",
    "   - Ansible 配置管理\n",
    "   - Jenkins CI/CD\n",
    "   - GitHub Actions\n",
    "\n",
    "3. **监控系统**：\n",
    "   - Prometheus + Grafana\n",
    "   - ELK Stack (日志分析)\n",
    "   - 自定义监控告警\n",
    "\n",
    "4. **高级网络**：\n",
    "   - VPN 和隧道技术\n",
    "   - 负载均衡\n",
    "   - 分布式存储\n",
    "\n",
    "### 10.4 推荐资源\n",
    "\n",
    "- **官方文档**：\n",
    "  - [SSH 官方手册](https://man.openbsd.org/ssh)\n",
    "  - [SLURM 文档](https://slurm.schedmd.com/documentation.html)\n",
    "  - [GNU Screen 用户手册](https://www.gnu.org/software/screen/manual/)\n",
    "\n",
    "- **实用工具**：\n",
    "  - [tmux 速查表](https://tmuxcheatsheet.com/)\n",
    "  - [rsync 详细教程](https://rsync.samba.org/)\n",
    "  - [htop 系统监控](https://htop.dev/)\n",
    "\n",
    "- **最佳实践**：\n",
    "  - [高性能计算最佳实践](https://hpc-wiki.info/)\n",
    "  - [Linux 服务器管理指南](https://linuxhandbook.com/)\n",
    "  - [Shell 脚本编程指南](https://tldp.org/LDP/Bash-Beginners-Guide/html/)\n",
    "\n",
    "恭喜你完成了服务器工作流教程！🎉\n",
    "\n",
    "现在你已经具备了在服务器上高效进行机器学习研究的技能。记住：\n",
    "- 🔧 **自动化一切**：能脚本化的就不要手动操作\n",
    "- 📊 **监控为王**：时刻了解系统和任务状态  \n",
    "- 🔒 **安全第一**：保护好你的服务器访问凭证\n",
    "- 📝 **文档记录**：记录你的配置和工作流程\n",
    "- 🤝 **团队协作**：与团队成员分享最佳实践\n",
    "\n",
    "祝你在服务器上的机器学习研究取得成功！🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
