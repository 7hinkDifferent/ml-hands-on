{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fe7c15",
   "metadata": {},
   "source": [
    "# Scikit-learn机器学习完全教程\n",
    "\n",
    "本笔记本将全面介绍Scikit-learn——Python中最重要的机器学习库，包括：\n",
    "\n",
    "- **机器学习基础**: 监督学习、无监督学习、模型评估\n",
    "- **数据预处理**: 特征缩放、编码、特征选择、数据清洗\n",
    "- **分类算法**: 支持向量机(SVM)、决策树、随机森林、逻辑回归等\n",
    "- **回归算法**: 线性回归、多项式回归、岭回归、LASSO回归\n",
    "- **聚类算法**: K-means、层次聚类、DBSCAN\n",
    "- **降维技术**: PCA、t-SNE、特征选择\n",
    "- **模型选择**: 交叉验证、网格搜索、模型评估指标\n",
    "- **实际项目**: MNIST手写数字分类、完整机器学习流程\n",
    "\n",
    "**重点案例**: 使用支持向量机(SVM)对MNIST数据集进行手写数字分类，这是计算机视觉和模式识别领域的经典问题。\n",
    "\n",
    "Scikit-learn以其统一的API、丰富的算法库和优秀的文档而闻名，是机器学习入门和实践的首选工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子保证结果可重现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置matplotlib中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"=== Scikit-learn环境配置 ===\")\n",
    "import sklearn\n",
    "print(f\"Scikit-learn版本: {sklearn.__version__}\")\n",
    "print(f\"NumPy版本: {np.__version__}\")\n",
    "print(f\"Pandas版本: {pd.__version__}\")\n",
    "\n",
    "# 加载MNIST数据集 (sklearn内置的简化版本)\n",
    "print(f\"\\n=== 加载MNIST数据集 ===\")\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 加载MNIST数据集\n",
    "print(\"正在下载MNIST数据集...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "X_mnist, y_mnist = mnist.data, mnist.target.astype(int)\n",
    "\n",
    "print(f\"MNIST数据集信息:\")\n",
    "print(f\"- 特征矩阵形状: {X_mnist.shape}\")\n",
    "print(f\"- 标签向量形状: {y_mnist.shape}\")\n",
    "print(f\"- 特征范围: {X_mnist.min():.1f} - {X_mnist.max():.1f}\")\n",
    "print(f\"- 类别数量: {len(np.unique(y_mnist))}\")\n",
    "print(f\"- 类别分布:\")\n",
    "unique, counts = np.unique(y_mnist, return_counts=True)\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"  数字 {digit}: {count:,} 样本\")\n",
    "\n",
    "# 可视化MNIST样本\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    # 找到每个数字的第一个样本\n",
    "    idx = np.where(y_mnist == i)[0][0]\n",
    "    row, col = divmod(i, 5)\n",
    "    \n",
    "    # 将784维向量重塑为28x28图像\n",
    "    image = X_mnist[idx].reshape(28, 28)\n",
    "    axes[row, col].imshow(image, cmap='gray')\n",
    "    axes[row, col].set_title(f'数字 {i}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('MNIST数据集样本展示', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 环境配置和数据加载完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f62a0",
   "metadata": {},
   "source": [
    "## 1. 机器学习基础概念\n",
    "\n",
    "### 1.1 机器学习类型\n",
    "\n",
    "- **监督学习**: 从标记的训练数据中学习，预测新数据的标签\n",
    "  - 分类 (Classification): 预测离散标签 (如数字识别)\n",
    "  - 回归 (Regression): 预测连续数值 (如房价预测)\n",
    "\n",
    "- **无监督学习**: 从无标签数据中发现隐藏模式\n",
    "  - 聚类 (Clustering): 将数据分组\n",
    "  - 降维 (Dimensionality Reduction): 简化数据表示\n",
    "\n",
    "- **强化学习**: 通过与环境交互学习最优策略\n",
    "\n",
    "### 1.2 Scikit-learn的设计哲学\n",
    "\n",
    "- **一致的API**: 所有估计器都有fit()、predict()等方法\n",
    "- **组合性**: 不同组件可以轻松组合\n",
    "- **合理的默认值**: 开箱即用的参数设置\n",
    "- **可检查性**: 模型内部状态可访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Scikit-learn典型工作流程演示\n",
    "print(\"=== Scikit-learn典型工作流程 ===\")\n",
    "\n",
    "# 使用一个简单的鸢尾花数据集来演示完整流程\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 步骤1: 加载数据\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "print(\"步骤1: 数据加载\")\n",
    "print(f\"特征名称: {iris.feature_names}\")\n",
    "print(f\"类别名称: {iris.target_names}\")\n",
    "print(f\"数据形状: {X_iris.shape}\")\n",
    "\n",
    "# 步骤2: 数据分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris\n",
    ")\n",
    "\n",
    "print(f\"\\n步骤2: 数据分割\")\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")\n",
    "\n",
    "# 步骤3: 特征缩放\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n步骤3: 特征缩放\")\n",
    "print(f\"原始特征范围: {X_train.min():.2f} - {X_train.max():.2f}\")\n",
    "print(f\"缩放后特征范围: {X_train_scaled.min():.2f} - {X_train_scaled.max():.2f}\")\n",
    "\n",
    "# 步骤4: 模型训练\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n步骤4: 模型训练\")\n",
    "print(f\"模型类型: {type(model).__name__}\")\n",
    "print(f\"模型参数: {model.get_params()}\")\n",
    "\n",
    "# 步骤5: 模型预测\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\n步骤5: 模型预测\")\n",
    "print(f\"预测结果: {y_pred}\")\n",
    "print(f\"真实标签: {y_test}\")\n",
    "\n",
    "# 步骤6: 模型评估\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n步骤6: 模型评估\")\n",
    "print(f\"准确率: {accuracy:.4f}\")\n",
    "\n",
    "# 可视化结果\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 特征分布可视化\n",
    "feature_names = iris.feature_names\n",
    "for i, feature in enumerate([0, 2]):  # 选择两个特征\n",
    "    for class_idx, class_name in enumerate(iris.target_names):\n",
    "        mask = y_iris == class_idx\n",
    "        axes[0].scatter(X_iris[mask, feature], X_iris[mask, 1], \n",
    "                       label=class_name, alpha=0.7)\n",
    "    \n",
    "axes[0].set_xlabel(feature_names[0])\n",
    "axes[0].set_ylabel(feature_names[1])\n",
    "axes[0].set_title('鸢尾花数据集特征分布')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "im = axes[1].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[1].set_title('混淆矩阵')\n",
    "axes[1].set_xlabel('预测标签')\n",
    "axes[1].set_ylabel('真实标签')\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        axes[1].text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ 完整工作流程演示完成！\")\n",
    "print(\"这就是机器学习项目的标准流程：\")\n",
    "print(\"数据加载 → 数据分割 → 特征处理 → 模型训练 → 预测 → 评估\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc66bb",
   "metadata": {},
   "source": [
    "## 2. 数据预处理\n",
    "\n",
    "数据预处理是机器学习项目中最重要的步骤之一。高质量的数据预处理通常比算法选择更重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b294f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 特征缩放\n",
    "print(\"=== 特征缩放 ===\")\n",
    "\n",
    "# 创建示例数据\n",
    "from sklearn.datasets import make_classification\n",
    "X_example, y_example = make_classification(n_samples=1000, n_features=4, \n",
    "                                          n_informative=3, n_redundant=1, \n",
    "                                          random_state=42)\n",
    "\n",
    "# 模拟不同量级的特征\n",
    "X_example[:, 0] *= 1000  # 第一个特征放大1000倍\n",
    "X_example[:, 1] *= 0.01  # 第二个特征缩小100倍\n",
    "\n",
    "print(\"原始数据特征统计:\")\n",
    "feature_stats = pd.DataFrame(X_example, columns=[f'特征{i+1}' for i in range(4)])\n",
    "print(feature_stats.describe())\n",
    "\n",
    "# 不同的缩放方法\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "scalers = {\n",
    "    '标准化 (StandardScaler)': StandardScaler(),\n",
    "    '最小-最大缩放 (MinMaxScaler)': MinMaxScaler(),\n",
    "    '鲁棒缩放 (RobustScaler)': RobustScaler()\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 原始数据分布\n",
    "axes[0, 0].boxplot(X_example, labels=[f'特征{i+1}' for i in range(4)])\n",
    "axes[0, 0].set_title('原始数据分布')\n",
    "axes[0, 0].set_ylabel('数值')\n",
    "\n",
    "# 不同缩放方法的效果\n",
    "for idx, (name, scaler) in enumerate(scalers.items()):\n",
    "    row, col = divmod(idx + 1, 2)\n",
    "    X_scaled = scaler.fit_transform(X_example)\n",
    "    axes[row, col].boxplot(X_scaled, labels=[f'特征{i+1}' for i in range(4)])\n",
    "    axes[row, col].set_title(name)\n",
    "    axes[row, col].set_ylabel('缩放后数值')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2.2 分类变量编码\n",
    "print(\"\\n=== 分类变量编码 ===\")\n",
    "\n",
    "# 创建包含分类变量的示例数据\n",
    "data_cat = pd.DataFrame({\n",
    "    '颜色': ['红', '蓝', '绿', '红', '蓝', '绿', '黄', '黄'],\n",
    "    '尺寸': ['小', '中', '大', '小', '大', '中', '小', '大'],\n",
    "    '品牌': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B'],\n",
    "    '价格': [100, 200, 150, 120, 180, 160, 90, 210]\n",
    "})\n",
    "\n",
    "print(\"原始分类数据:\")\n",
    "print(data_cat)\n",
    "\n",
    "# 标签编码 (Label Encoding)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_color = LabelEncoder()\n",
    "data_cat['颜色_标签编码'] = le_color.fit_transform(data_cat['颜色'])\n",
    "\n",
    "print(f\"\\n颜色标签编码映射: {dict(zip(le_color.classes_, range(len(le_color.classes_))))}\")\n",
    "\n",
    "# 独热编码 (One-Hot Encoding)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "color_onehot = ohe.fit_transform(data_cat[['颜色']])\n",
    "color_onehot_df = pd.DataFrame(color_onehot, columns=[f'颜色_{cat}' for cat in ohe.categories_[0]])\n",
    "\n",
    "print(\"\\n颜色独热编码结果:\")\n",
    "print(color_onehot_df.head())\n",
    "\n",
    "# 序数编码 (Ordinal Encoding) - 适用于有顺序关系的分类变量\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# 为尺寸定义顺序\n",
    "size_mapping = [['小', '中', '大']]\n",
    "oe = OrdinalEncoder(categories=size_mapping)\n",
    "data_cat['尺寸_序数编码'] = oe.fit_transform(data_cat[['尺寸']])\n",
    "\n",
    "print(f\"\\n尺寸序数编码映射: 小=0, 中=1, 大=2\")\n",
    "print(data_cat[['尺寸', '尺寸_序数编码']])\n",
    "\n",
    "# 2.3 处理缺失值\n",
    "print(\"\\n=== 处理缺失值 ===\")\n",
    "\n",
    "# 创建含有缺失值的数据\n",
    "data_missing = pd.DataFrame({\n",
    "    '年龄': [25, 30, np.nan, 35, 28, np.nan, 32],\n",
    "    '收入': [50000, np.nan, 60000, 70000, np.nan, 55000, 65000],\n",
    "    '教育年限': [16, 18, 12, np.nan, 14, 16, 20]\n",
    "})\n",
    "\n",
    "print(\"含缺失值的数据:\")\n",
    "print(data_missing)\n",
    "print(f\"\\n缺失值统计:\")\n",
    "print(data_missing.isnull().sum())\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# 简单填充策略\n",
    "imputers = {\n",
    "    '均值填充': SimpleImputer(strategy='mean'),\n",
    "    '中位数填充': SimpleImputer(strategy='median'),\n",
    "    '众数填充': SimpleImputer(strategy='most_frequent'),\n",
    "    'KNN填充': KNNImputer(n_neighbors=3)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, imputer in imputers.items():\n",
    "    filled_data = imputer.fit_transform(data_missing)\n",
    "    results[name] = pd.DataFrame(filled_data, columns=data_missing.columns)\n",
    "\n",
    "# 展示不同填充方法的结果\n",
    "print(\"\\n不同填充方法的结果对比:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(result.round(0))\n",
    "\n",
    "# 2.4 特征选择\n",
    "print(\"\\n=== 特征选择 ===\")\n",
    "\n",
    "# 使用MNIST数据的子集进行特征选择演示\n",
    "# 为了计算效率，我们只使用前1000个样本\n",
    "X_subset = X_mnist[:1000]\n",
    "y_subset = y_mnist[:1000]\n",
    "\n",
    "print(f\"原始特征数量: {X_subset.shape[1]}\")\n",
    "\n",
    "# 方差阈值特征选择\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_threshold = VarianceThreshold(threshold=100)  # 移除方差小于100的特征\n",
    "X_var_selected = var_threshold.fit_transform(X_subset)\n",
    "\n",
    "print(f\"方差阈值选择后特征数量: {X_var_selected.shape[1]}\")\n",
    "\n",
    "# 单变量特征选择\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "k_best = SelectKBest(score_func=chi2, k=100)  # 选择前100个最佳特征\n",
    "X_k_best = k_best.fit_transform(X_subset, y_subset)\n",
    "\n",
    "print(f\"SelectKBest选择后特征数量: {X_k_best.shape[1]}\")\n",
    "\n",
    "# 递归特征消除\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用逻辑回归作为基估计器\n",
    "estimator = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=50)\n",
    "X_rfe = rfe.fit_transform(X_subset, y_subset)\n",
    "\n",
    "print(f\"RFE选择后特征数量: {X_rfe.shape[1]}\")\n",
    "\n",
    "# 可视化特征选择的效果\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 显示一些原始图像\n",
    "for i in range(3):\n",
    "    axes[i].imshow(X_subset[i].reshape(28, 28), cmap='gray')\n",
    "    axes[i].set_title(f'原始图像 (标签: {y_subset[i]})')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('MNIST原始图像示例', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n数据预处理要点:\")\n",
    "print(\"✓ 特征缩放对距离敏感的算法很重要\")\n",
    "print(\"✓ 分类变量编码要根据变量性质选择合适方法\")\n",
    "print(\"✓ 缺失值处理要考虑数据的分布和含义\")\n",
    "print(\"✓ 特征选择可以提高模型性能并减少计算成本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d00333",
   "metadata": {},
   "source": [
    "## 3. 支持向量机 (SVM) 与MNIST分类\n",
    "\n",
    "支持向量机是一种强大的监督学习算法，特别适用于高维数据分类。我们将详细学习SVM的原理，并在MNIST数据集上进行手写数字分类实战。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 SVM基础理论和核函数\n",
    "print(\"=== SVM基础理论 ===\")\n",
    "\n",
    "# 首先用简单的二分类数据演示SVM原理\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# 生成二分类数据\n",
    "X_2d, y_2d = make_blobs(n_samples=100, centers=2, cluster_std=1.2, \n",
    "                       center_box=(-2.0, 2.0), random_state=42)\n",
    "\n",
    "# 不同核函数的SVM\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "for idx, kernel in enumerate(kernels):\n",
    "    row, col = divmod(idx, 2)\n",
    "    \n",
    "    # 训练SVM\n",
    "    svm = SVC(kernel=kernel, random_state=42)\n",
    "    svm.fit(X_2d, y_2d)\n",
    "    \n",
    "    # 创建网格用于可视化决策边界\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # 预测网格点\n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = svm.predict(mesh_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # 绘制决策边界\n",
    "    axes[row, col].contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdBu)\n",
    "    \n",
    "    # 绘制数据点\n",
    "    scatter = axes[row, col].scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu)\n",
    "    \n",
    "    # 绘制支持向量\n",
    "    axes[row, col].scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1],\n",
    "                          s=100, facecolors='none', edgecolors='black', linewidth=2)\n",
    "    \n",
    "    axes[row, col].set_title(f'{kernel.upper()} 核函数')\n",
    "    axes[row, col].set_xlabel('特征 1')\n",
    "    axes[row, col].set_ylabel('特征 2')\n",
    "\n",
    "plt.suptitle('不同核函数的SVM决策边界', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"SVM核函数解释:\")\n",
    "print(\"• Linear: 线性核，适用于线性可分数据\")\n",
    "print(\"• Polynomial: 多项式核，可以处理非线性关系\")\n",
    "print(\"• RBF (高斯): 径向基函数核，最常用的非线性核\")\n",
    "print(\"• Sigmoid: S型核，类似神经网络的激活函数\")\n",
    "\n",
    "# 3.2 MNIST数据集准备和预处理\n",
    "print(\"\\n=== MNIST数据集准备 ===\")\n",
    "\n",
    "# 为了训练效率，我们使用MNIST的子集\n",
    "# 在实际项目中可以使用全部数据\n",
    "n_samples = 5000  # 使用5000个样本进行演示\n",
    "\n",
    "# 随机采样\n",
    "indices = np.random.choice(len(X_mnist), n_samples, replace=False)\n",
    "X_mnist_subset = X_mnist[indices]\n",
    "y_mnist_subset = y_mnist[indices]\n",
    "\n",
    "print(f\"使用MNIST子集: {X_mnist_subset.shape}\")\n",
    "print(f\"类别分布:\")\n",
    "unique, counts = np.unique(y_mnist_subset, return_counts=True)\n",
    "for digit, count in zip(unique, counts):\n",
    "    print(f\"  数字 {digit}: {count} 样本\")\n",
    "\n",
    "# 数据预处理\n",
    "# 1. 特征缩放 (像素值从0-255缩放到0-1)\n",
    "X_mnist_scaled = X_mnist_subset / 255.0\n",
    "\n",
    "# 2. 数据分割\n",
    "X_train_mnist, X_test_mnist, y_train_mnist, y_test_mnist = train_test_split(\n",
    "    X_mnist_scaled, y_mnist_subset, test_size=0.3, random_state=42, \n",
    "    stratify=y_mnist_subset\n",
    ")\n",
    "\n",
    "print(f\"\\n数据分割结果:\")\n",
    "print(f\"训练集: {X_train_mnist.shape}\")\n",
    "print(f\"测试集: {X_test_mnist.shape}\")\n",
    "\n",
    "# 3.3 SVM模型训练和优化\n",
    "print(\"\\n=== SVM模型训练和参数优化 ===\")\n",
    "\n",
    "# 首先使用默认参数训练SVM\n",
    "print(\"1. 使用默认参数的SVM:\")\n",
    "svm_default = SVC(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "import time\n",
    "start_time = time.time()\n",
    "svm_default.fit(X_train_mnist, y_train_mnist)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"训练时间: {training_time:.2f} 秒\")\n",
    "\n",
    "# 在测试集上评估\n",
    "y_pred_default = svm_default.predict(X_test_mnist)\n",
    "accuracy_default = accuracy_score(y_test_mnist, y_pred_default)\n",
    "print(f\"默认参数准确率: {accuracy_default:.4f}\")\n",
    "\n",
    "# 使用网格搜索优化参数\n",
    "print(\"\\n2. 使用网格搜索优化参数:\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# 注意：在实际项目中，可以使用更大的参数网格\n",
    "# 这里为了演示和计算效率，使用较小的网格\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42), \n",
    "    param_grid, \n",
    "    cv=3,  # 3折交叉验证\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # 使用所有CPU核心\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"正在进行网格搜索...\")\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_mnist, y_train_mnist)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"网格搜索时间: {search_time:.2f} 秒\")\n",
    "print(f\"最佳参数: {grid_search.best_params_}\")\n",
    "print(f\"最佳交叉验证得分: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 使用最佳参数的模型在测试集上评估\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test_mnist)\n",
    "accuracy_best = accuracy_score(y_test_mnist, y_pred_best)\n",
    "print(f\"优化后准确率: {accuracy_best:.4f}\")\n",
    "\n",
    "# 3.4 详细的模型评估\n",
    "print(\"\\n=== 详细的模型评估 ===\")\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test_mnist, y_pred_best)\n",
    "\n",
    "# 分类报告\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test_mnist, y_pred_best))\n",
    "\n",
    "# 可视化结果\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. 混淆矩阵热力图\n",
    "im = axes[0, 0].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[0, 0].set_title('混淆矩阵')\n",
    "axes[0, 0].set_xlabel('预测标签')\n",
    "axes[0, 0].set_ylabel('真实标签')\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        axes[0, 0].text(j, i, format(cm[i, j], 'd'),\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 0])\n",
    "\n",
    "# 2. 每个类别的准确率\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "axes[0, 1].bar(range(10), class_accuracy)\n",
    "axes[0, 1].set_title('各数字识别准确率')\n",
    "axes[0, 1].set_xlabel('数字')\n",
    "axes[0, 1].set_ylabel('准确率')\n",
    "axes[0, 1].set_xticks(range(10))\n",
    "\n",
    "# 3. 正确预测的样本展示\n",
    "correct_mask = y_test_mnist == y_pred_best\n",
    "correct_indices = np.where(correct_mask)[0][:6]\n",
    "\n",
    "for i, idx in enumerate(correct_indices):\n",
    "    row, col = divmod(i, 3)\n",
    "    if row < 2 and col < 3:\n",
    "        axes[row, col + (1 if row == 0 else 0)].imshow(\n",
    "            X_test_mnist[idx].reshape(28, 28), cmap='gray'\n",
    "        )\n",
    "        axes[row, col + (1 if row == 0 else 0)].set_title(\n",
    "            f'正确: {y_test_mnist[idx]}'\n",
    "        )\n",
    "        axes[row, col + (1 if row == 0 else 0)].axis('off')\n",
    "\n",
    "# 错误预测的样本展示  \n",
    "incorrect_mask = y_test_mnist != y_pred_best\n",
    "incorrect_indices = np.where(incorrect_mask)[0][:3]\n",
    "\n",
    "for i, idx in enumerate(incorrect_indices):\n",
    "    axes[1, i].imshow(X_test_mnist[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].set_title(f'错误: 真实{y_test_mnist[idx]} → 预测{y_pred_best[idx]}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.5 模型性能分析\n",
    "print(\"\\n=== 模型性能分析 ===\")\n",
    "\n",
    "# 计算各种评估指标\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test_mnist, y_pred_best, average='weighted')\n",
    "recall = recall_score(y_test_mnist, y_pred_best, average='weighted')\n",
    "f1 = f1_score(y_test_mnist, y_pred_best, average='weighted')\n",
    "\n",
    "performance_metrics = {\n",
    "    '准确率 (Accuracy)': accuracy_best,\n",
    "    '精确率 (Precision)': precision,\n",
    "    '召回率 (Recall)': recall,\n",
    "    'F1 分数': f1\n",
    "}\n",
    "\n",
    "print(\"整体性能指标:\")\n",
    "for metric, value in performance_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# 训练时间对比\n",
    "print(f\"\\n计算效率:\")\n",
    "print(f\"默认参数训练时间: {training_time:.2f} 秒\")\n",
    "print(f\"网格搜索时间: {search_time:.2f} 秒\")\n",
    "print(f\"性能提升: {((accuracy_best - accuracy_default) / accuracy_default * 100):.2f}%\")\n",
    "\n",
    "print(\"\\nSVM在MNIST上的关键发现:\")\n",
    "print(\"✓ SVM在高维图像数据上表现优秀\")\n",
    "print(\"✓ RBF核函数通常在图像分类中效果最好\")\n",
    "print(\"✓ 参数优化可以显著提升模型性能\")\n",
    "print(\"✓ SVM对特征缩放敏感，需要进行预处理\")\n",
    "print(\"✓ 支持向量的数量反映了数据的复杂度\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529a6a3",
   "metadata": {},
   "source": [
    "## 4. 多种分类算法对比\n",
    "\n",
    "除了SVM，scikit-learn还提供了多种强大的分类算法。我们将在MNIST数据集上比较不同算法的性能，帮助你理解各算法的特点和适用场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad07354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 准备多个分类器\n",
    "print(\"=== 多种分类算法对比 ===\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 使用之前的MNIST子集数据\n",
    "print(f\"使用数据集: 训练集 {X_train_mnist.shape}, 测试集 {X_test_mnist.shape}\")\n",
    "\n",
    "# 定义多个分类器\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100,), random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "# 4.2 训练和评估所有分类器\n",
    "results = {}\n",
    "training_times = {}\n",
    "\n",
    "print(\"\\n正在训练和评估各种分类器...\")\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"\\n训练 {name}...\")\n",
    "    \n",
    "    # 训练时间\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_mnist, y_train_mnist)\n",
    "    training_time = time.time() - start_time\n",
    "    training_times[name] = training_time\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = classifier.predict(X_test_mnist)\n",
    "    \n",
    "    # 评估指标\n",
    "    accuracy = accuracy_score(y_test_mnist, y_pred)\n",
    "    precision = precision_score(y_test_mnist, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_mnist, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_mnist, y_pred, average='weighted')\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"  准确率: {accuracy:.4f}\")\n",
    "    print(f\"  训练时间: {training_time:.2f}秒\")\n",
    "\n",
    "# 4.3 结果可视化和分析\n",
    "print(\"\\n=== 算法性能对比分析 ===\")\n",
    "\n",
    "# 创建结果DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"所有算法性能对比:\")\n",
    "print(results_df)\n",
    "\n",
    "# 可视化结果\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 准确率对比\n",
    "algorithms = list(results.keys())\n",
    "accuracies = [results[alg]['accuracy'] for alg in algorithms]\n",
    "\n",
    "axes[0, 0].bar(range(len(algorithms)), accuracies)\n",
    "axes[0, 0].set_title('准确率对比')\n",
    "axes[0, 0].set_ylabel('准确率')\n",
    "axes[0, 0].set_xticks(range(len(algorithms)))\n",
    "axes[0, 0].set_xticklabels(algorithms, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0, 0].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. 训练时间对比\n",
    "times = [results[alg]['training_time'] for alg in algorithms]\n",
    "\n",
    "axes[0, 1].bar(range(len(algorithms)), times, color='orange')\n",
    "axes[0, 1].set_title('训练时间对比')\n",
    "axes[0, 1].set_ylabel('训练时间 (秒)')\n",
    "axes[0, 1].set_xticks(range(len(algorithms)))\n",
    "axes[0, 1].set_xticklabels(algorithms, rotation=45, ha='right')\n",
    "axes[0, 1].set_yscale('log')  # 使用对数刻度\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 准确率vs训练时间散点图\n",
    "axes[0, 2].scatter(times, accuracies, s=100, alpha=0.7)\n",
    "for i, alg in enumerate(algorithms):\n",
    "    axes[0, 2].annotate(alg, (times[i], accuracies[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[0, 2].set_xlabel('训练时间 (秒)')\n",
    "axes[0, 2].set_ylabel('准确率')\n",
    "axes[0, 2].set_title('准确率 vs 训练时间')\n",
    "axes[0, 2].set_xscale('log')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. F1分数对比\n",
    "f1_scores = [results[alg]['f1_score'] for alg in algorithms]\n",
    "\n",
    "axes[1, 0].bar(range(len(algorithms)), f1_scores, color='green')\n",
    "axes[1, 0].set_title('F1分数对比')\n",
    "axes[1, 0].set_ylabel('F1分数')\n",
    "axes[1, 0].set_xticks(range(len(algorithms)))\n",
    "axes[1, 0].set_xticklabels(algorithms, rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. 综合性能雷达图\n",
    "from math import pi\n",
    "\n",
    "# 选择前5个算法进行雷达图展示\n",
    "top_5_algorithms = sorted(algorithms, key=lambda x: results[x]['accuracy'], reverse=True)[:5]\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "\n",
    "# 标准化指标到0-1范围\n",
    "normalized_data = {}\n",
    "for alg in top_5_algorithms:\n",
    "    normalized_data[alg] = [results[alg][metric] for metric in metrics]\n",
    "\n",
    "# 雷达图\n",
    "angles = [n / float(len(metrics)) * 2 * pi for n in range(len(metrics))]\n",
    "angles += angles[:1]  # 闭合图形\n",
    "\n",
    "axes[1, 1].set_theta_offset(pi / 2)\n",
    "axes[1, 1].set_theta_direction(-1)\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "for i, alg in enumerate(top_5_algorithms):\n",
    "    values = normalized_data[alg]\n",
    "    values += values[:1]  # 闭合图形\n",
    "    \n",
    "    axes[1, 1].plot(angles, values, 'o-', linewidth=2, label=alg, color=colors[i])\n",
    "    axes[1, 1].fill(angles, values, alpha=0.25, color=colors[i])\n",
    "\n",
    "axes[1, 1].set_xticks(angles[:-1])\n",
    "axes[1, 1].set_xticklabels(metrics)\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "axes[1, 1].set_title('前5名算法性能雷达图')\n",
    "axes[1, 1].legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# 6. 混淆矩阵对比 (选择最佳算法)\n",
    "best_algorithm = max(algorithms, key=lambda x: results[x]['accuracy'])\n",
    "best_classifier = classifiers[best_algorithm]\n",
    "y_pred_best = best_classifier.predict(X_test_mnist)\n",
    "cm_best = confusion_matrix(y_test_mnist, y_pred_best)\n",
    "\n",
    "im = axes[1, 2].imshow(cm_best, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[1, 2].set_title(f'最佳算法混淆矩阵\\n({best_algorithm})')\n",
    "axes[1, 2].set_xlabel('预测标签')\n",
    "axes[1, 2].set_ylabel('真实标签')\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(cm_best.shape[0]):\n",
    "    for j in range(cm_best.shape[1]):\n",
    "        axes[1, 2].text(j, i, format(cm_best[i, j], 'd'),\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if cm_best[i, j] > cm_best.max() / 2 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.4 算法特点总结\n",
    "print(\"\\n=== 各算法特点总结 ===\")\n",
    "\n",
    "algorithm_characteristics = {\n",
    "    'Logistic Regression': {\n",
    "        'advantages': ['快速训练', '概率输出', '线性可解释'],\n",
    "        'disadvantages': ['假设线性关系', '对特征工程敏感'],\n",
    "        'best_for': '线性可分问题、需要概率输出'\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'advantages': ['高度可解释', '无需特征缩放', '处理非线性'],\n",
    "        'disadvantages': ['容易过拟合', '对数据变化敏感'],\n",
    "        'best_for': '需要可解释性的问题'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'advantages': ['减少过拟合', '特征重要性', '鲁棒性强'],\n",
    "        'disadvantages': ['内存消耗大', '可解释性降低'],\n",
    "        'best_for': '通用分类问题、特征选择'\n",
    "    },\n",
    "    'SVM (RBF)': {\n",
    "        'advantages': ['高维数据优秀', '内存高效', '灵活核函数'],\n",
    "        'disadvantages': ['训练时间长', '参数敏感', '无概率输出'],\n",
    "        'best_for': '高维数据、小到中等样本量'\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'advantages': ['简单直观', '无训练时间', '适应局部模式'],\n",
    "        'disadvantages': ['预测速度慢', '对维度诅咒敏感', '需要特征缩放'],\n",
    "        'best_for': '小数据集、局部模式重要'\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'advantages': ['高预测精度', '处理复杂模式', '特征重要性'],\n",
    "        'disadvantages': ['训练时间长', '容易过拟合', '参数多'],\n",
    "        'best_for': '结构化数据竞赛、高精度要求'\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'advantages': ['训练极快', '小数据表现好', '多分类自然'],\n",
    "        'disadvantages': ['特征独立假设', '数值特征需要假设分布'],\n",
    "        'best_for': '文本分类、小数据集'\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'advantages': ['学习复杂模式', '自动特征学习', '灵活架构'],\n",
    "        'disadvantages': ['需要大量数据', '黑盒模型', '训练时间长'],\n",
    "        'best_for': '大数据集、复杂非线性模式'\n",
    "    }\n",
    "}\n",
    "\n",
    "for alg_name in algorithms:\n",
    "    if alg_name in algorithm_characteristics:\n",
    "        char = algorithm_characteristics[alg_name]\n",
    "        print(f\"\\n{alg_name}:\")\n",
    "        print(f\"  准确率: {results[alg_name]['accuracy']:.4f}\")\n",
    "        print(f\"  优点: {', '.join(char['advantages'])}\")\n",
    "        print(f\"  缺点: {', '.join(char['disadvantages'])}\")\n",
    "        print(f\"  适用场景: {char['best_for']}\")\n",
    "\n",
    "print(f\"\\n在MNIST手写数字识别任务中:\")\n",
    "print(f\"🏆 最佳准确率: {best_algorithm} ({results[best_algorithm]['accuracy']:.4f})\")\n",
    "print(f\"⚡ 最快训练: {min(algorithms, key=lambda x: results[x]['training_time'])} ({min(training_times.values()):.2f}秒)\")\n",
    "\n",
    "fastest_alg = min(algorithms, key=lambda x: results[x]['training_time'])\n",
    "best_tradeoff = max(algorithms, key=lambda x: results[x]['accuracy'] / results[x]['training_time'])\n",
    "\n",
    "print(f\"⚖️  最佳性价比: {best_tradeoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d728c",
   "metadata": {},
   "source": [
    "## 5. 回归算法详解\n",
    "\n",
    "回归用于预测连续数值，是机器学习的另一大类问题。我们将学习各种回归算法，并用房价预测作为实战案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 加载和准备回归数据\n",
    "print(\"=== 回归算法详解 ===\")\n",
    "\n",
    "from sklearn.datasets import load_boston, make_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 由于Boston房价数据集的一些争议，我们创建一个类似的合成数据集\n",
    "print(\"生成房价预测数据集...\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# 生成房价相关特征\n",
    "n_samples = 1000\n",
    "n_features = 8\n",
    "\n",
    "# 创建特征\n",
    "X_house, y_house = make_regression(\n",
    "    n_samples=n_samples, \n",
    "    n_features=n_features, \n",
    "    noise=10, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 创建更有意义的特征名\n",
    "feature_names = [\n",
    "    '房屋面积', '房间数量', '浴室数量', '楼层', \n",
    "    '建造年份', '地理位置评分', '学区评分', '交通便利性'\n",
    "]\n",
    "\n",
    "# 转换为DataFrame以便分析\n",
    "house_data = pd.DataFrame(X_house, columns=feature_names)\n",
    "house_data['房价'] = y_house\n",
    "\n",
    "# 为了更真实，调整数据范围\n",
    "house_data['房屋面积'] = house_data['房屋面积'] * 10 + 100  # 100-200 平米\n",
    "house_data['房间数量'] = np.abs(house_data['房间数量']) + 2   # 2-5房间\n",
    "house_data['浴室数量'] = np.abs(house_data['浴室数量']) + 1   # 1-3浴室  \n",
    "house_data['楼层'] = np.abs(house_data['楼层']) % 20 + 1      # 1-20层\n",
    "house_data['建造年份'] = 2020 - (np.abs(house_data['建造年份']) % 30)  # 1990-2020\n",
    "house_data['房价'] = house_data['房价'] * 0.01 + 50  # 调整价格范围\n",
    "\n",
    "print(f\"房价数据集信息:\")\n",
    "print(f\"样本数量: {len(house_data)}\")\n",
    "print(f\"特征数量: {len(feature_names)}\")\n",
    "print(\"\\n前5行数据:\")\n",
    "print(house_data.head())\n",
    "\n",
    "print(\"\\n数据统计:\")\n",
    "print(house_data.describe().round(2))\n",
    "\n",
    "# 相关性分析\n",
    "correlation_matrix = house_data.corr()\n",
    "\n",
    "# 可视化数据分布和相关性\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 房价分布\n",
    "axes[0, 0].hist(house_data['房价'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('房价分布')\n",
    "axes[0, 0].set_xlabel('房价')\n",
    "axes[0, 0].set_ylabel('频次')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 特征相关性热力图\n",
    "im = axes[0, 1].imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "axes[0, 1].set_title('特征相关性矩阵')\n",
    "axes[0, 1].set_xticks(range(len(house_data.columns)))\n",
    "axes[0, 1].set_yticks(range(len(house_data.columns)))\n",
    "axes[0, 1].set_xticklabels(house_data.columns, rotation=45, ha='right')\n",
    "axes[0, 1].set_yticklabels(house_data.columns)\n",
    "\n",
    "# 添加相关性数值\n",
    "for i in range(len(house_data.columns)):\n",
    "    for j in range(len(house_data.columns)):\n",
    "        text = axes[0, 1].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\" if abs(correlation_matrix.iloc[i, j]) < 0.5 else \"white\")\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 1])\n",
    "\n",
    "# 3. 房屋面积vs房价散点图\n",
    "axes[0, 2].scatter(house_data['房屋面积'], house_data['房价'], alpha=0.6)\n",
    "axes[0, 2].set_xlabel('房屋面积')\n",
    "axes[0, 2].set_ylabel('房价')\n",
    "axes[0, 2].set_title('房屋面积 vs 房价')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 房间数量vs房价箱型图\n",
    "room_groups = house_data.groupby(house_data['房间数量'].astype(int))\n",
    "room_prices = [group['房价'].values for name, group in room_groups]\n",
    "room_labels = [str(int(name)) for name, group in room_groups]\n",
    "\n",
    "axes[1, 0].boxplot(room_prices, labels=room_labels)\n",
    "axes[1, 0].set_xlabel('房间数量')\n",
    "axes[1, 0].set_ylabel('房价')\n",
    "axes[1, 0].set_title('房间数量 vs 房价分布')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. 建造年份vs房价\n",
    "axes[1, 1].scatter(house_data['建造年份'], house_data['房价'], alpha=0.6, color='green')\n",
    "axes[1, 1].set_xlabel('建造年份')\n",
    "axes[1, 1].set_ylabel('房价')\n",
    "axes[1, 1].set_title('建造年份 vs 房价')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. 特征重要性初步分析（相关系数）\n",
    "feature_importance = correlation_matrix['房价'].abs().sort_values(ascending=True)[:-1]\n",
    "axes[1, 2].barh(range(len(feature_importance)), feature_importance.values)\n",
    "axes[1, 2].set_yticks(range(len(feature_importance)))\n",
    "axes[1, 2].set_yticklabels(feature_importance.index)\n",
    "axes[1, 2].set_xlabel('与房价的相关系数(绝对值)')\n",
    "axes[1, 2].set_title('特征重要性(相关性)')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 准备训练数据\n",
    "X_house_final = house_data[feature_names]\n",
    "y_house_final = house_data['房价']\n",
    "\n",
    "# 数据分割\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = train_test_split(\n",
    "    X_house_final, y_house_final, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n数据分割结果:\")\n",
    "print(f\"训练集: {X_train_house.shape}\")\n",
    "print(f\"测试集: {X_test_house.shape}\")\n",
    "\n",
    "# 5.2 多种回归算法实现和对比\n",
    "print(\"\\n=== 多种回归算法对比 ===\")\n",
    "\n",
    "# 特征标准化\n",
    "scaler_house = StandardScaler()\n",
    "X_train_house_scaled = scaler_house.fit_transform(X_train_house)\n",
    "X_test_house_scaled = scaler_house.transform(X_test_house)\n",
    "\n",
    "# 定义回归模型\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=1.0, random_state=42),\n",
    "    'Elastic Net': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector Regression': SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "# 多项式回归（使用Pipeline）\n",
    "poly_regression = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "regressors['Polynomial Regression'] = poly_regression\n",
    "\n",
    "# 训练和评估所有回归模型\n",
    "regression_results = {}\n",
    "regression_times = {}\n",
    "\n",
    "print(\"\\n正在训练和评估各种回归模型...\")\n",
    "for name, regressor in regressors.items():\n",
    "    print(f\"\\n训练 {name}...\")\n",
    "    \n",
    "    # 选择是否使用标准化数据\n",
    "    if name in ['Ridge Regression', 'Lasso Regression', 'Elastic Net', 'Support Vector Regression']:\n",
    "        X_train_use = X_train_house_scaled\n",
    "        X_test_use = X_test_house_scaled\n",
    "    else:\n",
    "        X_train_use = X_train_house\n",
    "        X_test_use = X_test_house\n",
    "    \n",
    "    # 训练时间\n",
    "    start_time = time.time()\n",
    "    regressor.fit(X_train_use, y_train_house)\n",
    "    training_time = time.time() - start_time\n",
    "    regression_times[name] = training_time\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_house = regressor.predict(X_test_use)\n",
    "    \n",
    "    # 评估指标\n",
    "    mae = mean_absolute_error(y_test_house, y_pred_house)\n",
    "    mse = mean_squared_error(y_test_house, y_pred_house)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_house, y_pred_house)\n",
    "    \n",
    "    regression_results[name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2,\n",
    "        'Training_Time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"  R² 分数: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  训练时间: {training_time:.4f}秒\")\n",
    "\n",
    "# 5.3 回归结果可视化和分析\n",
    "print(\"\\n=== 回归结果分析 ===\")\n",
    "\n",
    "# 创建结果DataFrame\n",
    "regression_df = pd.DataFrame(regression_results).T\n",
    "print(\"所有回归算法性能对比:\")\n",
    "print(regression_df.round(4))\n",
    "\n",
    "# 可视化结果\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. R²分数对比\n",
    "models = list(regression_results.keys())\n",
    "r2_scores = [regression_results[model]['R²'] for model in models]\n",
    "\n",
    "axes[0, 0].bar(range(len(models)), r2_scores, color='lightblue')\n",
    "axes[0, 0].set_title('R² 分数对比')\n",
    "axes[0, 0].set_ylabel('R² 分数')\n",
    "axes[0, 0].set_xticks(range(len(models)))\n",
    "axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. RMSE对比\n",
    "rmse_scores = [regression_results[model]['RMSE'] for model in models]\n",
    "\n",
    "axes[0, 1].bar(range(len(models)), rmse_scores, color='lightcoral')\n",
    "axes[0, 1].set_title('RMSE对比 (越小越好)')\n",
    "axes[0, 1].set_ylabel('RMSE')\n",
    "axes[0, 1].set_xticks(range(len(models)))\n",
    "axes[0, 1].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 训练时间对比\n",
    "training_times_reg = [regression_results[model]['Training_Time'] for model in models]\n",
    "\n",
    "axes[0, 2].bar(range(len(models)), training_times_reg, color='lightgreen')\n",
    "axes[0, 2].set_title('训练时间对比')\n",
    "axes[0, 2].set_ylabel('训练时间 (秒)')\n",
    "axes[0, 2].set_xticks(range(len(models)))\n",
    "axes[0, 2].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[0, 2].set_yscale('log')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 最佳模型的预测vs真实值\n",
    "best_model_name = max(models, key=lambda x: regression_results[x]['R²'])\n",
    "best_regressor = regressors[best_model_name]\n",
    "\n",
    "# 重新预测用于绘图\n",
    "if best_model_name in ['Ridge Regression', 'Lasso Regression', 'Elastic Net', 'Support Vector Regression']:\n",
    "    y_pred_best = best_regressor.predict(X_test_house_scaled)\n",
    "else:\n",
    "    y_pred_best = best_regressor.predict(X_test_house)\n",
    "\n",
    "axes[1, 0].scatter(y_test_house, y_pred_best, alpha=0.6)\n",
    "axes[1, 0].plot([y_test_house.min(), y_test_house.max()], \n",
    "               [y_test_house.min(), y_test_house.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('真实房价')\n",
    "axes[1, 0].set_ylabel('预测房价')\n",
    "axes[1, 0].set_title(f'最佳模型预测效果\\n({best_model_name})')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. 残差分析\n",
    "residuals = y_test_house - y_pred_best\n",
    "axes[1, 1].scatter(y_pred_best, residuals, alpha=0.6)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('预测值')\n",
    "axes[1, 1].set_ylabel('残差')\n",
    "axes[1, 1].set_title('残差图')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. 性能vs复杂度分析\n",
    "complexity_scores = {\n",
    "    'Linear Regression': 1,\n",
    "    'Ridge Regression': 2,\n",
    "    'Lasso Regression': 2,\n",
    "    'Elastic Net': 3,\n",
    "    'Polynomial Regression': 4,\n",
    "    'Decision Tree': 5,\n",
    "    'Random Forest': 7,\n",
    "    'Gradient Boosting': 8,\n",
    "    'Support Vector Regression': 6\n",
    "}\n",
    "\n",
    "complexity_vals = [complexity_scores[model] for model in models]\n",
    "axes[1, 2].scatter(complexity_vals, r2_scores, s=100, alpha=0.7)\n",
    "for i, model in enumerate(models):\n",
    "    axes[1, 2].annotate(model, (complexity_vals[i], r2_scores[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[1, 2].set_xlabel('模型复杂度')\n",
    "axes[1, 2].set_ylabel('R² 分数')\n",
    "axes[1, 2].set_title('模型复杂度 vs 性能')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.4 回归算法特点总结\n",
    "print(\"\\n=== 回归算法特点总结 ===\")\n",
    "\n",
    "regression_characteristics = {\n",
    "    'Linear Regression': {\n",
    "        'description': '最简单的线性回归模型',\n",
    "        'advantages': ['可解释性强', '训练速度快', '无超参数'],\n",
    "        'disadvantages': ['假设线性关系', '对多重共线性敏感'],\n",
    "        'when_to_use': '特征数量较少、线性关系明显'\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'description': 'L2正则化的线性回归',\n",
    "        'advantages': ['防止过拟合', '处理多重共线性', '稳定性好'],\n",
    "        'disadvantages': ['系数不会为零', '仍假设线性关系'],\n",
    "        'when_to_use': '特征数量多、存在多重共线性'\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'description': 'L1正则化的线性回归',\n",
    "        'advantages': ['自动特征选择', '稀疏解', '防止过拟合'],\n",
    "        'disadvantages': ['可能选择错误特征', '不稳定'],\n",
    "        'when_to_use': '需要特征选择、稀疏模型'\n",
    "    },\n",
    "    'Elastic Net': {\n",
    "        'description': '结合L1和L2正则化',\n",
    "        'advantages': ['平衡Ridge和Lasso', '稳定的特征选择'],\n",
    "        'disadvantages': ['需要调节两个参数', '计算复杂'],\n",
    "        'when_to_use': '特征数量很多、需要稳定的特征选择'\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'description': '基于决策树的回归',\n",
    "        'advantages': ['非线性建模', '可解释性', '无需特征缩放'],\n",
    "        'disadvantages': ['容易过拟合', '对数据变化敏感'],\n",
    "        'when_to_use': '非线性关系、需要可解释性'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'description': '多个决策树的集成',\n",
    "        'advantages': ['减少过拟合', '特征重要性', '鲁棒性'],\n",
    "        'disadvantages': ['可解释性降低', '内存消耗大'],\n",
    "        'when_to_use': '通用回归问题、特征重要性分析'\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name in models[:6]:  # 展示前6个主要算法\n",
    "    if model_name in regression_characteristics:\n",
    "        char = regression_characteristics[model_name]\n",
    "        result = regression_results[model_name]\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  描述: {char['description']}\")\n",
    "        print(f\"  R² 分数: {result['R²']:.4f}\")\n",
    "        print(f\"  RMSE: {result['RMSE']:.2f}\")\n",
    "        print(f\"  优点: {', '.join(char['advantages'])}\")\n",
    "        print(f\"  缺点: {', '.join(char['disadvantages'])}\")\n",
    "        print(f\"  适用场景: {char['when_to_use']}\")\n",
    "\n",
    "print(f\"\\n房价预测任务总结:\")\n",
    "print(f\"🏆 最佳R²分数: {best_model_name} ({regression_results[best_model_name]['R²']:.4f})\")\n",
    "fastest_reg = min(models, key=lambda x: regression_results[x]['Training_Time'])\n",
    "print(f\"⚡ 最快训练: {fastest_reg} ({regression_results[fastest_reg]['Training_Time']:.4f}秒)\")\n",
    "\n",
    "print(f\"\\n回归评估指标说明:\")\n",
    "print(f\"• MAE (平均绝对误差): 预测值与真实值差异的平均值\")\n",
    "print(f\"• RMSE (均方根误差): 对大误差更敏感，单位与目标变量相同\")\n",
    "print(f\"• R² (决定系数): 模型解释方差的比例，越接近1越好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25d9af",
   "metadata": {},
   "source": [
    "## 6. 聚类算法详解\n",
    "\n",
    "聚类是无监督学习的重要分支，用于发现数据中的隐藏模式和结构。我们将学习各种聚类算法，并在客户细分场景中进行实战。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 生成客户数据用于聚类分析\n",
    "print(\"=== 聚类算法详解 ===\")\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# 生成客户消费数据\n",
    "print(\"生成客户消费行为数据...\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# 创建三个不同类型的客户群体\n",
    "n_customers = 300\n",
    "\n",
    "# 高价值客户 (收入高，消费多)\n",
    "high_value = np.random.multivariate_normal(\n",
    "    mean=[80, 120], cov=[[100, 50], [50, 200]], size=100\n",
    ")\n",
    "\n",
    "# 中等价值客户 (收入中等，消费中等)\n",
    "medium_value = np.random.multivariate_normal(\n",
    "    mean=[50, 70], cov=[[80, 30], [30, 120]], size=100\n",
    ")\n",
    "\n",
    "# 低价值客户 (收入低，消费少)\n",
    "low_value = np.random.multivariate_normal(\n",
    "    mean=[25, 35], cov=[[50, 20], [20, 80]], size=100\n",
    ")\n",
    "\n",
    "# 合并数据\n",
    "X_customers = np.vstack([high_value, medium_value, low_value])\n",
    "true_labels = np.hstack([np.zeros(100), np.ones(100), np.full(100, 2)])\n",
    "\n",
    "# 添加更多特征\n",
    "additional_features = np.random.randn(n_customers, 3)  # 添加3个额外特征\n",
    "X_customers = np.hstack([X_customers, additional_features])\n",
    "\n",
    "# 创建DataFrame\n",
    "feature_names_cluster = ['年收入(千)', '年消费(千)', '购买频率', '客户满意度', '推荐意愿']\n",
    "customer_data = pd.DataFrame(X_customers, columns=feature_names_cluster)\n",
    "\n",
    "# 确保数据为正值并调整范围\n",
    "customer_data['年收入(千)'] = np.abs(customer_data['年收入(千)']) + 20\n",
    "customer_data['年消费(千)'] = np.abs(customer_data['年消费(千)']) + 10\n",
    "customer_data['购买频率'] = np.abs(customer_data['购买频率']) * 5 + 1\n",
    "customer_data['客户满意度'] = (customer_data['客户满意度'] + 3) * 1.5  # 1-10分\n",
    "customer_data['推荐意愿'] = (customer_data['推荐意愿'] + 3) * 1.5    # 1-10分\n",
    "\n",
    "print(f\"客户数据概览:\")\n",
    "print(f\"样本数量: {len(customer_data)}\")\n",
    "print(f\"特征数量: {len(feature_names_cluster)}\")\n",
    "print(\"\\n前5行数据:\")\n",
    "print(customer_data.head())\n",
    "\n",
    "print(\"\\n数据统计:\")\n",
    "print(customer_data.describe().round(2))\n",
    "\n",
    "# 数据可视化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 收入vs消费散点图\n",
    "scatter = axes[0, 0].scatter(customer_data['年收入(千)'], customer_data['年消费(千)'], \n",
    "                           c=true_labels, cmap='viridis', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('年收入(千)')\n",
    "axes[0, 0].set_ylabel('年消费(千)')\n",
    "axes[0, 0].set_title('客户收入vs消费分布 (真实分组)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[0, 0])\n",
    "\n",
    "# 2. 各特征分布\n",
    "for i, feature in enumerate(feature_names_cluster[:4]):\n",
    "    row, col = divmod(i+1, 3)\n",
    "    if row < 2:\n",
    "        axes[row, col].hist(customer_data[feature], bins=20, alpha=0.7)\n",
    "        axes[row, col].set_title(f'{feature}分布')\n",
    "        axes[row, col].set_xlabel(feature)\n",
    "        axes[row, col].set_ylabel('频次')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. 相关性矩阵\n",
    "correlation_matrix_cluster = customer_data.corr()\n",
    "im = axes[1, 2].imshow(correlation_matrix_cluster, cmap='coolwarm', aspect='auto')\n",
    "axes[1, 2].set_title('客户特征相关性')\n",
    "axes[1, 2].set_xticks(range(len(feature_names_cluster)))\n",
    "axes[1, 2].set_yticks(range(len(feature_names_cluster)))\n",
    "axes[1, 2].set_xticklabels(feature_names_cluster, rotation=45, ha='right')\n",
    "axes[1, 2].set_yticklabels(feature_names_cluster)\n",
    "\n",
    "for i in range(len(feature_names_cluster)):\n",
    "    for j in range(len(feature_names_cluster)):\n",
    "        text = axes[1, 2].text(j, i, f'{correlation_matrix_cluster.iloc[i, j]:.2f}',\n",
    "                              ha=\"center\", va=\"center\", \n",
    "                              color=\"black\" if abs(correlation_matrix_cluster.iloc[i, j]) < 0.5 else \"white\")\n",
    "\n",
    "plt.colorbar(im, ax=axes[1, 2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 数据标准化（聚类算法对特征尺度敏感）\n",
    "scaler_cluster = StandardScaler()\n",
    "X_customers_scaled = scaler_cluster.fit_transform(customer_data)\n",
    "\n",
    "print(\"✓ 客户数据准备完成！\")\n",
    "\n",
    "# 6.2 K-means聚类详解\n",
    "print(\"\\n=== K-means聚类详解 ===\")\n",
    "\n",
    "# 确定最优聚类数量 - 肘部法则\n",
    "print(\"1. 使用肘部法则确定最优聚类数量...\")\n",
    "\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_customers_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_customers_scaled, kmeans.labels_))\n",
    "\n",
    "# 可视化肘部法则和轮廓系数\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 肘部法则\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_xlabel('聚类数量 (K)')\n",
    "axes[0].set_ylabel('簇内误差平方和 (Inertia)')\n",
    "axes[0].set_title('肘部法则')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 轮廓系数\n",
    "axes[1].plot(K_range, silhouette_scores, 'ro-')\n",
    "axes[1].set_xlabel('聚类数量 (K)')\n",
    "axes[1].set_ylabel('轮廓系数')\n",
    "axes[1].set_title('轮廓系数法')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 选择最优K值\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"基于轮廓系数的最优聚类数量: {optimal_k}\")\n",
    "\n",
    "# 使用最优K值进行K-means聚类\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans_optimal.fit_predict(X_customers_scaled)\n",
    "\n",
    "print(f\"K-means聚类结果:\")\n",
    "print(f\"聚类数量: {optimal_k}\")\n",
    "print(f\"轮廓系数: {silhouette_score(X_customers_scaled, kmeans_labels):.4f}\")\n",
    "print(f\"Calinski-Harabasz指数: {calinski_harabasz_score(X_customers_scaled, kmeans_labels):.2f}\")\n",
    "\n",
    "# 6.3 多种聚类算法对比\n",
    "print(\"\\n=== 多种聚类算法对比 ===\")\n",
    "\n",
    "# 定义多种聚类算法\n",
    "clustering_algorithms = {\n",
    "    'K-Means': KMeans(n_clusters=3, random_state=42, n_init=10),\n",
    "    'Hierarchical': AgglomerativeClustering(n_clusters=3),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
    "    'Gaussian Mixture': GaussianMixture(n_components=3, random_state=42),\n",
    "    'Spectral Clustering': SpectralClustering(n_clusters=3, random_state=42)\n",
    "}\n",
    "\n",
    "# 应用所有聚类算法\n",
    "clustering_results = {}\n",
    "cluster_labels = {}\n",
    "\n",
    "for name, algorithm in clustering_algorithms.items():\n",
    "    print(f\"应用 {name}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if name == 'Gaussian Mixture':\n",
    "        labels = algorithm.fit_predict(X_customers_scaled)\n",
    "    else:\n",
    "        labels = algorithm.fit_predict(X_customers_scaled)\n",
    "    \n",
    "    clustering_time = time.time() - start_time\n",
    "    cluster_labels[name] = labels\n",
    "    \n",
    "    # 计算评估指标\n",
    "    if len(np.unique(labels)) > 1:  # 确保有多个聚类\n",
    "        silhouette = silhouette_score(X_customers_scaled, labels)\n",
    "        calinski = calinski_harabasz_score(X_customers_scaled, labels)\n",
    "        \n",
    "        # 与真实标签比较（如果可用）\n",
    "        ari = adjusted_rand_score(true_labels, labels)\n",
    "        \n",
    "        clustering_results[name] = {\n",
    "            'silhouette_score': silhouette,\n",
    "            'calinski_harabasz': calinski,\n",
    "            'adjusted_rand_index': ari,\n",
    "            'n_clusters': len(np.unique(labels)),\n",
    "            'clustering_time': clustering_time\n",
    "        }\n",
    "    else:\n",
    "        clustering_results[name] = {\n",
    "            'silhouette_score': -1,  # 无效聚类\n",
    "            'calinski_harabasz': -1,\n",
    "            'adjusted_rand_index': -1,\n",
    "            'n_clusters': len(np.unique(labels)),\n",
    "            'clustering_time': clustering_time\n",
    "        }\n",
    "\n",
    "# 显示结果\n",
    "clustering_df = pd.DataFrame(clustering_results).T\n",
    "print(\"\\n聚类算法性能对比:\")\n",
    "print(clustering_df.round(4))\n",
    "\n",
    "# 6.4 聚类结果可视化\n",
    "print(\"\\n=== 聚类结果可视化 ===\")\n",
    "\n",
    "# 为了可视化，我们使用PCA降维到2D\n",
    "pca_viz = PCA(n_components=2, random_state=42)\n",
    "X_customers_2d = pca_viz.fit_transform(X_customers_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 绘制不同算法的聚类结果\n",
    "plot_configs = [\n",
    "    ('真实分组', true_labels),\n",
    "    ('K-Means', cluster_labels['K-Means']),\n",
    "    ('Hierarchical', cluster_labels['Hierarchical']),\n",
    "    ('DBSCAN', cluster_labels['DBSCAN']),\n",
    "    ('Gaussian Mixture', cluster_labels['Gaussian Mixture']),\n",
    "    ('Spectral Clustering', cluster_labels['Spectral Clustering'])\n",
    "]\n",
    "\n",
    "for idx, (title, labels) in enumerate(plot_configs):\n",
    "    row, col = divmod(idx, 3)\n",
    "    \n",
    "    # 处理噪声点（DBSCAN中的-1标签）\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        if label == -1:\n",
    "            # 噪声点用黑色x标记\n",
    "            mask = labels == label\n",
    "            axes[row, col].scatter(X_customers_2d[mask, 0], X_customers_2d[mask, 1], \n",
    "                                 c='black', marker='x', s=50, alpha=0.7, label='噪声')\n",
    "        else:\n",
    "            mask = labels == label\n",
    "            axes[row, col].scatter(X_customers_2d[mask, 0], X_customers_2d[mask, 1], \n",
    "                                 c=color, alpha=0.7, s=50, label=f'簇 {label}')\n",
    "    \n",
    "    axes[row, col].set_title(f'{title}')\n",
    "    axes[row, col].set_xlabel(f'PC1 ({pca_viz.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    axes[row, col].set_ylabel(f'PC2 ({pca_viz.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    axes[row, col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6.5 层次聚类树状图\n",
    "print(\"\\n=== 层次聚类分析 ===\")\n",
    "\n",
    "# 计算距离矩阵和链接矩阵\n",
    "# 为了效率，只使用部分数据绘制树状图\n",
    "sample_size = 50\n",
    "sample_indices = np.random.choice(len(X_customers_scaled), sample_size, replace=False)\n",
    "X_sample = X_customers_scaled[sample_indices]\n",
    "\n",
    "# 计算链接矩阵\n",
    "linkage_matrix = linkage(X_sample, method='ward')\n",
    "\n",
    "# 绘制树状图\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_matrix, orientation='top', distance_sort='descending')\n",
    "plt.title('层次聚类树状图 (Ward链接)')\n",
    "plt.xlabel('样本索引')\n",
    "plt.ylabel('距离')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6.6 聚类结果解释和业务应用\n",
    "print(\"\\n=== 聚类结果解释和业务应用 ===\")\n",
    "\n",
    "# 使用K-means结果进行客户细分分析\n",
    "customer_data['聚类标签'] = kmeans_labels\n",
    "\n",
    "# 各聚类的特征分析\n",
    "cluster_analysis = customer_data.groupby('聚类标签').agg({\n",
    "    '年收入(千)': ['mean', 'std'],\n",
    "    '年消费(千)': ['mean', 'std'],\n",
    "    '购买频率': ['mean', 'std'],\n",
    "    '客户满意度': ['mean', 'std'],\n",
    "    '推荐意愿': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"各客户群体特征分析:\")\n",
    "print(cluster_analysis)\n",
    "\n",
    "# 各聚类的大小\n",
    "cluster_sizes = customer_data['聚类标签'].value_counts().sort_index()\n",
    "print(f\"\\n各聚类大小:\")\n",
    "for cluster_id, size in cluster_sizes.items():\n",
    "    percentage = size / len(customer_data) * 100\n",
    "    print(f\"聚类 {cluster_id}: {size} 客户 ({percentage:.1f}%)\")\n",
    "\n",
    "# 客户群体命名和特征描述\n",
    "cluster_descriptions = {}\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = customer_data[customer_data['聚类标签'] == cluster_id]\n",
    "    avg_income = cluster_data['年收入(千)'].mean()\n",
    "    avg_spending = cluster_data['年消费(千)'].mean()\n",
    "    avg_frequency = cluster_data['购买频率'].mean()\n",
    "    \n",
    "    if avg_income > 60 and avg_spending > 80:\n",
    "        cluster_descriptions[cluster_id] = {\n",
    "            'name': '高价值客户',\n",
    "            'description': '高收入、高消费、高频率购买',\n",
    "            'strategy': '维护关系、提供VIP服务、推荐高端产品'\n",
    "        }\n",
    "    elif avg_income > 40 and avg_spending > 50:\n",
    "        cluster_descriptions[cluster_id] = {\n",
    "            'name': '潜力客户',\n",
    "            'description': '中等收入和消费，有提升空间',\n",
    "            'strategy': '推荐促销活动、提升购买频率、交叉销售'\n",
    "        }\n",
    "    else:\n",
    "        cluster_descriptions[cluster_id] = {\n",
    "            'name': '价格敏感客户',\n",
    "            'description': '收入和消费较低，价格敏感',\n",
    "            'strategy': '提供优惠活动、基础产品推荐、提升满意度'\n",
    "        }\n",
    "\n",
    "print(f\"\\n客户群体描述和营销策略:\")\n",
    "for cluster_id, desc in cluster_descriptions.items():\n",
    "    print(f\"\\n聚类 {cluster_id} - {desc['name']}:\")\n",
    "    print(f\"  特征: {desc['description']}\")\n",
    "    print(f\"  营销策略: {desc['strategy']}\")\n",
    "    print(f\"  客户数量: {cluster_sizes[cluster_id]}\")\n",
    "\n",
    "# 6.7 聚类算法特点总结\n",
    "print(f\"\\n=== 聚类算法特点总结 ===\")\n",
    "\n",
    "algorithm_comparison = {\n",
    "    'K-Means': {\n",
    "        'advantages': ['简单快速', '适合球形聚类', '可扩展性好'],\n",
    "        'disadvantages': ['需要预设K值', '对异常值敏感', '假设球形聚类'],\n",
    "        'best_for': '大数据集、球形分布、已知聚类数'\n",
    "    },\n",
    "    'Hierarchical': {\n",
    "        'advantages': ['不需要预设聚类数', '产生聚类层次', '确定性结果'],\n",
    "        'disadvantages': ['计算复杂度高', '对噪声敏感', '难以处理大数据'],\n",
    "        'best_for': '小数据集、需要聚类层次、探索性分析'\n",
    "    },\n",
    "    'DBSCAN': {\n",
    "        'advantages': ['发现任意形状聚类', '自动检测噪声', '不需要预设聚类数'],\n",
    "        'disadvantages': ['参数敏感', '密度差异大时效果差', '高维数据困难'],\n",
    "        'best_for': '噪声数据、任意形状聚类、异常检测'\n",
    "    },\n",
    "    'Gaussian Mixture': {\n",
    "        'advantages': ['软聚类(概率)', '处理椭圆形聚类', '模型选择灵活'],\n",
    "        'disadvantages': ['需要预设组件数', '对初始化敏感', '计算复杂'],\n",
    "        'best_for': '椭圆形聚类、需要概率输出、混合分布'\n",
    "    }\n",
    "}\n",
    "\n",
    "for alg_name, characteristics in algorithm_comparison.items():\n",
    "    if alg_name in clustering_results:\n",
    "        result = clustering_results[alg_name]\n",
    "        print(f\"\\n{alg_name}:\")\n",
    "        print(f\"  轮廓系数: {result['silhouette_score']:.4f}\")\n",
    "        print(f\"  优点: {', '.join(characteristics['advantages'])}\")\n",
    "        print(f\"  缺点: {', '.join(characteristics['disadvantages'])}\")\n",
    "        print(f\"  适用场景: {characteristics['best_for']}\")\n",
    "\n",
    "# 最佳聚类算法推荐\n",
    "best_clustering = max(clustering_results.keys(), \n",
    "                     key=lambda x: clustering_results[x]['silhouette_score'])\n",
    "print(f\"\\n🏆 本案例最佳聚类算法: {best_clustering}\")\n",
    "print(f\"   轮廓系数: {clustering_results[best_clustering]['silhouette_score']:.4f}\")\n",
    "\n",
    "print(f\"\\n聚类分析关键要点:\")\n",
    "print(f\"✓ 选择合适的聚类数量很重要（肘部法则、轮廓系数）\")\n",
    "print(f\"✓ 数据预处理（标准化）对聚类结果有重大影响\")\n",
    "print(f\"✓ 不同算法适用于不同的数据分布和业务场景\")\n",
    "print(f\"✓ 聚类结果需要结合业务知识进行解释和应用\")\n",
    "print(f\"✓ 评估指标要结合多个维度进行综合判断\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15765ba8",
   "metadata": {},
   "source": [
    "## 7. 降维技术详解\n",
    "\n",
    "降维是处理高维数据的重要技术，可以减少计算复杂度、避免维度诅咒、便于可视化。我们将学习PCA、t-SNE等经典降维技术。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7adfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 主成分分析 (PCA) 详解\n",
    "print(\"=== 主成分分析 (PCA) 详解 ===\")\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "# 使用MNIST数据集进行降维演示\n",
    "# 为了计算效率，使用子集\n",
    "n_samples_dim = 2000\n",
    "indices_dim = np.random.choice(len(X_mnist), n_samples_dim, replace=False)\n",
    "X_mnist_dim = X_mnist[indices_dim] / 255.0  # 标准化\n",
    "y_mnist_dim = y_mnist[indices_dim]\n",
    "\n",
    "print(f\"降维数据集信息:\")\n",
    "print(f\"原始维度: {X_mnist_dim.shape}\")\n",
    "print(f\"类别数量: {len(np.unique(y_mnist_dim))}\")\n",
    "\n",
    "# PCA分析\n",
    "print(\"\\n1. PCA主成分分析:\")\n",
    "\n",
    "# 计算所有主成分\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_mnist_dim)\n",
    "\n",
    "# 累积解释方差比\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# 可视化PCA结果\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 解释方差比\n",
    "axes[0, 0].plot(range(1, 51), pca_full.explained_variance_ratio_[:50], 'bo-', markersize=4)\n",
    "axes[0, 0].set_xlabel('主成分')\n",
    "axes[0, 0].set_ylabel('解释方差比')\n",
    "axes[0, 0].set_title('前50个主成分的解释方差比')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 累积解释方差比\n",
    "axes[0, 1].plot(range(1, 101), cumulative_variance[:100], 'ro-', markersize=3)\n",
    "axes[0, 1].axhline(y=0.95, color='green', linestyle='--', label='95%方差')\n",
    "axes[0, 1].axhline(y=0.99, color='orange', linestyle='--', label='99%方差')\n",
    "axes[0, 1].set_xlabel('主成分数量')\n",
    "axes[0, 1].set_ylabel('累积解释方差比')\n",
    "axes[0, 1].set_title('累积解释方差比')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 找到保留95%和99%方差的主成分数量\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "n_components_99 = np.argmax(cumulative_variance >= 0.99) + 1\n",
    "\n",
    "print(f\"保留95%方差需要的主成分数量: {n_components_95}\")\n",
    "print(f\"保留99%方差需要的主成分数量: {n_components_99}\")\n",
    "\n",
    "# 3. 使用不同数量的主成分进行降维\n",
    "pca_components = [2, 10, 50, 100, 200]\n",
    "reconstruction_errors = []\n",
    "\n",
    "for n_comp in pca_components:\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    X_transformed = pca.fit_transform(X_mnist_dim)\n",
    "    X_reconstructed = pca.inverse_transform(X_transformed)\n",
    "    \n",
    "    # 计算重构误差\n",
    "    error = np.mean((X_mnist_dim - X_reconstructed) ** 2)\n",
    "    reconstruction_errors.append(error)\n",
    "\n",
    "# 重构误差图\n",
    "axes[0, 2].plot(pca_components, reconstruction_errors, 'go-')\n",
    "axes[0, 2].set_xlabel('主成分数量')\n",
    "axes[0, 2].set_ylabel('重构误差 (MSE)')\n",
    "axes[0, 2].set_title('主成分数量 vs 重构误差')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 2D PCA可视化\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_mnist_dim)\n",
    "\n",
    "scatter = axes[1, 0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=y_mnist_dim, cmap='tab10', alpha=0.7)\n",
    "axes[1, 0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[1, 0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.2%} variance)')\n",
    "axes[1, 0].set_title('PCA 2D可视化')\n",
    "plt.colorbar(scatter, ax=axes[1, 0])\n",
    "\n",
    "# 5. 主成分可视化（前几个主成分看起来像什么）\n",
    "pca_viz = PCA(n_components=9)\n",
    "pca_viz.fit(X_mnist_dim)\n",
    "\n",
    "for i in range(9):\n",
    "    row, col = divmod(i, 3)\n",
    "    if row == 1 and col < 2:\n",
    "        component = pca_viz.components_[i].reshape(28, 28)\n",
    "        axes[1, col + 1].imshow(component, cmap='coolwarm')\n",
    "        axes[1, col + 1].set_title(f'主成分 {i+1}')\n",
    "        axes[1, col + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 重构效果展示\n",
    "print(\"\\n2. PCA重构效果展示:\")\n",
    "\n",
    "# 选择几个不同的主成分数量进行重构\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "\n",
    "# 原始图像\n",
    "sample_idx = 0\n",
    "original_image = X_mnist_dim[sample_idx].reshape(28, 28)\n",
    "axes[0, 0].imshow(original_image, cmap='gray')\n",
    "axes[0, 0].set_title('原始图像')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 不同主成分数量的重构\n",
    "components_to_test = [5, 10, 25, 50, 100]\n",
    "for i, n_comp in enumerate(components_to_test):\n",
    "    pca_recon = PCA(n_components=n_comp)\n",
    "    X_transform = pca_recon.fit_transform(X_mnist_dim)\n",
    "    X_recon = pca_recon.inverse_transform(X_transform)\n",
    "    \n",
    "    reconstructed_image = X_recon[sample_idx].reshape(28, 28)\n",
    "    axes[0, i+1].imshow(reconstructed_image, cmap='gray')\n",
    "    axes[0, i+1].set_title(f'{n_comp} 主成分')\n",
    "    axes[0, i+1].axis('off')\n",
    "\n",
    "# 展示更多样本\n",
    "for row in range(1, 3):\n",
    "    sample_idx = row * 100\n",
    "    original = X_mnist_dim[sample_idx].reshape(28, 28)\n",
    "    axes[row, 0].imshow(original, cmap='gray')\n",
    "    axes[row, 0].set_title(f'原始 (数字{y_mnist_dim[sample_idx]})')\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    for i, n_comp in enumerate(components_to_test):\n",
    "        pca_recon = PCA(n_components=n_comp)\n",
    "        X_transform = pca_recon.fit_transform(X_mnist_dim)\n",
    "        X_recon = pca_recon.inverse_transform(X_transform)\n",
    "        \n",
    "        reconstructed = X_recon[sample_idx].reshape(28, 28)\n",
    "        axes[row, i+1].imshow(reconstructed, cmap='gray')\n",
    "        axes[row, i+1].axis('off')\n",
    "\n",
    "plt.suptitle('PCA重构效果对比', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.2 t-SNE非线性降维\n",
    "print(\"\\n=== t-SNE非线性降维 ===\")\n",
    "\n",
    "# 为了计算效率，使用更小的子集\n",
    "n_samples_tsne = 1000\n",
    "indices_tsne = np.random.choice(len(X_mnist_dim), n_samples_tsne, replace=False)\n",
    "X_tsne_input = X_mnist_dim[indices_tsne]\n",
    "y_tsne_input = y_mnist_dim[indices_tsne]\n",
    "\n",
    "print(\"正在计算t-SNE降维...\")\n",
    "print(\"注意：t-SNE计算时间较长，请耐心等待...\")\n",
    "\n",
    "# 不同perplexity参数的t-SNE\n",
    "perplexities = [5, 30, 50]\n",
    "tsne_results = {}\n",
    "\n",
    "for perp in perplexities:\n",
    "    print(f\"计算 perplexity={perp} 的t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, n_iter=1000)\n",
    "    X_tsne = tsne.fit_transform(X_tsne_input)\n",
    "    tsne_results[perp] = X_tsne\n",
    "\n",
    "# 比较PCA和t-SNE结果\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# PCA 2D结果（从之前计算的结果中取子集）\n",
    "pca_subset = X_pca_2d[indices_tsne]\n",
    "scatter = axes[0, 0].scatter(pca_subset[:, 0], pca_subset[:, 1], c=y_tsne_input, cmap='tab10', alpha=0.7)\n",
    "axes[0, 0].set_title('PCA 2D')\n",
    "axes[0, 0].set_xlabel('PC1')\n",
    "axes[0, 0].set_ylabel('PC2')\n",
    "plt.colorbar(scatter, ax=axes[0, 0])\n",
    "\n",
    "# 不同perplexity的t-SNE结果\n",
    "for idx, perp in enumerate(perplexities):\n",
    "    row, col = divmod(idx + 1, 2)\n",
    "    X_tsne = tsne_results[perp]\n",
    "    \n",
    "    scatter = axes[row, col].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_tsne_input, cmap='tab10', alpha=0.7)\n",
    "    axes[row, col].set_title(f't-SNE (perplexity={perp})')\n",
    "    axes[row, col].set_xlabel('t-SNE 1')\n",
    "    axes[row, col].set_ylabel('t-SNE 2')\n",
    "    plt.colorbar(scatter, ax=axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.3 特征选择技术\n",
    "print(\"\\n=== 特征选择技术 ===\")\n",
    "\n",
    "# 使用完整的MNIST子集进行特征选择\n",
    "print(\"应用各种特征选择方法...\")\n",
    "\n",
    "# 1. 方差阈值选择\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_selector = VarianceThreshold(threshold=0.1)\n",
    "X_var_selected = var_selector.fit_transform(X_mnist_dim)\n",
    "\n",
    "print(f\"方差阈值选择:\")\n",
    "print(f\"原始特征数: {X_mnist_dim.shape[1]}\")\n",
    "print(f\"选择后特征数: {X_var_selected.shape[1]}\")\n",
    "print(f\"保留特征比例: {X_var_selected.shape[1]/X_mnist_dim.shape[1]:.2%}\")\n",
    "\n",
    "# 2. 单变量特征选择\n",
    "univariate_selectors = {\n",
    "    'chi2': SelectKBest(score_func=chi2, k=100),\n",
    "    'f_classif': SelectKBest(score_func=f_classif, k=100),\n",
    "    'mutual_info': SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "}\n",
    "\n",
    "feature_selection_results = {}\n",
    "\n",
    "for name, selector in univariate_selectors.items():\n",
    "    print(f\"\\n{name} 特征选择:\")\n",
    "    X_selected = selector.fit_transform(X_mnist_dim, y_mnist_dim)\n",
    "    \n",
    "    # 获取特征得分\n",
    "    scores = selector.scores_\n",
    "    selected_features = selector.get_support()\n",
    "    \n",
    "    feature_selection_results[name] = {\n",
    "        'X_selected': X_selected,\n",
    "        'scores': scores,\n",
    "        'selected_features': selected_features,\n",
    "        'n_features': X_selected.shape[1]\n",
    "    }\n",
    "    \n",
    "    print(f\"选择的特征数: {X_selected.shape[1]}\")\n",
    "    print(f\"平均特征得分: {np.mean(scores):.2f}\")\n",
    "\n",
    "# 3. 递归特征消除 (RFE)\n",
    "print(f\"\\n递归特征消除 (RFE):\")\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# 使用逻辑回归作为基估计器\n",
    "estimator = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rfe_selector = RFE(estimator=estimator, n_features_to_select=100, step=50)\n",
    "\n",
    "X_rfe_selected = rfe_selector.fit_transform(X_mnist_dim, y_mnist_dim)\n",
    "print(f\"RFE选择的特征数: {X_rfe_selected.shape[1]}\")\n",
    "\n",
    "# 7.4 特征选择效果评估\n",
    "print(\"\\n=== 特征选择效果评估 ===\")\n",
    "\n",
    "# 比较不同特征选择方法对分类性能的影响\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "feature_sets = {\n",
    "    '原始特征': X_mnist_dim,\n",
    "    '方差阈值': X_var_selected,\n",
    "    'Chi2选择': feature_selection_results['chi2']['X_selected'],\n",
    "    'F分类选择': feature_selection_results['f_classif']['X_selected'],\n",
    "    'RFE选择': X_rfe_selected,\n",
    "    'PCA (100维)': PCA(n_components=100).fit_transform(X_mnist_dim)\n",
    "}\n",
    "\n",
    "# 使用逻辑回归进行交叉验证\n",
    "classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "cv_results = {}\n",
    "\n",
    "print(\"评估不同特征选择方法的分类性能...\")\n",
    "for name, X_features in feature_sets.items():\n",
    "    print(f\"评估 {name}...\")\n",
    "    scores = cross_val_score(classifier, X_features, y_mnist_dim, cv=3, scoring='accuracy')\n",
    "    cv_results[name] = {\n",
    "        'mean_accuracy': scores.mean(),\n",
    "        'std_accuracy': scores.std(),\n",
    "        'n_features': X_features.shape[1]\n",
    "    }\n",
    "\n",
    "# 可视化特征选择效果\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. 准确率对比\n",
    "methods = list(cv_results.keys())\n",
    "accuracies = [cv_results[method]['mean_accuracy'] for method in methods]\n",
    "errors = [cv_results[method]['std_accuracy'] for method in methods]\n",
    "\n",
    "axes[0, 0].bar(range(len(methods)), accuracies, yerr=errors, capsize=5)\n",
    "axes[0, 0].set_title('不同特征选择方法的分类准确率')\n",
    "axes[0, 0].set_ylabel('准确率')\n",
    "axes[0, 0].set_xticks(range(len(methods)))\n",
    "axes[0, 0].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 添加数值标签\n",
    "for i, (acc, err) in enumerate(zip(accuracies, errors)):\n",
    "    axes[0, 0].text(i, acc + err + 0.005, f'{acc:.3f}±{err:.3f}', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. 特征数量对比\n",
    "n_features = [cv_results[method]['n_features'] for method in methods]\n",
    "axes[0, 1].bar(range(len(methods)), n_features, color='orange')\n",
    "axes[0, 1].set_title('特征数量对比')\n",
    "axes[0, 1].set_ylabel('特征数量')\n",
    "axes[0, 1].set_xticks(range(len(methods)))\n",
    "axes[0, 1].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 准确率vs特征数量\n",
    "axes[1, 0].scatter(n_features, accuracies, s=100, alpha=0.7)\n",
    "for i, method in enumerate(methods):\n",
    "    axes[1, 0].annotate(method, (n_features[i], accuracies[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[1, 0].set_xlabel('特征数量')\n",
    "axes[1, 0].set_ylabel('准确率')\n",
    "axes[1, 0].set_title('准确率 vs 特征数量')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 特征重要性可视化（以Chi2为例）\n",
    "chi2_scores = feature_selection_results['chi2']['scores']\n",
    "feature_importance_image = chi2_scores.reshape(28, 28)\n",
    "im = axes[1, 1].imshow(feature_importance_image, cmap='hot', interpolation='nearest')\n",
    "axes[1, 1].set_title('Chi2特征重要性热力图')\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.5 降维技术总结\n",
    "print(\"\\n=== 降维技术总结 ===\")\n",
    "\n",
    "dimensionality_reduction_summary = {\n",
    "    'PCA': {\n",
    "        'type': '线性降维',\n",
    "        'advantages': ['快速计算', '可解释性', '保留最大方差', '可逆变换'],\n",
    "        'disadvantages': ['线性假设', '可能丢失非线性结构'],\n",
    "        'best_for': '数据预处理、噪声减少、压缩',\n",
    "        'parameters': '主成分数量'\n",
    "    },\n",
    "    't-SNE': {\n",
    "        'type': '非线性降维',\n",
    "        'advantages': ['保留局部结构', '可视化效果好', '发现非线性模式'],\n",
    "        'disadvantages': ['计算复杂', '不可逆', '对参数敏感'],\n",
    "        'best_for': '数据可视化、聚类分析',\n",
    "        'parameters': 'perplexity, learning_rate'\n",
    "    },\n",
    "    '方差阈值': {\n",
    "        'type': '特征选择',\n",
    "        'advantages': ['简单快速', '移除无用特征', '减少维度'],\n",
    "        'disadvantages': ['可能移除有用特征', '不考虑目标变量'],\n",
    "        'best_for': '预处理步骤、移除常数特征',\n",
    "        'parameters': '方差阈值'\n",
    "    },\n",
    "    '单变量选择': {\n",
    "        'type': '特征选择',\n",
    "        'advantages': ['考虑目标变量', '统计显著性', '可解释'],\n",
    "        'disadvantages': ['忽略特征交互', '可能选择冗余特征'],\n",
    "        'best_for': '初步特征筛选、理解特征重要性',\n",
    "        'parameters': '评分函数、特征数量'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"降维技术对比:\")\n",
    "for technique, info in dimensionality_reduction_summary.items():\n",
    "    print(f\"\\n{technique} ({info['type']}):\")\n",
    "    print(f\"  优点: {', '.join(info['advantages'])}\")\n",
    "    print(f\"  缺点: {', '.join(info['disadvantages'])}\")\n",
    "    print(f\"  适用场景: {info['best_for']}\")\n",
    "    print(f\"  关键参数: {info['parameters']}\")\n",
    "\n",
    "# 性能总结\n",
    "print(f\"\\n本案例性能总结:\")\n",
    "best_method = max(cv_results.keys(), key=lambda x: cv_results[x]['mean_accuracy'])\n",
    "most_efficient = min(cv_results.keys(), key=lambda x: cv_results[x]['n_features'])\n",
    "\n",
    "print(f\"🏆 最佳准确率: {best_method} ({cv_results[best_method]['mean_accuracy']:.4f})\")\n",
    "print(f\"⚡ 最少特征: {most_efficient} ({cv_results[most_efficient]['n_features']} 特征)\")\n",
    "\n",
    "print(f\"\\n降维技术选择建议:\")\n",
    "print(f\"• 数据预处理: 使用PCA或方差阈值\")\n",
    "print(f\"• 可视化分析: 使用t-SNE或PCA\")\n",
    "print(f\"• 特征选择: 结合单变量选择和RFE\")\n",
    "print(f\"• 计算效率: 优先考虑PCA和方差阈值\")\n",
    "print(f\"• 可解释性: 选择PCA或单变量特征选择\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12903612",
   "metadata": {},
   "source": [
    "## 8. 模型选择与评估\n",
    "\n",
    "模型选择和评估是机器学习的核心环节。我们将学习交叉验证、网格搜索、性能评估指标等关键技术，确保模型的可靠性和泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 交叉验证详解\n",
    "print(\"=== 交叉验证详解 ===\")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    KFold, StratifiedKFold, LeaveOneOut, ShuffleSplit,\n",
    "    cross_val_score, cross_validate, validation_curve, learning_curve\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# 使用之前的MNIST子集数据\n",
    "print(f\"使用数据集: {X_mnist_dim.shape}\")\n",
    "\n",
    "# 准备一个基础分类器\n",
    "base_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# 8.1.1 不同交叉验证策略\n",
    "print(\"\\n1. 不同交叉验证策略对比:\")\n",
    "\n",
    "cv_strategies = {\n",
    "    'KFold(5)': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    'StratifiedKFold(5)': StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    'KFold(10)': KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    'ShuffleSplit': ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "for name, cv_strategy in cv_strategies.items():\n",
    "    print(f\"  评估 {name}...\")\n",
    "    scores = cross_val_score(base_classifier, X_mnist_dim, y_mnist_dim, \n",
    "                           cv=cv_strategy, scoring='accuracy')\n",
    "    cv_results[name] = {\n",
    "        'scores': scores,\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std()\n",
    "    }\n",
    "\n",
    "# 可视化交叉验证结果\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. 交叉验证得分对比\n",
    "strategies = list(cv_results.keys())\n",
    "means = [cv_results[s]['mean'] for s in strategies]\n",
    "stds = [cv_results[s]['std'] for s in strategies]\n",
    "\n",
    "axes[0, 0].bar(range(len(strategies)), means, yerr=stds, capsize=5)\n",
    "axes[0, 0].set_title('不同交叉验证策略的准确率对比')\n",
    "axes[0, 0].set_ylabel('准确率')\n",
    "axes[0, 0].set_xticks(range(len(strategies)))\n",
    "axes[0, 0].set_xticklabels(strategies, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    axes[0, 0].text(i, mean + std + 0.005, f'{mean:.3f}±{std:.3f}', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. 得分分布箱型图\n",
    "score_data = [cv_results[s]['scores'] for s in strategies]\n",
    "axes[0, 1].boxplot(score_data, labels=strategies)\n",
    "axes[0, 1].set_title('交叉验证得分分布')\n",
    "axes[0, 1].set_ylabel('准确率')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 8.1.2 多指标交叉验证\n",
    "print(\"\\n2. 多指标交叉验证:\")\n",
    "\n",
    "# 定义多个评估指标\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro'\n",
    "}\n",
    "\n",
    "# 使用StratifiedKFold进行多指标评估\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "multi_metric_results = cross_validate(\n",
    "    base_classifier, X_mnist_dim, y_mnist_dim,\n",
    "    cv=skf, scoring=scoring_metrics, return_train_score=True\n",
    ")\n",
    "\n",
    "# 3. 训练集vs验证集性能对比\n",
    "train_test_comparison = {}\n",
    "for metric in scoring_metrics.keys():\n",
    "    train_scores = multi_metric_results[f'train_{metric}']\n",
    "    test_scores = multi_metric_results[f'test_{metric}']\n",
    "    \n",
    "    train_test_comparison[metric] = {\n",
    "        'train_mean': train_scores.mean(),\n",
    "        'train_std': train_scores.std(),\n",
    "        'test_mean': test_scores.mean(),\n",
    "        'test_std': test_scores.std(),\n",
    "        'overfitting': train_scores.mean() - test_scores.mean()\n",
    "    }\n",
    "\n",
    "# 可视化训练集vs测试集性能\n",
    "metrics = list(train_test_comparison.keys())\n",
    "train_means = [train_test_comparison[m]['train_mean'] for m in metrics]\n",
    "test_means = [train_test_comparison[m]['test_mean'] for m in metrics]\n",
    "train_stds = [train_test_comparison[m]['train_std'] for m in metrics]\n",
    "test_stds = [train_test_comparison[m]['test_std'] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 0].bar(x - width/2, train_means, width, yerr=train_stds, label='训练集', alpha=0.8)\n",
    "axes[1, 0].bar(x + width/2, test_means, width, yerr=test_stds, label='验证集', alpha=0.8)\n",
    "axes[1, 0].set_title('训练集 vs 验证集性能对比')\n",
    "axes[1, 0].set_ylabel('得分')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(metrics)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 过拟合程度分析\n",
    "overfitting_scores = [train_test_comparison[m]['overfitting'] for m in metrics]\n",
    "bars = axes[1, 1].bar(range(len(metrics)), overfitting_scores)\n",
    "axes[1, 1].set_title('过拟合程度分析 (训练-验证)')\n",
    "axes[1, 1].set_ylabel('性能差异')\n",
    "axes[1, 1].set_xticks(range(len(metrics)))\n",
    "axes[1, 1].set_xticklabels(metrics)\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 标记过拟合程度\n",
    "for i, score in enumerate(overfitting_scores):\n",
    "    color = 'red' if score > 0.05 else 'green'\n",
    "    axes[1, 1].text(i, score + 0.001, f'{score:.3f}', \n",
    "                    ha='center', va='bottom', color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"交叉验证结果分析:\")\n",
    "for strategy, result in cv_results.items():\n",
    "    print(f\"{strategy}: {result['mean']:.4f} ± {result['std']:.4f}\")\n",
    "\n",
    "print(\"\\n多指标评估结果:\")\n",
    "for metric, result in train_test_comparison.items():\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  训练集: {result['train_mean']:.4f} ± {result['train_std']:.4f}\")\n",
    "    print(f\"  验证集: {result['test_mean']:.4f} ± {result['test_std']:.4f}\")\n",
    "    print(f\"  过拟合程度: {result['overfitting']:.4f}\")\n",
    "\n",
    "# 8.2 网格搜索和随机搜索\n",
    "print(\"\\n=== 网格搜索和随机搜索 ===\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 为了演示效果，我们使用随机森林分类器\n",
    "print(\"1. 网格搜索超参数优化:\")\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 创建随机森林分类器\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 网格搜索\n",
    "print(\"正在进行网格搜索...\")\n",
    "grid_search = GridSearchCV(\n",
    "    rf_classifier, param_grid_rf, \n",
    "    cv=3, scoring='accuracy', \n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "# 使用较小的数据集以节省时间\n",
    "indices_grid = np.random.choice(len(X_mnist_dim), 1000, replace=False)\n",
    "X_grid = X_mnist_dim[indices_grid]\n",
    "y_grid = y_mnist_dim[indices_grid]\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_grid, y_grid)\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f\"网格搜索完成，耗时: {grid_time:.2f}秒\")\n",
    "print(f\"最佳参数: {grid_search.best_params_}\")\n",
    "print(f\"最佳得分: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 2. 随机搜索\n",
    "print(\"\\n2. 随机搜索超参数优化:\")\n",
    "\n",
    "# 定义参数分布\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# 随机搜索\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_classifier, param_dist_rf,\n",
    "    n_iter=20, cv=3, scoring='accuracy',\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"正在进行随机搜索...\")\n",
    "start_time = time.time()\n",
    "random_search.fit(X_grid, y_grid)\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"随机搜索完成，耗时: {random_time:.2f}秒\")\n",
    "print(f\"最佳参数: {random_search.best_params_}\")\n",
    "print(f\"最佳得分: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 8.3 学习曲线分析\n",
    "print(\"\\n=== 学习曲线分析 ===\")\n",
    "\n",
    "# 计算学习曲线\n",
    "print(\"计算学习曲线...\")\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "# 使用最优的随机森林模型\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "train_sizes_abs, train_scores_lc, val_scores_lc = learning_curve(\n",
    "    best_rf, X_grid, y_grid,\n",
    "    train_sizes=train_sizes, cv=3,\n",
    "    scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "# 计算验证曲线\n",
    "print(\"计算验证曲线...\")\n",
    "param_name = 'n_estimators'\n",
    "param_range = [10, 50, 100, 150, 200, 250, 300]\n",
    "\n",
    "train_scores_vc, val_scores_vc = validation_curve(\n",
    "    RandomForestClassifier(random_state=42), X_grid, y_grid,\n",
    "    param_name=param_name, param_range=param_range,\n",
    "    cv=3, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "# 可视化学习曲线和验证曲线\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. 学习曲线\n",
    "train_mean_lc = np.mean(train_scores_lc, axis=1)\n",
    "train_std_lc = np.std(train_scores_lc, axis=1)\n",
    "val_mean_lc = np.mean(val_scores_lc, axis=1)\n",
    "val_std_lc = np.std(val_scores_lc, axis=1)\n",
    "\n",
    "axes[0, 0].plot(train_sizes_abs, train_mean_lc, 'o-', color='blue', label='训练集')\n",
    "axes[0, 0].fill_between(train_sizes_abs, train_mean_lc - train_std_lc, \n",
    "                       train_mean_lc + train_std_lc, alpha=0.1, color='blue')\n",
    "\n",
    "axes[0, 0].plot(train_sizes_abs, val_mean_lc, 'o-', color='red', label='验证集')\n",
    "axes[0, 0].fill_between(train_sizes_abs, val_mean_lc - val_std_lc, \n",
    "                       val_mean_lc + val_std_lc, alpha=0.1, color='red')\n",
    "\n",
    "axes[0, 0].set_xlabel('训练集大小')\n",
    "axes[0, 0].set_ylabel('准确率')\n",
    "axes[0, 0].set_title('学习曲线')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 验证曲线\n",
    "train_mean_vc = np.mean(train_scores_vc, axis=1)\n",
    "train_std_vc = np.std(train_scores_vc, axis=1)\n",
    "val_mean_vc = np.mean(val_scores_vc, axis=1)\n",
    "val_std_vc = np.std(val_scores_vc, axis=1)\n",
    "\n",
    "axes[0, 1].plot(param_range, train_mean_vc, 'o-', color='blue', label='训练集')\n",
    "axes[0, 1].fill_between(param_range, train_mean_vc - train_std_vc, \n",
    "                       train_mean_vc + train_std_vc, alpha=0.1, color='blue')\n",
    "\n",
    "axes[0, 1].plot(param_range, val_mean_vc, 'o-', color='red', label='验证集')\n",
    "axes[0, 1].fill_between(param_range, val_mean_vc - val_std_vc, \n",
    "                       val_mean_vc + val_std_vc, alpha=0.1, color='red')\n",
    "\n",
    "axes[0, 1].set_xlabel(f'{param_name}')\n",
    "axes[0, 1].set_ylabel('准确率')\n",
    "axes[0, 1].set_title('验证曲线')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 网格搜索vs随机搜索效率对比\n",
    "search_comparison = {\n",
    "    '网格搜索': {\n",
    "        'time': grid_time,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'n_combinations': len(grid_search.cv_results_['params'])\n",
    "    },\n",
    "    '随机搜索': {\n",
    "        'time': random_time,\n",
    "        'best_score': random_search.best_score_,\n",
    "        'n_combinations': 20\n",
    "    }\n",
    "}\n",
    "\n",
    "methods = list(search_comparison.keys())\n",
    "times = [search_comparison[m]['time'] for m in methods]\n",
    "scores = [search_comparison[m]['best_score'] for m in methods]\n",
    "\n",
    "# 时间对比\n",
    "axes[1, 0].bar(methods, times, color=['blue', 'orange'])\n",
    "axes[1, 0].set_title('搜索时间对比')\n",
    "axes[1, 0].set_ylabel('时间 (秒)')\n",
    "for i, time_val in enumerate(times):\n",
    "    axes[1, 0].text(i, time_val + 0.1, f'{time_val:.1f}s', ha='center', va='bottom')\n",
    "\n",
    "# 得分对比\n",
    "axes[1, 1].bar(methods, scores, color=['blue', 'orange'])\n",
    "axes[1, 1].set_title('最佳得分对比')\n",
    "axes[1, 1].set_ylabel('准确率')\n",
    "for i, score in enumerate(scores):\n",
    "    axes[1, 1].text(i, score + 0.001, f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8.4 详细的模型评估指标\n",
    "print(\"\\n=== 详细的模型评估指标 ===\")\n",
    "\n",
    "# 使用最佳模型进行详细评估\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_detailed = best_model.predict(X_test_mnist)\n",
    "y_pred_proba = best_model.predict_proba(X_test_mnist)\n",
    "\n",
    "# 计算各种评估指标\n",
    "evaluation_metrics = {\n",
    "    'accuracy': accuracy_score(y_test_mnist, y_pred_detailed),\n",
    "    'precision_macro': precision_score(y_test_mnist, y_pred_detailed, average='macro'),\n",
    "    'precision_micro': precision_score(y_test_mnist, y_pred_detailed, average='micro'),\n",
    "    'precision_weighted': precision_score(y_test_mnist, y_pred_detailed, average='weighted'),\n",
    "    'recall_macro': recall_score(y_test_mnist, y_pred_detailed, average='macro'),\n",
    "    'recall_micro': recall_score(y_test_mnist, y_pred_detailed, average='micro'),\n",
    "    'recall_weighted': recall_score(y_test_mnist, y_pred_detailed, average='weighted'),\n",
    "    'f1_macro': f1_score(y_test_mnist, y_pred_detailed, average='macro'),\n",
    "    'f1_micro': f1_score(y_test_mnist, y_pred_detailed, average='micro'),\n",
    "    'f1_weighted': f1_score(y_test_mnist, y_pred_detailed, average='weighted')\n",
    "}\n",
    "\n",
    "print(\"详细评估指标:\")\n",
    "for metric, value in evaluation_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# 分类报告\n",
    "print(f\"\\n分类报告:\")\n",
    "print(classification_report(y_test_mnist, y_pred_detailed))\n",
    "\n",
    "# 8.5 模型选择最佳实践总结\n",
    "print(\"\\n=== 模型选择最佳实践总结 ===\")\n",
    "\n",
    "best_practices = {\n",
    "    '数据分割': [\n",
    "        '使用分层抽样保证类别平衡',\n",
    "        '留出独立的测试集',\n",
    "        '训练集用于模型训练，验证集用于模型选择'\n",
    "    ],\n",
    "    '交叉验证': [\n",
    "        '分类问题使用StratifiedKFold',\n",
    "        '小数据集使用LeaveOneOut',\n",
    "        '大数据集使用ShuffleSplit提高效率'\n",
    "    ],\n",
    "    '超参数优化': [\n",
    "        '先使用随机搜索快速定位区域',\n",
    "        '再使用网格搜索精细优化',\n",
    "        '考虑使用贝叶斯优化（hyperopt等）'\n",
    "    ],\n",
    "    '模型评估': [\n",
    "        '使用多个评估指标综合判断',\n",
    "        '关注训练集和验证集的性能差异',\n",
    "        '绘制学习曲线诊断过拟合/欠拟合'\n",
    "    ],\n",
    "    '模型选择': [\n",
    "        '简单模型优于复杂模型（奥卡姆剃刀）',\n",
    "        '考虑模型的可解释性需求',\n",
    "        '平衡性能、训练时间和预测时间'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"模型选择最佳实践:\")\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"  • {practice}\")\n",
    "\n",
    "# 常见评估指标解释\n",
    "print(f\"\\n评估指标解释:\")\n",
    "metric_explanations = {\n",
    "    'Accuracy': '正确分类的样本比例，适用于类别平衡的数据',\n",
    "    'Precision': '预测为正类中真正正类的比例，关注误报',\n",
    "    'Recall': '真正正类中被正确预测的比例，关注漏报',\n",
    "    'F1-Score': 'Precision和Recall的调和平均数',\n",
    "    'Macro平均': '各类别指标的算术平均，给每个类别相同权重',\n",
    "    'Micro平均': '所有样本的全局指标，给每个样本相同权重',\n",
    "    'Weighted平均': '按类别样本数加权的平均，适用于不平衡数据'\n",
    "}\n",
    "\n",
    "for metric, explanation in metric_explanations.items():\n",
    "    print(f\"• {metric}: {explanation}\")\n",
    "\n",
    "print(f\"\\n本案例总结:\")\n",
    "print(f\"✓ 使用了{len(cv_strategies)}种交叉验证策略\")\n",
    "print(f\"✓ 网格搜索评估了{search_comparison['网格搜索']['n_combinations']}种参数组合\")\n",
    "print(f\"✓ 随机搜索在{random_time:.1f}秒内找到了接近最优的解\")\n",
    "print(f\"✓ 最终模型在测试集上的准确率: {evaluation_metrics['accuracy']:.4f}\")\n",
    "print(f\"✓ 学习曲线显示模型具有良好的泛化能力\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad19d7e",
   "metadata": {},
   "source": [
    "## 9. 综合项目案例：完整机器学习流程\n",
    "\n",
    "将前面学到的所有技术整合，构建一个完整的机器学习项目。从数据探索到模型部署，体现真实项目的完整流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 项目初始化和数据探索\n",
    "print(\"=== 综合项目案例：MNIST手写数字识别完整流程 ===\")\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 项目配置\n",
    "PROJECT_CONFIG = {\n",
    "    'project_name': 'MNIST_Digit_Recognition',\n",
    "    'version': '1.0',\n",
    "    'author': 'ML_Tutorial',\n",
    "    'created_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'target_accuracy': 0.95,\n",
    "    'max_training_time': 300  # 秒\n",
    "}\n",
    "\n",
    "print(f\"项目: {PROJECT_CONFIG['project_name']} v{PROJECT_CONFIG['version']}\")\n",
    "print(f\"目标准确率: {PROJECT_CONFIG['target_accuracy']}\")\n",
    "print(f\"最大训练时间: {PROJECT_CONFIG['max_training_time']}秒\")\n",
    "\n",
    "# 使用完整的MNIST数据集（限制大小以节省计算时间）\n",
    "n_samples_final = 10000\n",
    "indices_final = np.random.choice(len(X_mnist), n_samples_final, replace=False)\n",
    "X_project = X_mnist[indices_final]\n",
    "y_project = y_mnist[indices_final]\n",
    "\n",
    "print(f\"\\n数据集信息:\")\n",
    "print(f\"样本数量: {X_project.shape[0]}\")\n",
    "print(f\"特征数量: {X_project.shape[1]}\")\n",
    "print(f\"类别数量: {len(np.unique(y_project))}\")\n",
    "\n",
    "# 9.1.1 探索性数据分析 (EDA)\n",
    "print(\"\\n步骤1: 探索性数据分析\")\n",
    "\n",
    "# 类别分布\n",
    "class_distribution = pd.Series(y_project).value_counts().sort_index()\n",
    "print(\"类别分布:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# 数据质量检查\n",
    "print(f\"\\n数据质量检查:\")\n",
    "print(f\"缺失值: {np.isnan(X_project).sum()}\")\n",
    "print(f\"特征值范围: {X_project.min()} - {X_project.max()}\")\n",
    "print(f\"零值比例: {(X_project == 0).mean():.2%}\")\n",
    "\n",
    "# 可视化数据分布\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. 类别分布\n",
    "axes[0, 0].bar(class_distribution.index, class_distribution.values)\n",
    "axes[0, 0].set_title('类别分布')\n",
    "axes[0, 0].set_xlabel('数字')\n",
    "axes[0, 0].set_ylabel('样本数量')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 像素值分布\n",
    "axes[0, 1].hist(X_project.flatten(), bins=50, alpha=0.7)\n",
    "axes[0, 1].set_title('像素值分布')\n",
    "axes[0, 1].set_xlabel('像素值')\n",
    "axes[0, 1].set_ylabel('频次')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 每个样本的非零像素数量\n",
    "non_zero_pixels = np.sum(X_project > 0, axis=1)\n",
    "axes[0, 2].hist(non_zero_pixels, bins=30, alpha=0.7, color='green')\n",
    "axes[0, 2].set_title('每个样本的非零像素数量')\n",
    "axes[0, 2].set_xlabel('非零像素数')\n",
    "axes[0, 2].set_ylabel('频次')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4-6. 展示每个数字的典型样本\n",
    "for i in range(3):\n",
    "    digit = i * 3\n",
    "    if digit < 10:\n",
    "        # 找到该数字的样本\n",
    "        digit_indices = np.where(y_project == digit)[0]\n",
    "        if len(digit_indices) > 0:\n",
    "            sample_idx = digit_indices[0]\n",
    "            image = X_project[sample_idx].reshape(28, 28)\n",
    "            axes[1, i].imshow(image, cmap='gray')\n",
    "            axes[1, i].set_title(f'数字 {digit} 样本')\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9.2 数据预处理流水线\n",
    "print(\"\\n步骤2: 构建数据预处理流水线\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 2.1 数据分割\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_project, y_project, test_size=0.2, random_state=42, stratify=y_project\n",
    ")\n",
    "\n",
    "print(f\"数据分割结果:\")\n",
    "print(f\"训练集: {X_train_final.shape}\")\n",
    "print(f\"测试集: {X_test_final.shape}\")\n",
    "\n",
    "# 2.2 创建预处理流水线\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(score_func=chi2, k=400))\n",
    "])\n",
    "\n",
    "print(\"预处理流水线组件:\")\n",
    "print(\"1. 标准化 (StandardScaler)\")\n",
    "print(\"2. 特征选择 (SelectKBest, k=400)\")\n",
    "\n",
    "# 应用预处理\n",
    "print(\"\\n应用预处理流水线...\")\n",
    "X_train_processed = preprocessing_pipeline.fit_transform(X_train_final, y_train_final)\n",
    "X_test_processed = preprocessing_pipeline.transform(X_test_final)\n",
    "\n",
    "print(f\"预处理后特征数量: {X_train_processed.shape[1]}\")\n",
    "\n",
    "# 9.3 模型候选池和基准测试\n",
    "print(\"\\n步骤3: 模型候选池和基准测试\")\n",
    "\n",
    "# 定义候选模型\n",
    "candidate_models = {\n",
    "    'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM_RBF': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Gradient_Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# 基准测试\n",
    "baseline_results = {}\n",
    "print(\"进行基准测试...\")\n",
    "\n",
    "for name, model in candidate_models.items():\n",
    "    print(f\"测试 {name}...\")\n",
    "    \n",
    "    # 使用3折交叉验证快速评估\n",
    "    start_time = time.time()\n",
    "    cv_scores = cross_val_score(model, X_train_processed, y_train_final, \n",
    "                               cv=3, scoring='accuracy')\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"  准确率: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    print(f\"  训练时间: {training_time:.2f}秒\")\n",
    "\n",
    "# 选择最有前景的模型\n",
    "best_baseline_model = max(baseline_results.keys(), \n",
    "                         key=lambda x: baseline_results[x]['cv_mean'])\n",
    "print(f\"\\n最佳基准模型: {best_baseline_model}\")\n",
    "print(f\"基准准确率: {baseline_results[best_baseline_model]['cv_mean']:.4f}\")\n",
    "\n",
    "# 9.4 超参数优化\n",
    "print(\"\\n步骤4: 超参数优化\")\n",
    "\n",
    "# 根据基准测试结果，选择最佳模型进行优化\n",
    "if best_baseline_model == 'Random_Forest':\n",
    "    param_grid_final = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    best_model_class = RandomForestClassifier(random_state=42)\n",
    "elif best_baseline_model == 'SVM_RBF':\n",
    "    param_grid_final = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    best_model_class = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "else:\n",
    "    # 默认使用随机森林\n",
    "    param_grid_final = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    best_model_class = RandomForestClassifier(random_state=42)\n",
    "\n",
    "print(f\"优化模型: {best_baseline_model}\")\n",
    "print(f\"参数网格: {param_grid_final}\")\n",
    "\n",
    "# 网格搜索优化\n",
    "grid_search_final = GridSearchCV(\n",
    "    best_model_class, param_grid_final,\n",
    "    cv=5, scoring='accuracy',\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "print(\"进行超参数优化...\")\n",
    "start_time = time.time()\n",
    "grid_search_final.fit(X_train_processed, y_train_final)\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "print(f\"优化完成，耗时: {optimization_time:.2f}秒\")\n",
    "print(f\"最佳参数: {grid_search_final.best_params_}\")\n",
    "print(f\"最佳交叉验证得分: {grid_search_final.best_score_:.4f}\")\n",
    "\n",
    "# 9.5 最终模型训练和评估\n",
    "print(\"\\n步骤5: 最终模型训练和评估\")\n",
    "\n",
    "# 获取最佳模型\n",
    "final_model = grid_search_final.best_estimator_\n",
    "\n",
    "# 在测试集上评估\n",
    "y_pred_final = final_model.predict(X_test_processed)\n",
    "y_pred_proba_final = final_model.predict_proba(X_test_processed)\n",
    "\n",
    "# 计算最终评估指标\n",
    "final_metrics = {\n",
    "    'accuracy': accuracy_score(y_test_final, y_pred_final),\n",
    "    'precision_macro': precision_score(y_test_final, y_pred_final, average='macro'),\n",
    "    'recall_macro': recall_score(y_test_final, y_pred_final, average='macro'),\n",
    "    'f1_macro': f1_score(y_test_final, y_pred_final, average='macro')\n",
    "}\n",
    "\n",
    "print(\"最终模型性能:\")\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# 检查是否达到目标准确率\n",
    "target_met = final_metrics['accuracy'] >= PROJECT_CONFIG['target_accuracy']\n",
    "print(f\"\\n目标准确率 ({PROJECT_CONFIG['target_accuracy']}) 达成: {'✓' if target_met else '✗'}\")\n",
    "\n",
    "# 9.6 结果可视化和分析\n",
    "print(\"\\n步骤6: 结果可视化和分析\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 模型性能对比\n",
    "models = list(baseline_results.keys()) + ['Final_Optimized']\n",
    "accuracies = [baseline_results[m]['cv_mean'] for m in baseline_results.keys()] + [final_metrics['accuracy']]\n",
    "colors = ['lightblue'] * len(baseline_results) + ['red']\n",
    "\n",
    "bars = axes[0, 0].bar(range(len(models)), accuracies, color=colors)\n",
    "axes[0, 0].set_title('模型性能对比')\n",
    "axes[0, 0].set_ylabel('准确率')\n",
    "axes[0, 0].set_xticks(range(len(models)))\n",
    "axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 添加目标线\n",
    "axes[0, 0].axhline(y=PROJECT_CONFIG['target_accuracy'], color='green', \n",
    "                   linestyle='--', label=f\"目标准确率 ({PROJECT_CONFIG['target_accuracy']})\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. 混淆矩阵\n",
    "cm_final = confusion_matrix(y_test_final, y_pred_final)\n",
    "im = axes[0, 1].imshow(cm_final, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[0, 1].set_title('最终模型混淆矩阵')\n",
    "axes[0, 1].set_xlabel('预测标签')\n",
    "axes[0, 1].set_ylabel('真实标签')\n",
    "\n",
    "# 添加数值标签\n",
    "for i in range(cm_final.shape[0]):\n",
    "    for j in range(cm_final.shape[1]):\n",
    "        axes[0, 1].text(j, i, format(cm_final[i, j], 'd'),\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if cm_final[i, j] > cm_final.max() / 2 else \"black\")\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 1])\n",
    "\n",
    "# 3. 特征重要性（如果模型支持）\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    # 获取原始特征的重要性\n",
    "    feature_importance = final_model.feature_importances_\n",
    "    # 反向映射到原始像素位置\n",
    "    selected_features = preprocessing_pipeline.named_steps['feature_selection'].get_support()\n",
    "    full_importance = np.zeros(784)\n",
    "    full_importance[selected_features] = feature_importance\n",
    "    \n",
    "    importance_image = full_importance.reshape(28, 28)\n",
    "    im2 = axes[0, 2].imshow(importance_image, cmap='hot', interpolation='nearest')\n",
    "    axes[0, 2].set_title('特征重要性热力图')\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[0, 2])\n",
    "else:\n",
    "    axes[0, 2].text(0.5, 0.5, '该模型不支持\\n特征重要性分析', \n",
    "                   ha='center', va='center', transform=axes[0, 2].transAxes)\n",
    "    axes[0, 2].set_title('特征重要性')\n",
    "\n",
    "# 4. 预测概率分布\n",
    "if y_pred_proba_final is not None:\n",
    "    max_proba = np.max(y_pred_proba_final, axis=1)\n",
    "    axes[1, 0].hist(max_proba, bins=30, alpha=0.7)\n",
    "    axes[1, 0].set_title('预测概率分布')\n",
    "    axes[1, 0].set_xlabel('最大预测概率')\n",
    "    axes[1, 0].set_ylabel('频次')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. 错误分析\n",
    "incorrect_indices = np.where(y_test_final != y_pred_final)[0]\n",
    "if len(incorrect_indices) > 0:\n",
    "    # 选择一些错误样本展示\n",
    "    sample_errors = incorrect_indices[:6]\n",
    "    for i, idx in enumerate(sample_errors):\n",
    "        if i < 6:\n",
    "            row, col = divmod(i + 6, 3)  # 从第二行开始\n",
    "            if row < 2:\n",
    "                true_label = y_test_final.iloc[idx] if hasattr(y_test_final, 'iloc') else y_test_final[idx]\n",
    "                pred_label = y_pred_final[idx]\n",
    "                image = X_test_final[idx].reshape(28, 28)\n",
    "                \n",
    "                axes[row, col].imshow(image, cmap='gray')\n",
    "                axes[row, col].set_title(f'错误: {true_label}→{pred_label}')\n",
    "                axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9.7 模型保存和部署准备\n",
    "print(\"\\n步骤7: 模型保存和部署准备\")\n",
    "\n",
    "# 创建模型包\n",
    "model_package = {\n",
    "    'model': final_model,\n",
    "    'preprocessing_pipeline': preprocessing_pipeline,\n",
    "    'feature_names': [f'pixel_{i}' for i in range(784)],\n",
    "    'target_names': [str(i) for i in range(10)],\n",
    "    'model_metadata': {\n",
    "        'model_type': type(final_model).__name__,\n",
    "        'best_params': grid_search_final.best_params_,\n",
    "        'cv_score': grid_search_final.best_score_,\n",
    "        'test_accuracy': final_metrics['accuracy'],\n",
    "        'training_samples': len(X_train_final),\n",
    "        'features_selected': X_train_processed.shape[1],\n",
    "        'created_date': datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# 保存模型（注释掉实际保存，避免文件系统操作）\n",
    "# model_filename = f\"mnist_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "# joblib.dump(model_package, model_filename)\n",
    "# print(f\"模型已保存到: {model_filename}\")\n",
    "\n",
    "print(\"模型包组件:\")\n",
    "for key, value in model_package.items():\n",
    "    if key != 'model' and key != 'preprocessing_pipeline':\n",
    "        print(f\"• {key}: {type(value)}\")\n",
    "\n",
    "# 模型预测函数示例\n",
    "def predict_digit(image_array, model_package):\n",
    "    \\\"\\\"\\\"\n",
    "    预测单个手写数字图像\n",
    "    \n",
    "    参数:\n",
    "    image_array: 28x28的numpy数组或784维向量\n",
    "    model_package: 包含模型和预处理器的包\n",
    "    \n",
    "    返回:\n",
    "    prediction: 预测的数字\n",
    "    probability: 预测概率\n",
    "    \\\"\\\"\\\"\n",
    "    # 确保输入是正确的形状\n",
    "    if image_array.shape == (28, 28):\n",
    "        image_vector = image_array.flatten()\n",
    "    else:\n",
    "        image_vector = image_array\n",
    "    \n",
    "    # 预处理\n",
    "    image_processed = model_package['preprocessing_pipeline'].transform([image_vector])\n",
    "    \n",
    "    # 预测\n",
    "    prediction = model_package['model'].predict(image_processed)[0]\n",
    "    probability = model_package['model'].predict_proba(image_processed)[0]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# 示例预测\n",
    "sample_image = X_test_final[0]\n",
    "pred, prob = predict_digit(sample_image, model_package)\n",
    "print(f\"\\n预测示例:\")\n",
    "print(f\"真实标签: {y_test_final.iloc[0] if hasattr(y_test_final, 'iloc') else y_test_final[0]}\")\n",
    "print(f\"预测标签: {pred}\")\n",
    "print(f\"预测概率: {prob[pred]:.4f}\")\n",
    "\n",
    "# 9.8 项目总结报告\n",
    "print(\"\\n步骤8: 项目总结报告\")\n",
    "\n",
    "project_summary = f\\\"\\\"\\\"\n",
    "=== {PROJECT_CONFIG['project_name']} 项目总结报告 ===\n",
    "\n",
    "项目信息:\n",
    "• 项目版本: {PROJECT_CONFIG['version']}\n",
    "• 创建日期: {PROJECT_CONFIG['created_date']}\n",
    "• 目标准确率: {PROJECT_CONFIG['target_accuracy']}\n",
    "\n",
    "数据集信息:\n",
    "• 总样本数: {len(X_project):,}\n",
    "• 训练样本: {len(X_train_final):,}\n",
    "• 测试样本: {len(X_test_final):,}\n",
    "• 原始特征数: {X_project.shape[1]}\n",
    "• 选择特征数: {X_train_processed.shape[1]}\n",
    "\n",
    "模型开发过程:\n",
    "1. ✓ 探索性数据分析\n",
    "2. ✓ 数据预处理流水线构建\n",
    "3. ✓ 多模型基准测试 ({len(candidate_models)} 个模型)\n",
    "4. ✓ 超参数优化 (网格搜索)\n",
    "5. ✓ 最终模型评估\n",
    "6. ✓ 模型保存和部署准备\n",
    "\n",
    "最终模型性能:\n",
    "• 模型类型: {type(final_model).__name__}\n",
    "• 测试准确率: {final_metrics['accuracy']:.4f}\n",
    "• 精确率 (宏平均): {final_metrics['precision_macro']:.4f}\n",
    "• 召回率 (宏平均): {final_metrics['recall_macro']:.4f}\n",
    "• F1分数 (宏平均): {final_metrics['f1_macro']:.4f}\n",
    "\n",
    "目标达成情况:\n",
    "• 准确率目标: {'达成 ✓' if target_met else '未达成 ✗'}\n",
    "\n",
    "计算效率:\n",
    "• 基准测试时间: {sum(baseline_results[m]['training_time'] for m in baseline_results):.1f} 秒\n",
    "• 超参数优化时间: {optimization_time:.1f} 秒\n",
    "• 总计算时间: {sum(baseline_results[m]['training_time'] for m in baseline_results) + optimization_time:.1f} 秒\n",
    "\n",
    "建议和后续工作:\n",
    "1. 考虑使用深度学习模型进一步提升性能\n",
    "2. 实施模型监控和自动重训练机制\n",
    "3. 优化预测延迟和内存使用\n",
    "4. 增加数据增强技术\n",
    "5. 部署到生产环境并收集反馈\n",
    "\n",
    "项目状态: {'成功完成' if target_met else '需要进一步优化'}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "print(project_summary)\n",
    "\n",
    "# 保存项目报告（注释掉实际保存）\n",
    "# report_filename = f\"project_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "# with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "#     f.write(project_summary)\n",
    "# print(f\"\\n项目报告已保存到: {report_filename}\")\n",
    "\n",
    "print(f\"\\n🎉 {PROJECT_CONFIG['project_name']} 项目完成！\")\n",
    "print(f\"这个综合案例展示了完整的机器学习项目流程:\")\n",
    "print(f\"从数据探索 → 预处理 → 模型选择 → 优化 → 评估 → 部署准备\")\n",
    "print(f\"在实际项目中，你可以按照这个流程进行开发和部署。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7022ba4",
   "metadata": {},
   "source": [
    "## 10. 学习总结与进阶指南\n",
    "\n",
    "通过这个完整的Scikit-learn教程，我们掌握了机器学习的核心技能。让我们总结关键知识点，并规划进阶学习路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 知识体系回顾\n",
    "print(\"=== Scikit-learn 学习总结与进阶指南 ===\")\n",
    "\n",
    "# 创建知识体系图\n",
    "knowledge_map = {\n",
    "    '机器学习基础': {\n",
    "        '监督学习': ['分类', '回归'],\n",
    "        '无监督学习': ['聚类', '降维'],\n",
    "        '模型评估': ['交叉验证', '评估指标']\n",
    "    },\n",
    "    '数据预处理': {\n",
    "        '特征缩放': ['StandardScaler', 'MinMaxScaler', 'RobustScaler'],\n",
    "        '分类编码': ['LabelEncoder', 'OneHotEncoder', 'OrdinalEncoder'],\n",
    "        '缺失值处理': ['SimpleImputer', 'KNNImputer'],\n",
    "        '特征选择': ['VarianceThreshold', 'SelectKBest', 'RFE']\n",
    "    },\n",
    "    '分类算法': {\n",
    "        '线性模型': ['LogisticRegression'],\n",
    "        '树模型': ['DecisionTree', 'RandomForest', 'GradientBoosting'],\n",
    "        '实例学习': ['KNeighbors'],\n",
    "        '支持向量机': ['SVC'],\n",
    "        '朴素贝叶斯': ['GaussianNB'],\n",
    "        '神经网络': ['MLPClassifier']\n",
    "    },\n",
    "    '回归算法': {\n",
    "        '线性回归': ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet'],\n",
    "        '树回归': ['DecisionTreeRegressor', 'RandomForestRegressor'],\n",
    "        '支持向量回归': ['SVR']\n",
    "    },\n",
    "    '聚类算法': {\n",
    "        '划分聚类': ['KMeans'],\n",
    "        '层次聚类': ['AgglomerativeClustering'],\n",
    "        '密度聚类': ['DBSCAN'],\n",
    "        '混合模型': ['GaussianMixture']\n",
    "    },\n",
    "    '降维技术': {\n",
    "        '线性降维': ['PCA', 'TruncatedSVD'],\n",
    "        '非线性降维': ['t-SNE'],\n",
    "        '特征选择': ['SelectKBest', 'RFE']\n",
    "    },\n",
    "    '模型选择': {\n",
    "        '交叉验证': ['KFold', 'StratifiedKFold'],\n",
    "        '超参数优化': ['GridSearchCV', 'RandomizedSearchCV'],\n",
    "        '模型评估': ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"📚 本教程涵盖的知识体系:\")\n",
    "for main_topic, subtopics in knowledge_map.items():\n",
    "    print(f\"\\n{main_topic}:\")\n",
    "    for subtopic, methods in subtopics.items():\n",
    "        print(f\"  • {subtopic}: {', '.join(methods)}\")\n",
    "\n",
    "# 10.2 最佳实践总结\n",
    "print(f\"\\n=== 机器学习最佳实践总结 ===\")\n",
    "\n",
    "best_practices = {\n",
    "    '数据准备阶段': [\n",
    "        '充分理解数据和业务问题',\n",
    "        '进行探索性数据分析(EDA)',\n",
    "        '检查数据质量和完整性',\n",
    "        '合理处理缺失值和异常值',\n",
    "        '确保数据分割的随机性和代表性'\n",
    "    ],\n",
    "    '特征工程阶段': [\n",
    "        '根据算法特性选择合适的特征缩放方法',\n",
    "        '正确编码分类变量',\n",
    "        '创建有意义的特征组合',\n",
    "        '使用特征选择减少维度诅咒',\n",
    "        '避免数据泄露(Data Leakage)'\n",
    "    ],\n",
    "    '模型选择阶段': [\n",
    "        '从简单模型开始，逐步增加复杂度',\n",
    "        '使用多个算法进行基准测试',\n",
    "        '重视模型的可解释性需求',\n",
    "        '考虑计算效率和部署约束',\n",
    "        '平衡偏差和方差'\n",
    "    ],\n",
    "    '模型验证阶段': [\n",
    "        '使用分层交叉验证确保结果可靠',\n",
    "        '关注多个评估指标而非单一指标',\n",
    "        '绘制学习曲线诊断过拟合/欠拟合',\n",
    "        '在独立测试集上最终验证',\n",
    "        '进行错误分析理解模型缺陷'\n",
    "    ],\n",
    "    '超参数优化阶段': [\n",
    "        '先使用随机搜索快速探索参数空间',\n",
    "        '再使用网格搜索精细优化',\n",
    "        '设置合理的搜索范围',\n",
    "        '使用嵌套交叉验证避免过拟合',\n",
    "        '考虑计算资源和时间约束'\n",
    "    ],\n",
    "    '模型部署阶段': [\n",
    "        '保存完整的预处理流水线',\n",
    "        '建立模型监控和预警机制',\n",
    "        '准备模型回滚方案',\n",
    "        '定期重训练和更新模型',\n",
    "        '建立A/B测试框架'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for stage, practices in best_practices.items():\n",
    "    print(f\"\\n{stage}:\")\n",
    "    for i, practice in enumerate(practices, 1):\n",
    "        print(f\"  {i}. {practice}\")\n",
    "\n",
    "# 10.3 常见问题和解决方案\n",
    "print(f\"\\n=== 常见问题和解决方案 ===\")\n",
    "\n",
    "common_issues = {\n",
    "    '数据相关问题': {\n",
    "        '类别不平衡': [\n",
    "            '使用分层抽样',\n",
    "            '调整类别权重(class_weight=\"balanced\")',\n",
    "            '使用SMOTE等重采样技术',\n",
    "            '选择合适的评估指标(F1, AUC等)'\n",
    "        ],\n",
    "        '特征维度过高': [\n",
    "            '使用特征选择技术',\n",
    "            '应用PCA等降维方法',\n",
    "            '使用L1正则化(Lasso)',\n",
    "            '增加更多训练数据'\n",
    "        ],\n",
    "        '数据泄露': [\n",
    "            '确保时间序列数据的正确分割',\n",
    "            '避免使用未来信息',\n",
    "            '仔细检查特征来源',\n",
    "            '使用管道确保预处理顺序'\n",
    "        ]\n",
    "    },\n",
    "    '模型性能问题': {\n",
    "        '过拟合': [\n",
    "            '增加训练数据',\n",
    "            '使用正则化技术',\n",
    "            '减少模型复杂度',\n",
    "            '使用集成方法',\n",
    "            '应用早停策略'\n",
    "        ],\n",
    "        '欠拟合': [\n",
    "            '增加模型复杂度',\n",
    "            '创建更多特征',\n",
    "            '减少正则化强度',\n",
    "            '选择更强大的算法',\n",
    "            '增加训练时间'\n",
    "        ],\n",
    "        '泛化能力差': [\n",
    "            '使用交叉验证评估',\n",
    "            '增加验证数据的多样性',\n",
    "            '减少模型复杂度',\n",
    "            '改进特征工程',\n",
    "            '使用集成学习'\n",
    "        ]\n",
    "    },\n",
    "    '计算效率问题': {\n",
    "        '训练时间过长': [\n",
    "            '使用更快的算法',\n",
    "            '减少特征数量',\n",
    "            '使用数据子集',\n",
    "            '并行计算(n_jobs=-1)',\n",
    "            '使用增量学习算法'\n",
    "        ],\n",
    "        '内存不足': [\n",
    "            '分批处理数据',\n",
    "            '使用稀疏矩阵',\n",
    "            '减少特征维度',\n",
    "            '使用内存映射',\n",
    "            '选择内存友好的算法'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, issues in common_issues.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for issue, solutions in issues.items():\n",
    "        print(f\"  问题: {issue}\")\n",
    "        for solution in solutions:\n",
    "            print(f\"    • {solution}\")\n",
    "\n",
    "# 10.4 算法选择指南\n",
    "print(f\"\\n=== 算法选择指南 ===\")\n",
    "\n",
    "algorithm_guide = {\n",
    "    '根据问题类型选择': {\n",
    "        '二分类问题': ['LogisticRegression', 'SVM', 'RandomForest'],\n",
    "        '多分类问题': ['LogisticRegression', 'RandomForest', 'GradientBoosting'],\n",
    "        '回归问题': ['LinearRegression', 'RandomForestRegressor', 'SVR'],\n",
    "        '聚类问题': ['KMeans', 'DBSCAN', 'AgglomerativeClustering'],\n",
    "        '降维问题': ['PCA', 't-SNE', 'SelectKBest']\n",
    "    },\n",
    "    '根据数据特点选择': {\n",
    "        '小数据集(<1000样本)': ['KNN', 'NaiveBayes', 'LinearRegression'],\n",
    "        '中等数据集(1000-100k)': ['SVM', 'RandomForest', 'GradientBoosting'],\n",
    "        '大数据集(>100k样本)': ['LogisticRegression', 'SGD', 'LinearSVM'],\n",
    "        '高维数据': ['LinearModels', 'SVM', 'NaiveBayes'],\n",
    "        '非线性关系': ['RandomForest', 'SVM(RBF)', 'NeuralNetwork']\n",
    "    },\n",
    "    '根据性能要求选择': {\n",
    "        '需要概率输出': ['LogisticRegression', 'RandomForest', 'GaussianNB'],\n",
    "        '需要可解释性': ['LinearRegression', 'DecisionTree', 'LogisticRegression'],\n",
    "        '追求最高精度': ['GradientBoosting', 'RandomForest', 'SVM'],\n",
    "        '需要快速预测': ['LinearModels', 'NaiveBayes', 'KNN'],\n",
    "        '需要快速训练': ['LinearModels', 'NaiveBayes']\n",
    "    }\n",
    "}\n",
    "\n",
    "for criterion, recommendations in algorithm_guide.items():\n",
    "    print(f\"\\n{criterion}:\")\n",
    "    for scenario, algorithms in recommendations.items():\n",
    "        print(f\"  {scenario}: {', '.join(algorithms)}\")\n",
    "\n",
    "# 10.5 进阶学习路径\n",
    "print(f\"\\n=== 进阶学习路径 ===\")\n",
    "\n",
    "learning_path = {\n",
    "    '深化Scikit-learn': [\n",
    "        '学习Pipeline和ColumnTransformer的高级用法',\n",
    "        '掌握自定义转换器和估计器',\n",
    "        '研究集成学习的高级技巧',\n",
    "        '学习半监督和主动学习',\n",
    "        '掌握时间序列分析方法'\n",
    "    ],\n",
    "    '扩展到深度学习': [\n",
    "        '学习TensorFlow/Keras基础',\n",
    "        '掌握PyTorch深度学习框架',\n",
    "        '理解卷积神经网络(CNN)',\n",
    "        '学习循环神经网络(RNN/LSTM)',\n",
    "        '探索Transformer架构'\n",
    "    ],\n",
    "    '特化领域应用': [\n",
    "        '自然语言处理(NLP): NLTK, spaCy, transformers',\n",
    "        '计算机视觉: OpenCV, PIL, torchvision',\n",
    "        '推荐系统: surprise, lightfm',\n",
    "        '时间序列: statsmodels, prophet',\n",
    "        '强化学习: OpenAI Gym, stable-baselines3'\n",
    "    ],\n",
    "    '工程化和部署': [\n",
    "        '学习MLOps工具链: MLflow, DVC, Kubeflow',\n",
    "        '掌握模型部署: Flask, FastAPI, Docker',\n",
    "        '学习云平台服务: AWS SageMaker, GCP AI Platform',\n",
    "        '掌握模型监控和A/B测试',\n",
    "        '学习分布式机器学习: Dask, Ray'\n",
    "    ],\n",
    "    '理论基础加强': [\n",
    "        '深入理解统计学习理论',\n",
    "        '学习优化算法原理',\n",
    "        '掌握概率图模型',\n",
    "        '研究因果推理方法',\n",
    "        '学习贝叶斯机器学习'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for area, topics in learning_path.items():\n",
    "    print(f\"\\n{area}:\")\n",
    "    for i, topic in enumerate(topics, 1):\n",
    "        print(f\"  {i}. {topic}\")\n",
    "\n",
    "# 10.6 实践项目建议\n",
    "print(f\"\\n=== 实践项目建议 ===\")\n",
    "\n",
    "project_suggestions = {\n",
    "    '初级项目(巩固基础)': [\n",
    "        '房价预测: 回归分析和特征工程',\n",
    "        '客户细分: 聚类分析和业务解释',\n",
    "        '垃圾邮件分类: 文本分类和特征提取',\n",
    "        '股票价格预测: 时间序列分析',\n",
    "        '图像分类: 传统ML方法vs深度学习对比'\n",
    "    ],\n",
    "    '中级项目(综合应用)': [\n",
    "        '推荐系统: 协同过滤和内容推荐',\n",
    "        '欺诈检测: 不平衡数据处理',\n",
    "        '情感分析: NLP和机器学习结合',\n",
    "        '销售预测: 多元时间序列分析',\n",
    "        '用户流失预测: 生存分析和分类模型'\n",
    "    ],\n",
    "    '高级项目(工程化)': [\n",
    "        '端到端ML管道: 从数据到部署',\n",
    "        '实时推荐系统: 在线学习和冷启动',\n",
    "        '多模态学习: 文本+图像+表格数据',\n",
    "        'AutoML系统: 自动特征工程和模型选择',\n",
    "        'A/B测试平台: 实验设计和因果推理'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for level, projects in project_suggestions.items():\n",
    "    print(f\"\\n{level}:\")\n",
    "    for i, project in enumerate(projects, 1):\n",
    "        print(f\"  {i}. {project}\")\n",
    "\n",
    "# 10.7 资源推荐\n",
    "print(f\"\\n=== 学习资源推荐 ===\")\n",
    "\n",
    "resources = {\n",
    "    '官方文档和教程': [\n",
    "        'Scikit-learn官方文档: https://scikit-learn.org/',\n",
    "        'Scikit-learn教程: https://scikit-learn.org/stable/tutorial/',\n",
    "        'Python数据科学手册: Jake VanderPlas',\n",
    "        'Hands-On Machine Learning: Aurélien Géron'\n",
    "    ],\n",
    "    '在线课程': [\n",
    "        'Andrew Ng机器学习课程 (Coursera)',\n",
    "        'Fast.ai实用机器学习课程',\n",
    "        'edX MIT机器学习课程',\n",
    "        'Kaggle Learn免费课程'\n",
    "    ],\n",
    "    '实践平台': [\n",
    "        'Kaggle竞赛和数据集',\n",
    "        'Google Colab免费GPU环境',\n",
    "        'GitHub开源项目学习',\n",
    "        'Papers With Code论文代码实现'\n",
    "    ],\n",
    "    '社区和论坛': [\n",
    "        'Stack Overflow问答',\n",
    "        'Reddit r/MachineLearning',\n",
    "        '知乎机器学习话题',\n",
    "        'Towards Data Science (Medium)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, resource_list in resources.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for resource in resource_list:\n",
    "        print(f\"  • {resource}\")\n",
    "\n",
    "# 10.8 结语\n",
    "print(f\"\\n=== 结语 ===\")\n",
    "\n",
    "conclusion = \\\"\\\"\\\"\n",
    "🎓 恭喜你完成了这个全面的Scikit-learn教程！\n",
    "\n",
    "通过这个教程，你已经掌握了：\n",
    "✅ 机器学习的核心概念和工作流程\n",
    "✅ 数据预处理的各种技术和最佳实践\n",
    "✅ 主要机器学习算法的原理和应用\n",
    "✅ 模型选择、评估和优化的方法\n",
    "✅ 完整项目的开发流程\n",
    "\n",
    "记住，机器学习是一个实践性很强的学科，理论学习只是开始。\n",
    "真正的成长来自于：\n",
    "• 动手实践各种项目\n",
    "• 参与开源社区\n",
    "• 持续关注新技术发展\n",
    "• 将学到的知识应用到实际问题中\n",
    "\n",
    "机器学习领域发展迅速，保持好奇心和学习热情，\n",
    "你将在这个激动人心的领域中不断成长！\n",
    "\n",
    "🚀 现在就开始你的机器学习之旅吧！\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "print(conclusion)\n",
    "\n",
    "# 创建学习检查清单\n",
    "print(f\"\\n📋 学习检查清单:\")\n",
    "checklist = [\n",
    "    \"理解监督学习、无监督学习的区别\",\n",
    "    \"能够进行完整的数据预处理\",\n",
    "    \"掌握至少3种分类算法的使用\",\n",
    "    \"掌握至少2种回归算法的使用\", \n",
    "    \"能够使用聚类算法进行客户细分\",\n",
    "    \"理解PCA等降维技术的原理和应用\",\n",
    "    \"能够使用交叉验证评估模型性能\",\n",
    "    \"掌握网格搜索进行超参数优化\",\n",
    "    \"能够解释模型结果和业务价值\",\n",
    "    \"完成至少一个端到端的ML项目\"\n",
    "]\n",
    "\n",
    "for i, item in enumerate(checklist, 1):\n",
    "    print(f\"  {i:2d}. □ {item}\")\n",
    "\n",
    "print(f\"\\n勾选完成的项目，规划下一步学习计划！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bcdcba",
   "metadata": {},
   "source": [
    "## 📚 机器学习与Scikit-learn学习资源\n",
    "\n",
    "### 🎯 Scikit-learn官方资源\n",
    "- [**Scikit-learn官方文档**](https://scikit-learn.org/stable/) - 最权威的API文档和用户指南\n",
    "- [**Scikit-learn Examples**](https://scikit-learn.org/stable/auto_examples/) - 官方示例代码库\n",
    "- [**Scikit-learn User Guide**](https://scikit-learn.org/stable/user_guide.html) - 详细的算法介绍和使用指南\n",
    "- [**Scikit-learn Tutorials**](https://scikit-learn.org/stable/tutorial/) - 官方教程系列\n",
    "\n",
    "### 📖 机器学习经典教程\n",
    "- [**Machine Learning Course by Andrew Ng**](https://www.coursera.org/learn/machine-learning) - Coursera最经典的机器学习课程\n",
    "- [**CS229 Stanford ML**](http://cs229.stanford.edu/) - 斯坦福大学机器学习课程资料\n",
    "- [**李宏毅机器学习课程**](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html) - 台大中文机器学习课程\n",
    "- [**MIT 6.034 Artificial Intelligence**](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/) - MIT人工智能课程\n",
    "\n",
    "### 📚 推荐教材和书籍\n",
    "- [**Hands-On Machine Learning**](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) - Aurélien Géron著，实战性很强\n",
    "- [**The Elements of Statistical Learning**](https://hastie.su.stanford.edu/ElemStatLearn/) - 统计学习经典教材(免费)\n",
    "- [**Pattern Recognition and Machine Learning**](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) - Christopher Bishop的经典教材\n",
    "- [**Introduction to Statistical Learning**](https://www.statlearning.com/) - 统计学习导论(免费在线版)\n",
    "\n",
    "### 🛠️ 实践和项目\n",
    "- [**Kaggle Learn**](https://www.kaggle.com/learn) - 免费的机器学习微课程\n",
    "- [**Machine Learning Mastery**](https://machinelearningmastery.com/) - Jason Brownlee的实战教程\n",
    "- [**Towards Data Science**](https://towardsdatascience.com/) - Medium上的数据科学文章\n",
    "- [**Papers with Code**](https://paperswithcode.com/) - 论文+代码实现\n",
    "\n",
    "### 🏆 竞赛和数据集\n",
    "- [**Kaggle Competitions**](https://www.kaggle.com/competitions) - 数据科学竞赛平台\n",
    "- [**UCI ML Repository**](https://archive.ics.uci.edu/ml/) - 经典机器学习数据集\n",
    "- [**Google Dataset Search**](https://datasetsearch.research.google.com/) - Google数据集搜索\n",
    "- [**Awesome Public Datasets**](https://github.com/awesomedata/awesome-public-datasets) - 优质公开数据集\n",
    "\n",
    "### 🔬 算法深入学习\n",
    "- [**Algorithm Visualizations**](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html) - 算法可视化\n",
    "- [**Machine Learning Yearning**](https://www.deeplearning.ai/machine-learning-yearning/) - Andrew Ng的实践指南\n",
    "- [**Interpretable ML Book**](https://christophm.github.io/interpretable-ml-book/) - 可解释机器学习\n",
    "- [**Feature Engineering Book**](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/) - 特征工程指南\n",
    "\n",
    "### 🐍 Python数据科学生态\n",
    "- [**Pandas Documentation**](https://pandas.pydata.org/docs/) - 数据处理利器\n",
    "- [**NumPy User Guide**](https://numpy.org/doc/stable/user/) - 数值计算基础\n",
    "- [**Matplotlib Gallery**](https://matplotlib.org/stable/gallery/) - 可视化示例\n",
    "- [**Seaborn Tutorial**](https://seaborn.pydata.org/tutorial.html) - 统计可视化\n",
    "\n",
    "### 📊 可视化和解释\n",
    "- [**Plotly Python**](https://plotly.com/python/) - 交互式可视化\n",
    "- [**SHAP (SHapley Additive exPlanations)**](https://shap.readthedocs.io/) - 模型解释工具\n",
    "- [**LIME**](https://github.com/marcotcr/lime) - 局部可解释机器学习\n",
    "- [**Yellowbrick**](https://www.scikit-yb.org/) - 机器学习可视化\n",
    "\n",
    "### 🇨🇳 中文学习资源\n",
    "- [**机器学习实战**](https://github.com/apachecn/MachineLearning) - ApacheCN中文教程\n",
    "- [**机器学习西瓜书**](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm) - 周志华教授著作\n",
    "- [**统计学习方法**](https://book.douban.com/subject/10590856/) - 李航教授著作\n",
    "- [**Python机器学习基础教程**](https://github.com/amueller/introduction_to_ml_with_python) - 中文版配套资源\n",
    "\n",
    "### 🎓 在线课程平台\n",
    "- [**edX MIT Introduction to ML**](https://www.edx.org/course/introduction-to-machine-learning) - MIT机器学习导论\n",
    "- [**Udacity ML Nanodegree**](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009t) - 机器学习纳米学位\n",
    "- [**DataCamp**](https://www.datacamp.com/) - 数据科学在线学习\n",
    "- [**Coursera ML Specialization**](https://www.coursera.org/specializations/machine-learning-introduction) - 新版机器学习专项课程\n",
    "\n",
    "### 🧪 实验和工具\n",
    "- [**Google Colab**](https://colab.research.google.com/) - 免费的云端Jupyter环境\n",
    "- [**Jupyter Notebooks Gallery**](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks) - 优质Jupyter笔记本\n",
    "- [**MLflow**](https://mlflow.org/) - 机器学习生命周期管理\n",
    "- [**Weights & Biases**](https://wandb.ai/) - 实验跟踪和可视化\n",
    "\n",
    "### 📱 移动学习\n",
    "- [**Machine Learning Mastery Blog**](https://machinelearningmastery.com/blog/) - 定期更新的技术博客\n",
    "- [**KDnuggets**](https://www.kdnuggets.com/) - 数据科学新闻和教程\n",
    "- [**Analytics Vidhya**](https://www.analyticsvidhya.com/) - 数据科学社区\n",
    "- [**DataScienceCentral**](https://www.datasciencecentral.com/) - 数据科学资讯平台\n",
    "\n",
    "记住：**机器学习是理论与实践的结合，多动手、多实验才是王道！** 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
